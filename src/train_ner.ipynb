{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('ner': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c9e9e9c2c630163d1306c3642fc8a6e53d34dc83778d6517d9e34b96a0c61c48"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# PII Data NER\n",
    "\n",
    "## Data\n",
    "An excel file containing these sheets:\n",
    "- Export Summary\n",
    "- PII Train Large Data - PII Trai (800 rows)\n",
    "- PII Test Data - PII Test Data (16000 rows\n",
    "\n",
    "## Initial observations/ assumptions:\n",
    "- The training data is very limited, making the exercise a good candiate for either transfer learning approach or if required semi-supervised learning approach with data augmentation.\n",
    "- A sentence can have more than one labels, which makes this a multilabel classification problem\n",
    "- Certain entities such as email, ssn, credit cards, follow a well known pattern. This makes them easier to detect with non-stocastic rule based methods\n",
    "- Other entities such as names and addresses have more pattern variance and might require a more machine learning centric approach.\n",
    "- On the other hand the test dataset only requires one label and one PII value, which means this problem forces an assumption that this is one-vs-all classification simplification.\n",
    "- Additionally, the instructions specifically ask for building a machine learning model, so it' best to skip the regex like rule based approaches since they would be trivial solutions, and not justify the intent of the exercise.\n",
    "- The problem does not constrain on the compute resources, and does not constrain on the inference time requirements, so it is safe to assume the best bet is to optimize for better accuract / f1- scores.\n",
    "- The solution should specifically address Entity ambiguity w.r.t overlapping classes (polysemic words) and just the PII, thereby contextual disambiguation needs to be implemented and detailed.\n",
    "\n",
    "## Solution Space\n",
    "- I'd treat this problem as a token sequence classification exercise where token is a unit comprising the sequence. \n",
    "- Since information is text is contiguous w.r.t token boundaries, it is safe to consider variable token descriptions, such as a token could be a character or a sub word or a word.\n",
    "- Standard approaches for named entity recorgnition can come in handy, the best expression of training data would be in CONLL format, including part of speed analysis followed IOB tagging using either RNN models or similar approaches.\n",
    "- Since the exercise is time bound, as a simplification, it is safe to start with off-the-shelf transformer models and then iteratively optimize.\n",
    "\n",
    "## Evaluation Criteria\n",
    "There will be a 2 part evaluation\n",
    "- To determine the performance on a holdout set (with crossvalidation for a real usage, skipped)\n",
    "  - Report microavg F1 Score, precision and recall for each class\n",
    "  - A full phrase match might be a good criteria for evaluation.\n",
    "\n",
    "- To determine perfomance of some known desired behavious with a custom checklist for model explainability and reliability. (Future, for now just test on a small list)\n",
    "    - Robustness estimates could be included to further harden the models.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "# local files\n",
    "import rules\n",
    "import preprocess\n",
    "import datagen\n",
    "\n",
    "from typing import List\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from flair.data import Sentence, Corpus\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import FlairEmbeddings, WordEmbeddings, StackedEmbeddings, TokenEmbeddings,TransformerWordEmbeddings\n",
    "\n",
    "random.seed(369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_excel(\"PII_Train_Large_Data_Test_Data.xlsx\",sheet_name=\"PII Train Large Data - PII Trai\", skiprows=1, index_col=None, na_values=['NA'], usecols = \"A,B,C\")\n",
    "# shuffle\n",
    "raw_data = raw_data.sample(frac=1,random_state=369).reset_index(drop=True)"
   ]
  },
  {
   "source": [
    "### Data Exploration\n",
    "Obervations:\n",
    "- total classes present = 8\n",
    "- classes are balanced\n",
    "- 60/20/20 split makes sense for train/test/dev\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                Text            Labels  \\\n",
       "0  Quality whom pay travel our 4914569109182 tabl...  CreditCardNumber   \n",
       "1  History effort 427 68 3081 system kitchen. Hea...               SSN   \n",
       "2  Team Republican him Jessica Ellis reveal. Play...              Name   \n",
       "3  Radio respond perhaps western loss blood. Turn...             Email   \n",
       "4      Ready off score 8H 67881 foot market protect.            Plates   \n",
       "\n",
       "                              PII  \n",
       "0                   4914569109182  \n",
       "1                     427 68 3081  \n",
       "2                   Jessica Ellis  \n",
       "3  jrodriguez@mccarthy-lawson.biz  \n",
       "4                        8H 67881  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Labels</th>\n      <th>PII</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Quality whom pay travel our 4914569109182 tabl...</td>\n      <td>CreditCardNumber</td>\n      <td>4914569109182</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>History effort 427 68 3081 system kitchen. Hea...</td>\n      <td>SSN</td>\n      <td>427 68 3081</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Team Republican him Jessica Ellis reveal. Play...</td>\n      <td>Name</td>\n      <td>Jessica Ellis</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Radio respond perhaps western loss blood. Turn...</td>\n      <td>Email</td>\n      <td>jrodriguez@mccarthy-lawson.biz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ready off score 8H 67881 foot market protect.</td>\n      <td>Plates</td>\n      <td>8H 67881</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Labels  Text\n",
       "0           Address   100\n",
       "1  CreditCardNumber   100\n",
       "2             Email   100\n",
       "3              Name   100\n",
       "4              None   100\n",
       "5      Phone_number   100\n",
       "6            Plates   100\n",
       "7               SSN   100"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Labels</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Address</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CreditCardNumber</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Email</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Name</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Phone_number</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Plates</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SSN</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# show the distribution of class in the train set\n",
    "raw_data.groupby([\"Labels\"])['Text'].nunique().reset_index()"
   ]
  },
  {
   "source": [
    "## Data Augmentation\n",
    "- Less support for complex patterns such as <b>Name</b> and <b>Address</b> and those need to be augmented for a fair evaluation\n",
    "- Lucky for me there is an easy way to generate fake names and addresses, let's add those to the mix to increase support."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                Text   Labels  \\\n",
       "0  Bring discuss from night Michael Wilson form i...     Name   \n",
       "1  About second save despite 42603 Carpenter Corn...  Address   \n",
       "2  Million natural yet girl. Enough physical Ange...     Name   \n",
       "3  Benefit 5821 Morales Orchard Lorraineport, FL ...  Address   \n",
       "4  Apply determine Sheila Robinson weight such tr...     Name   \n",
       "\n",
       "                                               PII  \n",
       "0                                   Michael Wilson  \n",
       "1  42603 Carpenter Corner New Jaredburgh, RI 70826  \n",
       "2                                   Angela Wallace  \n",
       "3      5821 Morales Orchard Lorraineport, FL 37647  \n",
       "4                                  Sheila Robinson  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Labels</th>\n      <th>PII</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bring discuss from night Michael Wilson form i...</td>\n      <td>Name</td>\n      <td>Michael Wilson</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>About second save despite 42603 Carpenter Corn...</td>\n      <td>Address</td>\n      <td>42603 Carpenter Corner New Jaredburgh, RI 70826</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Million natural yet girl. Enough physical Ange...</td>\n      <td>Name</td>\n      <td>Angela Wallace</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Benefit 5821 Morales Orchard Lorraineport, FL ...</td>\n      <td>Address</td>\n      <td>5821 Morales Orchard Lorraineport, FL 37647</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Apply determine Sheila Robinson weight such tr...</td>\n      <td>Name</td>\n      <td>Sheila Robinson</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Ref: datagen.py for details\n",
    "gen = datagen.DataGenerator(max_nb_chars=80, n=900, seed=369)\n",
    "fake_data = gen.generate_fake_data()\n",
    "fake_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented data is a combination of original data and the fake data\n",
    "aug_data = pd.concat([raw_data, fake_data])\n",
    "# shuffle again\n",
    "aug_data = aug_data.sample(frac=1,random_state=369).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Labels  Text\n",
       "0           Address  1000\n",
       "1  CreditCardNumber   100\n",
       "2             Email   100\n",
       "3              Name  1000\n",
       "4              None   100\n",
       "5      Phone_number   100\n",
       "6            Plates   100\n",
       "7               SSN   100"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Labels</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Address</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CreditCardNumber</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Email</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Name</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Phone_number</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Plates</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SSN</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# show the distribution of class in the train set\n",
    "# Note: Now we have 1000 examples of Name and Address\n",
    "aug_data.groupby([\"Labels\"])['Text'].nunique().reset_index()"
   ]
  },
  {
   "source": [
    "## Tokenization\n",
    "- This is one of the key aspects for getting the correct NER.\n",
    "- Known patterns can be pinned with deterministic tokens in order to aid the recognition.\n",
    "- Flair's internal tokenization handles special characters by adding spaces, which makes for special handling in case of email, where \"@\" symbol must be replaced with \" @ \" and an inverse transform might be needed on the predicted spans before consumption.\n",
    "\n",
    "Here is an example of email sentence tokenized, notice tokens <b>eee</b> @ <b>mmm</b>:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Email\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Mission O\\n',\n",
       " 'throughout O\\n',\n",
       " 'small O\\n',\n",
       " 'save O\\n',\n",
       " 'still O\\n',\n",
       " 'lay O\\n',\n",
       " 'discussion O\\n',\n",
       " 'according. O\\n',\n",
       " 'Spend O\\n',\n",
       " 'man O\\n',\n",
       " 'eee O\\n',\n",
       " 'zdawson B-Email\\n',\n",
       " '@ I-Email\\n',\n",
       " 'hotmail.com I-Email\\n',\n",
       " 'mmm O\\n',\n",
       " 'finally O\\n',\n",
       " 'finish O\\n',\n",
       " 'some O\\n',\n",
       " 'officer. O\\n',\n",
       " '\\n']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Here is an example of how the tokenization takes place.\n",
    "converter = preprocess.CoNLLConverter()\n",
    "index = 61\n",
    "print(aug_data['Labels'].iloc[index])\n",
    "converter.bio_tagger(aug_data['Text'].iloc[index], aug_data['Labels'].iloc[index], aug_data['PII'].iloc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Labels  Text\n",
       "0           Address   200\n",
       "1  CreditCardNumber    20\n",
       "2             Email    20\n",
       "3              Name   200\n",
       "4              None    20\n",
       "5      Phone_number    20\n",
       "6            Plates    20\n",
       "7               SSN    20"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Labels</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Address</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CreditCardNumber</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Email</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Name</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Phone_number</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Plates</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SSN</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# partition data into train, test, dev\n",
    "X_train, X_test, y_train, y_test = train_test_split(aug_data.index, aug_data[\"Labels\"], test_size=0.2, random_state=369 ,stratify=aug_data[\"Labels\"])\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.25, random_state=369, stratify=y_train)  # 0.25 x 0.8 = 0.2\n",
    "# verify split distribution is identical\n",
    "aug_data.loc[X_dev,:].groupby([\"Labels\"])['Text'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all data for visual checks\n",
    "with open(\"pii_conll_data_all.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for index, row in aug_data.iterrows():\n",
    "        tagged_data = converter.bio_tagger(row['Text'], row['Labels'], row['PII'])\n",
    "        f.writelines(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train.txt\n",
    "with open(\"train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for index, row in aug_data.loc[X_train,:].iterrows():\n",
    "        tagged_data = converter.bio_tagger(row['Text'], row['Labels'], row['PII'])\n",
    "        f.writelines(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test.txt\n",
    "with open(\"test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for index, row in aug_data.loc[X_test,:].iterrows():\n",
    "        tagged_data = converter.bio_tagger(row['Text'], row['Labels'], row['PII'])\n",
    "        f.writelines(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dev.txt\n",
    "with open(\"dev.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for index, row in aug_data.loc[X_dev,:].iterrows():\n",
    "        tagged_data = converter.bio_tagger(row['Text'], row['Labels'], row['PII'])\n",
    "        f.writelines(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-30 23:20:34,947 Reading data from .\n",
      "2021-01-30 23:20:34,948 Train: train.txt\n",
      "2021-01-30 23:20:34,949 Dev: dev.txt\n",
      "2021-01-30 23:20:34,949 Test: test.txt\n"
     ]
    }
   ],
   "source": [
    "#Load the corpus\n",
    "# define columns\n",
    "columns = {0 : 'text', 1 : 'ner'}\n",
    "# directory where the data resides\n",
    "data_folder = '.'\n",
    "# initializing the corpus\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file = 'train.txt',\n",
    "                              test_file = 'test.txt',\n",
    "                              dev_file = 'dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init Flair embeddings\n",
    "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
    "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
    "\n",
    "# ***\n",
    "# Note: This would be helpful if we had well formed sentences, this would really help in \n",
    "# the case of polysemic words, which we currently don't have in the train / test data\n",
    "# since that would mean having PER, LOC\n",
    "# ***\n",
    "\n",
    "# init multilingual BERT\n",
    "# bert_embedding = TransformerWordEmbeddings('bert-base-multilingual-cased')\n",
    "\n",
    "embedding_types : List[TokenEmbeddings] = [\n",
    "        WordEmbeddings('glove'),\n",
    "        ## other embeddings\n",
    "        flair_forward_embedding, \n",
    "        flair_backward_embedding, \n",
    "        # bert_embedding\n",
    "        ]\n",
    "embeddings : StackedEmbeddings = StackedEmbeddings(\n",
    "                                 embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dictionary with 16 tags: <unk>, O, B-Address, I-Address, B-Plates, I-Plates, B-Name, I-Name, B-Phone_number, B-SSN, B-CreditCardNumber, B-Email, I-Email, I-SSN, <START>, <STOP>\nSequenceTagger(\n  (embeddings): StackedEmbeddings(\n    (list_embedding_0): WordEmbeddings('glove')\n    (list_embedding_1): FlairEmbeddings(\n      (lm): LanguageModel(\n        (drop): Dropout(p=0.1, inplace=False)\n        (encoder): Embedding(11854, 100)\n        (rnn): LSTM(100, 2048)\n        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n      )\n    )\n    (list_embedding_2): FlairEmbeddings(\n      (lm): LanguageModel(\n        (drop): Dropout(p=0.1, inplace=False)\n        (encoder): Embedding(11854, 100)\n        (rnn): LSTM(100, 2048)\n        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n      )\n    )\n  )\n  (word_dropout): WordDropout(p=0.05)\n  (locked_dropout): LockedDropout(p=0.5)\n  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n  (linear): Linear(in_features=512, out_features=16, bias=True)\n  (beta): 1.0\n  (weights): None\n  (weight_tensor) None\n)\n"
     ]
    }
   ],
   "source": [
    "# prepare the tag for ner\n",
    "tag_type = 'ner'\n",
    "# make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)\n",
    "\n",
    "tagger : SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                       embeddings=embeddings,\n",
    "                                       tag_dictionary=tag_dictionary,\n",
    "                                       tag_type=tag_type,\n",
    "                                       use_crf=True)\n",
    "\n",
    "# describe the network\n",
    "print(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-30 23:21:30,785 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:21:30,786 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(11854, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(11854, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=16, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-01-30 23:21:30,788 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:21:30,789 Corpus: \"Corpus: 1560 train + 520 dev + 520 test sentences\"\n",
      "2021-01-30 23:21:30,790 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:21:30,790 Parameters:\n",
      "2021-01-30 23:21:30,791  - learning_rate: \"0.1\"\n",
      "2021-01-30 23:21:30,791  - mini_batch_size: \"32\"\n",
      "2021-01-30 23:21:30,792  - patience: \"3\"\n",
      "2021-01-30 23:21:30,793  - anneal_factor: \"0.5\"\n",
      "2021-01-30 23:21:30,794  - max_epochs: \"150\"\n",
      "2021-01-30 23:21:30,795  - shuffle: \"True\"\n",
      "2021-01-30 23:21:30,795  - train_with_dev: \"False\"\n",
      "2021-01-30 23:21:30,796  - batch_growth_annealing: \"False\"\n",
      "2021-01-30 23:21:30,798 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:21:30,799 Model training base path: \"taggers\\pii-ner-v0\"\n",
      "2021-01-30 23:21:30,801 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:21:30,802 Device: cuda:0\n",
      "2021-01-30 23:21:30,803 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:21:30,805 Embeddings storage mode: cpu\n",
      "2021-01-30 23:21:30,808 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:21:32,581 epoch 1 - iter 4/49 - loss 22.58154964 - samples/sec: 72.27 - lr: 0.100000\n",
      "2021-01-30 23:21:34,286 epoch 1 - iter 8/49 - loss 17.93580651 - samples/sec: 75.07 - lr: 0.100000\n",
      "2021-01-30 23:21:35,781 epoch 1 - iter 12/49 - loss 15.83787417 - samples/sec: 85.62 - lr: 0.100000\n",
      "2021-01-30 23:21:37,243 epoch 1 - iter 16/49 - loss 14.22916049 - samples/sec: 87.61 - lr: 0.100000\n",
      "2021-01-30 23:21:38,680 epoch 1 - iter 20/49 - loss 13.05743599 - samples/sec: 89.26 - lr: 0.100000\n",
      "2021-01-30 23:21:40,228 epoch 1 - iter 24/49 - loss 12.04526969 - samples/sec: 82.65 - lr: 0.100000\n",
      "2021-01-30 23:21:41,955 epoch 1 - iter 28/49 - loss 11.23047078 - samples/sec: 74.14 - lr: 0.100000\n",
      "2021-01-30 23:21:43,408 epoch 1 - iter 32/49 - loss 10.48964347 - samples/sec: 88.15 - lr: 0.100000\n",
      "2021-01-30 23:21:44,871 epoch 1 - iter 36/49 - loss 9.78758725 - samples/sec: 87.67 - lr: 0.100000\n",
      "2021-01-30 23:21:46,462 epoch 1 - iter 40/49 - loss 9.19350570 - samples/sec: 80.50 - lr: 0.100000\n",
      "2021-01-30 23:21:48,031 epoch 1 - iter 44/49 - loss 8.64774423 - samples/sec: 81.62 - lr: 0.100000\n",
      "2021-01-30 23:21:49,563 epoch 1 - iter 48/49 - loss 8.17322055 - samples/sec: 83.62 - lr: 0.100000\n",
      "2021-01-30 23:21:49,864 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:21:49,865 EPOCH 1 done: loss 8.0484 - lr 0.1000000\n",
      "2021-01-30 23:21:55,254 DEV : loss 1.898419737815857 - score 0.7731\n",
      "2021-01-30 23:21:55,280 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:21:58,623 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:21:59,360 epoch 2 - iter 4/49 - loss 2.67750400 - samples/sec: 173.89 - lr: 0.100000\n",
      "2021-01-30 23:22:00,034 epoch 2 - iter 8/49 - loss 2.36305326 - samples/sec: 190.18 - lr: 0.100000\n",
      "2021-01-30 23:22:00,722 epoch 2 - iter 12/49 - loss 2.27117385 - samples/sec: 186.47 - lr: 0.100000\n",
      "2021-01-30 23:22:01,377 epoch 2 - iter 16/49 - loss 2.11800072 - samples/sec: 195.75 - lr: 0.100000\n",
      "2021-01-30 23:22:02,060 epoch 2 - iter 20/49 - loss 2.01906113 - samples/sec: 187.73 - lr: 0.100000\n",
      "2021-01-30 23:22:02,778 epoch 2 - iter 24/49 - loss 1.92805455 - samples/sec: 178.53 - lr: 0.100000\n",
      "2021-01-30 23:22:03,460 epoch 2 - iter 28/49 - loss 1.90763015 - samples/sec: 187.95 - lr: 0.100000\n",
      "2021-01-30 23:22:04,128 epoch 2 - iter 32/49 - loss 1.86041920 - samples/sec: 191.80 - lr: 0.100000\n",
      "2021-01-30 23:22:04,793 epoch 2 - iter 36/49 - loss 1.79927409 - samples/sec: 192.76 - lr: 0.100000\n",
      "2021-01-30 23:22:05,439 epoch 2 - iter 40/49 - loss 1.80679482 - samples/sec: 198.15 - lr: 0.100000\n",
      "2021-01-30 23:22:06,094 epoch 2 - iter 44/49 - loss 1.76364078 - samples/sec: 196.01 - lr: 0.100000\n",
      "2021-01-30 23:22:06,729 epoch 2 - iter 48/49 - loss 1.69919165 - samples/sec: 201.87 - lr: 0.100000\n",
      "2021-01-30 23:22:06,861 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:22:06,862 EPOCH 2 done: loss 1.6800 - lr 0.1000000\n",
      "2021-01-30 23:22:08,686 DEV : loss 0.6449254155158997 - score 0.8715\n",
      "2021-01-30 23:22:08,713 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:22:12,090 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:22:12,810 epoch 3 - iter 4/49 - loss 0.91469967 - samples/sec: 178.00 - lr: 0.100000\n",
      "2021-01-30 23:22:13,529 epoch 3 - iter 8/49 - loss 1.07274796 - samples/sec: 177.98 - lr: 0.100000\n",
      "2021-01-30 23:22:14,168 epoch 3 - iter 12/49 - loss 1.03998288 - samples/sec: 200.62 - lr: 0.100000\n",
      "2021-01-30 23:22:14,799 epoch 3 - iter 16/49 - loss 1.06162519 - samples/sec: 203.17 - lr: 0.100000\n",
      "2021-01-30 23:22:15,448 epoch 3 - iter 20/49 - loss 1.03750327 - samples/sec: 197.53 - lr: 0.100000\n",
      "2021-01-30 23:22:16,080 epoch 3 - iter 24/49 - loss 1.01032831 - samples/sec: 202.85 - lr: 0.100000\n",
      "2021-01-30 23:22:16,745 epoch 3 - iter 28/49 - loss 1.02116259 - samples/sec: 192.77 - lr: 0.100000\n",
      "2021-01-30 23:22:17,390 epoch 3 - iter 32/49 - loss 1.00255647 - samples/sec: 198.75 - lr: 0.100000\n",
      "2021-01-30 23:22:18,035 epoch 3 - iter 36/49 - loss 0.98378548 - samples/sec: 198.76 - lr: 0.100000\n",
      "2021-01-30 23:22:18,659 epoch 3 - iter 40/49 - loss 0.97881793 - samples/sec: 205.78 - lr: 0.100000\n",
      "2021-01-30 23:22:19,351 epoch 3 - iter 44/49 - loss 0.98077358 - samples/sec: 185.25 - lr: 0.100000\n",
      "2021-01-30 23:22:19,999 epoch 3 - iter 48/49 - loss 0.95565764 - samples/sec: 197.84 - lr: 0.100000\n",
      "2021-01-30 23:22:20,141 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:22:20,141 EPOCH 3 done: loss 0.9603 - lr 0.1000000\n",
      "2021-01-30 23:22:21,976 DEV : loss 0.38109567761421204 - score 0.9347\n",
      "2021-01-30 23:22:22,003 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:22:25,443 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:22:26,080 epoch 4 - iter 4/49 - loss 0.95579511 - samples/sec: 201.26 - lr: 0.100000\n",
      "2021-01-30 23:22:26,718 epoch 4 - iter 8/49 - loss 0.88346305 - samples/sec: 201.26 - lr: 0.100000\n",
      "2021-01-30 23:22:27,380 epoch 4 - iter 12/49 - loss 0.81097397 - samples/sec: 193.64 - lr: 0.100000\n",
      "2021-01-30 23:22:28,092 epoch 4 - iter 16/49 - loss 0.77533121 - samples/sec: 180.28 - lr: 0.100000\n",
      "2021-01-30 23:22:28,767 epoch 4 - iter 20/49 - loss 0.73942493 - samples/sec: 189.90 - lr: 0.100000\n",
      "2021-01-30 23:22:29,389 epoch 4 - iter 24/49 - loss 0.71924439 - samples/sec: 206.12 - lr: 0.100000\n",
      "2021-01-30 23:22:30,086 epoch 4 - iter 28/49 - loss 0.68017668 - samples/sec: 183.52 - lr: 0.100000\n",
      "2021-01-30 23:22:30,761 epoch 4 - iter 32/49 - loss 0.69265131 - samples/sec: 189.91 - lr: 0.100000\n",
      "2021-01-30 23:22:31,401 epoch 4 - iter 36/49 - loss 0.68632024 - samples/sec: 200.62 - lr: 0.100000\n",
      "2021-01-30 23:22:32,021 epoch 4 - iter 40/49 - loss 0.69342706 - samples/sec: 206.79 - lr: 0.100000\n",
      "2021-01-30 23:22:32,679 epoch 4 - iter 44/49 - loss 0.67571855 - samples/sec: 194.82 - lr: 0.100000\n",
      "2021-01-30 23:22:33,315 epoch 4 - iter 48/49 - loss 0.64602079 - samples/sec: 201.57 - lr: 0.100000\n",
      "2021-01-30 23:22:33,444 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:22:33,444 EPOCH 4 done: loss 0.6436 - lr 0.1000000\n",
      "2021-01-30 23:22:35,235 DEV : loss 0.49562206864356995 - score 0.8727\n",
      "2021-01-30 23:22:35,261 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:22:35,262 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:22:35,945 epoch 5 - iter 4/49 - loss 0.93478358 - samples/sec: 187.68 - lr: 0.100000\n",
      "2021-01-30 23:22:36,581 epoch 5 - iter 8/49 - loss 0.76117328 - samples/sec: 201.25 - lr: 0.100000\n",
      "2021-01-30 23:22:37,205 epoch 5 - iter 12/49 - loss 0.69910236 - samples/sec: 205.46 - lr: 0.100000\n",
      "2021-01-30 23:22:37,810 epoch 5 - iter 16/49 - loss 0.67637740 - samples/sec: 211.58 - lr: 0.100000\n",
      "2021-01-30 23:22:38,496 epoch 5 - iter 20/49 - loss 0.64432973 - samples/sec: 187.38 - lr: 0.100000\n",
      "2021-01-30 23:22:39,160 epoch 5 - iter 24/49 - loss 0.63017973 - samples/sec: 193.06 - lr: 0.100000\n",
      "2021-01-30 23:22:39,821 epoch 5 - iter 28/49 - loss 0.61767057 - samples/sec: 194.23 - lr: 0.100000\n",
      "2021-01-30 23:22:40,522 epoch 5 - iter 32/49 - loss 0.59024120 - samples/sec: 182.84 - lr: 0.100000\n",
      "2021-01-30 23:22:41,162 epoch 5 - iter 36/49 - loss 0.55616322 - samples/sec: 200.00 - lr: 0.100000\n",
      "2021-01-30 23:22:41,841 epoch 5 - iter 40/49 - loss 0.54543906 - samples/sec: 189.07 - lr: 0.100000\n",
      "2021-01-30 23:22:42,502 epoch 5 - iter 44/49 - loss 0.54371845 - samples/sec: 193.94 - lr: 0.100000\n",
      "2021-01-30 23:22:43,154 epoch 5 - iter 48/49 - loss 0.55172021 - samples/sec: 196.30 - lr: 0.100000\n",
      "2021-01-30 23:22:43,288 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:22:43,288 EPOCH 5 done: loss 0.5518 - lr 0.1000000\n",
      "2021-01-30 23:22:45,078 DEV : loss 0.2230025827884674 - score 0.969\n",
      "2021-01-30 23:22:45,105 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:22:48,517 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:22:49,189 epoch 6 - iter 4/49 - loss 0.46091035 - samples/sec: 191.33 - lr: 0.100000\n",
      "2021-01-30 23:22:49,851 epoch 6 - iter 8/49 - loss 0.38715197 - samples/sec: 193.61 - lr: 0.100000\n",
      "2021-01-30 23:22:50,521 epoch 6 - iter 12/49 - loss 0.39896632 - samples/sec: 191.28 - lr: 0.100000\n",
      "2021-01-30 23:22:51,150 epoch 6 - iter 16/49 - loss 0.39612152 - samples/sec: 203.64 - lr: 0.100000\n",
      "2021-01-30 23:22:51,832 epoch 6 - iter 20/49 - loss 0.37404497 - samples/sec: 188.20 - lr: 0.100000\n",
      "2021-01-30 23:22:52,506 epoch 6 - iter 24/49 - loss 0.38191219 - samples/sec: 190.20 - lr: 0.100000\n",
      "2021-01-30 23:22:53,146 epoch 6 - iter 28/49 - loss 0.36910405 - samples/sec: 200.27 - lr: 0.100000\n",
      "2021-01-30 23:22:54,010 epoch 6 - iter 32/49 - loss 0.37308112 - samples/sec: 148.11 - lr: 0.100000\n",
      "2021-01-30 23:22:54,697 epoch 6 - iter 36/49 - loss 0.38132942 - samples/sec: 186.56 - lr: 0.100000\n",
      "2021-01-30 23:22:55,427 epoch 6 - iter 40/49 - loss 0.39074808 - samples/sec: 175.31 - lr: 0.100000\n",
      "2021-01-30 23:22:56,052 epoch 6 - iter 44/49 - loss 0.39554997 - samples/sec: 205.42 - lr: 0.100000\n",
      "2021-01-30 23:22:56,730 epoch 6 - iter 48/49 - loss 0.40774785 - samples/sec: 188.77 - lr: 0.100000\n",
      "2021-01-30 23:22:56,870 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:22:56,871 EPOCH 6 done: loss 0.4095 - lr 0.1000000\n",
      "2021-01-30 23:22:58,658 DEV : loss 0.14185886085033417 - score 0.97\n",
      "2021-01-30 23:22:58,685 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:23:02,051 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:23:02,713 epoch 7 - iter 4/49 - loss 0.35812479 - samples/sec: 193.65 - lr: 0.100000\n",
      "2021-01-30 23:23:03,343 epoch 7 - iter 8/49 - loss 0.41380739 - samples/sec: 203.48 - lr: 0.100000\n",
      "2021-01-30 23:23:03,990 epoch 7 - iter 12/49 - loss 0.41033316 - samples/sec: 197.84 - lr: 0.100000\n",
      "2021-01-30 23:23:04,639 epoch 7 - iter 16/49 - loss 0.40743106 - samples/sec: 197.53 - lr: 0.100000\n",
      "2021-01-30 23:23:05,285 epoch 7 - iter 20/49 - loss 0.46525480 - samples/sec: 198.37 - lr: 0.100000\n",
      "2021-01-30 23:23:05,934 epoch 7 - iter 24/49 - loss 0.47430279 - samples/sec: 197.82 - lr: 0.100000\n",
      "2021-01-30 23:23:06,620 epoch 7 - iter 28/49 - loss 0.44674021 - samples/sec: 186.85 - lr: 0.100000\n",
      "2021-01-30 23:23:07,344 epoch 7 - iter 32/49 - loss 0.42805811 - samples/sec: 177.00 - lr: 0.100000\n",
      "2021-01-30 23:23:07,975 epoch 7 - iter 36/49 - loss 0.41729362 - samples/sec: 203.17 - lr: 0.100000\n",
      "2021-01-30 23:23:08,613 epoch 7 - iter 40/49 - loss 0.40524400 - samples/sec: 200.94 - lr: 0.100000\n",
      "2021-01-30 23:23:09,246 epoch 7 - iter 44/49 - loss 0.38618604 - samples/sec: 202.21 - lr: 0.100000\n",
      "2021-01-30 23:23:09,855 epoch 7 - iter 48/49 - loss 0.37482151 - samples/sec: 210.53 - lr: 0.100000\n",
      "2021-01-30 23:23:09,982 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:23:09,983 EPOCH 7 done: loss 0.3757 - lr 0.1000000\n",
      "2021-01-30 23:23:11,763 DEV : loss 0.12086606025695801 - score 0.976\n",
      "2021-01-30 23:23:11,790 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:23:15,187 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:23:15,829 epoch 8 - iter 4/49 - loss 0.35373795 - samples/sec: 199.69 - lr: 0.100000\n",
      "2021-01-30 23:23:16,484 epoch 8 - iter 8/49 - loss 0.32098983 - samples/sec: 195.72 - lr: 0.100000\n",
      "2021-01-30 23:23:17,160 epoch 8 - iter 12/49 - loss 0.31519954 - samples/sec: 189.41 - lr: 0.100000\n",
      "2021-01-30 23:23:17,831 epoch 8 - iter 16/49 - loss 0.28722229 - samples/sec: 190.76 - lr: 0.100000\n",
      "2021-01-30 23:23:18,513 epoch 8 - iter 20/49 - loss 0.30255990 - samples/sec: 187.96 - lr: 0.100000\n",
      "2021-01-30 23:23:19,195 epoch 8 - iter 24/49 - loss 0.30289603 - samples/sec: 187.97 - lr: 0.100000\n",
      "2021-01-30 23:23:19,837 epoch 8 - iter 28/49 - loss 0.30726994 - samples/sec: 199.53 - lr: 0.100000\n",
      "2021-01-30 23:23:20,478 epoch 8 - iter 32/49 - loss 0.31280483 - samples/sec: 200.28 - lr: 0.100000\n",
      "2021-01-30 23:23:21,165 epoch 8 - iter 36/49 - loss 0.31119423 - samples/sec: 186.31 - lr: 0.100000\n",
      "2021-01-30 23:23:21,824 epoch 8 - iter 40/49 - loss 0.31078010 - samples/sec: 194.50 - lr: 0.100000\n",
      "2021-01-30 23:23:22,461 epoch 8 - iter 44/49 - loss 0.31105875 - samples/sec: 201.54 - lr: 0.100000\n",
      "2021-01-30 23:23:23,093 epoch 8 - iter 48/49 - loss 0.30988725 - samples/sec: 202.54 - lr: 0.100000\n",
      "2021-01-30 23:23:23,214 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:23:23,215 EPOCH 8 done: loss 0.3063 - lr 0.1000000\n",
      "2021-01-30 23:23:24,932 DEV : loss 0.0914660096168518 - score 0.9771\n",
      "2021-01-30 23:23:24,960 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:23:28,414 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:23:29,082 epoch 9 - iter 4/49 - loss 0.24161664 - samples/sec: 192.19 - lr: 0.100000\n",
      "2021-01-30 23:23:29,716 epoch 9 - iter 8/49 - loss 0.24488863 - samples/sec: 201.89 - lr: 0.100000\n",
      "2021-01-30 23:23:30,351 epoch 9 - iter 12/49 - loss 0.26944518 - samples/sec: 201.57 - lr: 0.100000\n",
      "2021-01-30 23:23:30,987 epoch 9 - iter 16/49 - loss 0.26666839 - samples/sec: 201.57 - lr: 0.100000\n",
      "2021-01-30 23:23:31,600 epoch 9 - iter 20/49 - loss 0.25468373 - samples/sec: 209.16 - lr: 0.100000\n",
      "2021-01-30 23:23:32,254 epoch 9 - iter 24/49 - loss 0.24033829 - samples/sec: 196.01 - lr: 0.100000\n",
      "2021-01-30 23:23:32,908 epoch 9 - iter 28/49 - loss 0.25332690 - samples/sec: 196.03 - lr: 0.100000\n",
      "2021-01-30 23:23:33,586 epoch 9 - iter 32/49 - loss 0.23780651 - samples/sec: 189.06 - lr: 0.100000\n",
      "2021-01-30 23:23:34,289 epoch 9 - iter 36/49 - loss 0.22761023 - samples/sec: 182.35 - lr: 0.100000\n",
      "2021-01-30 23:23:34,996 epoch 9 - iter 40/49 - loss 0.22839381 - samples/sec: 181.30 - lr: 0.100000\n",
      "2021-01-30 23:23:35,646 epoch 9 - iter 44/49 - loss 0.23329315 - samples/sec: 196.91 - lr: 0.100000\n",
      "2021-01-30 23:23:36,312 epoch 9 - iter 48/49 - loss 0.22989788 - samples/sec: 192.48 - lr: 0.100000\n",
      "2021-01-30 23:23:36,441 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:23:36,441 EPOCH 9 done: loss 0.2272 - lr 0.1000000\n",
      "2021-01-30 23:23:38,156 DEV : loss 0.08476147055625916 - score 0.9791\n",
      "2021-01-30 23:23:38,182 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:23:41,509 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:23:42,151 epoch 10 - iter 4/49 - loss 0.28156561 - samples/sec: 199.68 - lr: 0.100000\n",
      "2021-01-30 23:23:42,775 epoch 10 - iter 8/49 - loss 0.18270820 - samples/sec: 205.13 - lr: 0.100000\n",
      "2021-01-30 23:23:43,413 epoch 10 - iter 12/49 - loss 0.22101110 - samples/sec: 200.63 - lr: 0.100000\n",
      "2021-01-30 23:23:44,158 epoch 10 - iter 16/49 - loss 0.23244710 - samples/sec: 172.02 - lr: 0.100000\n",
      "2021-01-30 23:23:44,802 epoch 10 - iter 20/49 - loss 0.21746907 - samples/sec: 198.76 - lr: 0.100000\n",
      "2021-01-30 23:23:45,456 epoch 10 - iter 24/49 - loss 0.21780325 - samples/sec: 195.99 - lr: 0.100000\n",
      "2021-01-30 23:23:46,092 epoch 10 - iter 28/49 - loss 0.23763540 - samples/sec: 201.26 - lr: 0.100000\n",
      "2021-01-30 23:23:46,731 epoch 10 - iter 32/49 - loss 0.24326889 - samples/sec: 200.31 - lr: 0.100000\n",
      "2021-01-30 23:23:47,342 epoch 10 - iter 36/49 - loss 0.23045805 - samples/sec: 209.49 - lr: 0.100000\n",
      "2021-01-30 23:23:47,992 epoch 10 - iter 40/49 - loss 0.23542417 - samples/sec: 197.22 - lr: 0.100000\n",
      "2021-01-30 23:23:48,650 epoch 10 - iter 44/49 - loss 0.24710090 - samples/sec: 194.87 - lr: 0.100000\n",
      "2021-01-30 23:23:49,263 epoch 10 - iter 48/49 - loss 0.24491150 - samples/sec: 209.13 - lr: 0.100000\n",
      "2021-01-30 23:23:49,387 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:23:49,387 EPOCH 10 done: loss 0.2454 - lr 0.1000000\n",
      "2021-01-30 23:23:51,087 DEV : loss 0.0742316022515297 - score 0.987\n",
      "2021-01-30 23:23:51,113 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:23:54,405 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:23:55,069 epoch 11 - iter 4/49 - loss 0.27794021 - samples/sec: 192.77 - lr: 0.100000\n",
      "2021-01-30 23:23:55,701 epoch 11 - iter 8/49 - loss 0.22248656 - samples/sec: 202.85 - lr: 0.100000\n",
      "2021-01-30 23:23:56,305 epoch 11 - iter 12/49 - loss 0.21074726 - samples/sec: 211.92 - lr: 0.100000\n",
      "2021-01-30 23:23:56,954 epoch 11 - iter 16/49 - loss 0.20362808 - samples/sec: 197.53 - lr: 0.100000\n",
      "2021-01-30 23:23:57,615 epoch 11 - iter 20/49 - loss 0.19939443 - samples/sec: 193.65 - lr: 0.100000\n",
      "2021-01-30 23:23:58,302 epoch 11 - iter 24/49 - loss 0.18957299 - samples/sec: 186.43 - lr: 0.100000\n",
      "2021-01-30 23:23:59,010 epoch 11 - iter 28/49 - loss 0.20366469 - samples/sec: 181.04 - lr: 0.100000\n",
      "2021-01-30 23:23:59,716 epoch 11 - iter 32/49 - loss 0.19926440 - samples/sec: 181.30 - lr: 0.100000\n",
      "2021-01-30 23:24:00,345 epoch 11 - iter 36/49 - loss 0.20548593 - samples/sec: 203.50 - lr: 0.100000\n",
      "2021-01-30 23:24:00,983 epoch 11 - iter 40/49 - loss 0.20594395 - samples/sec: 200.64 - lr: 0.100000\n",
      "2021-01-30 23:24:01,612 epoch 11 - iter 44/49 - loss 0.20240200 - samples/sec: 203.81 - lr: 0.100000\n",
      "2021-01-30 23:24:02,240 epoch 11 - iter 48/49 - loss 0.20410575 - samples/sec: 203.82 - lr: 0.100000\n",
      "2021-01-30 23:24:02,370 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:02,371 EPOCH 11 done: loss 0.2016 - lr 0.1000000\n",
      "2021-01-30 23:24:04,144 DEV : loss 0.05912670120596886 - score 0.983\n",
      "2021-01-30 23:24:04,170 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:24:04,172 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:04,831 epoch 12 - iter 4/49 - loss 0.22786537 - samples/sec: 194.52 - lr: 0.100000\n",
      "2021-01-30 23:24:05,454 epoch 12 - iter 8/49 - loss 0.27827366 - samples/sec: 205.77 - lr: 0.100000\n",
      "2021-01-30 23:24:06,069 epoch 12 - iter 12/49 - loss 0.23755653 - samples/sec: 208.80 - lr: 0.100000\n",
      "2021-01-30 23:24:06,777 epoch 12 - iter 16/49 - loss 0.22641342 - samples/sec: 181.06 - lr: 0.100000\n",
      "2021-01-30 23:24:07,530 epoch 12 - iter 20/49 - loss 0.21792832 - samples/sec: 170.35 - lr: 0.100000\n",
      "2021-01-30 23:24:08,372 epoch 12 - iter 24/49 - loss 0.20859213 - samples/sec: 152.20 - lr: 0.100000\n",
      "2021-01-30 23:24:09,087 epoch 12 - iter 28/49 - loss 0.20023279 - samples/sec: 179.27 - lr: 0.100000\n",
      "2021-01-30 23:24:09,722 epoch 12 - iter 32/49 - loss 0.19851079 - samples/sec: 201.88 - lr: 0.100000\n",
      "2021-01-30 23:24:10,350 epoch 12 - iter 36/49 - loss 0.19798048 - samples/sec: 203.83 - lr: 0.100000\n",
      "2021-01-30 23:24:11,049 epoch 12 - iter 40/49 - loss 0.19837480 - samples/sec: 183.47 - lr: 0.100000\n",
      "2021-01-30 23:24:11,679 epoch 12 - iter 44/49 - loss 0.19562286 - samples/sec: 203.14 - lr: 0.100000\n",
      "2021-01-30 23:24:12,309 epoch 12 - iter 48/49 - loss 0.20001543 - samples/sec: 203.83 - lr: 0.100000\n",
      "2021-01-30 23:24:12,447 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:12,448 EPOCH 12 done: loss 0.1978 - lr 0.1000000\n",
      "2021-01-30 23:24:14,186 DEV : loss 0.05627086013555527 - score 0.989\n",
      "2021-01-30 23:24:14,212 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:24:17,517 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:18,193 epoch 13 - iter 4/49 - loss 0.09194326 - samples/sec: 189.62 - lr: 0.100000\n",
      "2021-01-30 23:24:18,848 epoch 13 - iter 8/49 - loss 0.11632499 - samples/sec: 195.73 - lr: 0.100000\n",
      "2021-01-30 23:24:19,494 epoch 13 - iter 12/49 - loss 0.11313182 - samples/sec: 198.14 - lr: 0.100000\n",
      "2021-01-30 23:24:20,166 epoch 13 - iter 16/49 - loss 0.12880188 - samples/sec: 190.76 - lr: 0.100000\n",
      "2021-01-30 23:24:20,916 epoch 13 - iter 20/49 - loss 0.13515821 - samples/sec: 170.89 - lr: 0.100000\n",
      "2021-01-30 23:24:21,612 epoch 13 - iter 24/49 - loss 0.14825323 - samples/sec: 184.17 - lr: 0.100000\n",
      "2021-01-30 23:24:22,253 epoch 13 - iter 28/49 - loss 0.15339203 - samples/sec: 200.28 - lr: 0.100000\n",
      "2021-01-30 23:24:23,042 epoch 13 - iter 32/49 - loss 0.15569295 - samples/sec: 162.23 - lr: 0.100000\n",
      "2021-01-30 23:24:23,896 epoch 13 - iter 36/49 - loss 0.15543522 - samples/sec: 149.88 - lr: 0.100000\n",
      "2021-01-30 23:24:24,587 epoch 13 - iter 40/49 - loss 0.15578228 - samples/sec: 185.24 - lr: 0.100000\n",
      "2021-01-30 23:24:25,239 epoch 13 - iter 44/49 - loss 0.16754830 - samples/sec: 197.04 - lr: 0.100000\n",
      "2021-01-30 23:24:25,892 epoch 13 - iter 48/49 - loss 0.16806497 - samples/sec: 196.32 - lr: 0.100000\n",
      "2021-01-30 23:24:26,028 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:26,029 EPOCH 13 done: loss 0.1685 - lr 0.1000000\n",
      "2021-01-30 23:24:27,805 DEV : loss 0.06355343759059906 - score 0.983\n",
      "2021-01-30 23:24:27,831 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:24:27,832 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:28,511 epoch 14 - iter 4/49 - loss 0.10876578 - samples/sec: 188.79 - lr: 0.100000\n",
      "2021-01-30 23:24:29,231 epoch 14 - iter 8/49 - loss 0.14387827 - samples/sec: 178.02 - lr: 0.100000\n",
      "2021-01-30 23:24:29,940 epoch 14 - iter 12/49 - loss 0.14690297 - samples/sec: 180.54 - lr: 0.100000\n",
      "2021-01-30 23:24:30,638 epoch 14 - iter 16/49 - loss 0.15452743 - samples/sec: 183.63 - lr: 0.100000\n",
      "2021-01-30 23:24:31,286 epoch 14 - iter 20/49 - loss 0.15229985 - samples/sec: 197.84 - lr: 0.100000\n",
      "2021-01-30 23:24:31,967 epoch 14 - iter 24/49 - loss 0.16154636 - samples/sec: 187.97 - lr: 0.100000\n",
      "2021-01-30 23:24:32,661 epoch 14 - iter 28/49 - loss 0.15878482 - samples/sec: 184.70 - lr: 0.100000\n",
      "2021-01-30 23:24:33,327 epoch 14 - iter 32/49 - loss 0.15014792 - samples/sec: 192.18 - lr: 0.100000\n",
      "2021-01-30 23:24:34,035 epoch 14 - iter 36/49 - loss 0.15247967 - samples/sec: 180.90 - lr: 0.100000\n",
      "2021-01-30 23:24:34,688 epoch 14 - iter 40/49 - loss 0.15364705 - samples/sec: 196.29 - lr: 0.100000\n",
      "2021-01-30 23:24:35,358 epoch 14 - iter 44/49 - loss 0.15600303 - samples/sec: 191.32 - lr: 0.100000\n",
      "2021-01-30 23:24:36,015 epoch 14 - iter 48/49 - loss 0.15221382 - samples/sec: 194.79 - lr: 0.100000\n",
      "2021-01-30 23:24:36,143 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:36,144 EPOCH 14 done: loss 0.1557 - lr 0.1000000\n",
      "2021-01-30 23:24:38,009 DEV : loss 0.062009356915950775 - score 0.985\n",
      "2021-01-30 23:24:38,035 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:24:38,036 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:38,694 epoch 15 - iter 4/49 - loss 0.09873772 - samples/sec: 194.82 - lr: 0.100000\n",
      "2021-01-30 23:24:39,316 epoch 15 - iter 8/49 - loss 0.12608218 - samples/sec: 206.11 - lr: 0.100000\n",
      "2021-01-30 23:24:39,943 epoch 15 - iter 12/49 - loss 0.11549278 - samples/sec: 204.80 - lr: 0.100000\n",
      "2021-01-30 23:24:40,640 epoch 15 - iter 16/49 - loss 0.14142953 - samples/sec: 184.18 - lr: 0.100000\n",
      "2021-01-30 23:24:41,292 epoch 15 - iter 20/49 - loss 0.13669153 - samples/sec: 196.62 - lr: 0.100000\n",
      "2021-01-30 23:24:41,918 epoch 15 - iter 24/49 - loss 0.13408415 - samples/sec: 204.47 - lr: 0.100000\n",
      "2021-01-30 23:24:42,736 epoch 15 - iter 28/49 - loss 0.12968377 - samples/sec: 156.68 - lr: 0.100000\n",
      "2021-01-30 23:24:43,400 epoch 15 - iter 32/49 - loss 0.12344541 - samples/sec: 193.06 - lr: 0.100000\n",
      "2021-01-30 23:24:44,018 epoch 15 - iter 36/49 - loss 0.12757365 - samples/sec: 207.46 - lr: 0.100000\n",
      "2021-01-30 23:24:44,669 epoch 15 - iter 40/49 - loss 0.13272534 - samples/sec: 196.91 - lr: 0.100000\n",
      "2021-01-30 23:24:45,368 epoch 15 - iter 44/49 - loss 0.13482687 - samples/sec: 183.13 - lr: 0.100000\n",
      "2021-01-30 23:24:46,070 epoch 15 - iter 48/49 - loss 0.13182132 - samples/sec: 182.35 - lr: 0.100000\n",
      "2021-01-30 23:24:46,206 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:46,207 EPOCH 15 done: loss 0.1313 - lr 0.1000000\n",
      "2021-01-30 23:24:47,966 DEV : loss 0.045114967972040176 - score 0.988\n",
      "2021-01-30 23:24:47,994 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:24:47,995 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:48,691 epoch 16 - iter 4/49 - loss 0.17384833 - samples/sec: 184.16 - lr: 0.100000\n",
      "2021-01-30 23:24:49,375 epoch 16 - iter 8/49 - loss 0.17650083 - samples/sec: 187.40 - lr: 0.100000\n",
      "2021-01-30 23:24:50,015 epoch 16 - iter 12/49 - loss 0.22477571 - samples/sec: 200.00 - lr: 0.100000\n",
      "2021-01-30 23:24:50,693 epoch 16 - iter 16/49 - loss 0.19522209 - samples/sec: 189.06 - lr: 0.100000\n",
      "2021-01-30 23:24:51,315 epoch 16 - iter 20/49 - loss 0.18184247 - samples/sec: 206.11 - lr: 0.100000\n",
      "2021-01-30 23:24:51,987 epoch 16 - iter 24/49 - loss 0.17774200 - samples/sec: 190.73 - lr: 0.100000\n",
      "2021-01-30 23:24:52,621 epoch 16 - iter 28/49 - loss 0.17032196 - samples/sec: 201.86 - lr: 0.100000\n",
      "2021-01-30 23:24:53,245 epoch 16 - iter 32/49 - loss 0.16390800 - samples/sec: 205.44 - lr: 0.100000\n",
      "2021-01-30 23:24:53,868 epoch 16 - iter 36/49 - loss 0.16488575 - samples/sec: 206.13 - lr: 0.100000\n",
      "2021-01-30 23:24:54,513 epoch 16 - iter 40/49 - loss 0.15829224 - samples/sec: 198.75 - lr: 0.100000\n",
      "2021-01-30 23:24:55,202 epoch 16 - iter 44/49 - loss 0.16567666 - samples/sec: 185.78 - lr: 0.100000\n",
      "2021-01-30 23:24:55,884 epoch 16 - iter 48/49 - loss 0.16864983 - samples/sec: 187.97 - lr: 0.100000\n",
      "2021-01-30 23:24:56,035 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:24:56,035 EPOCH 16 done: loss 0.1662 - lr 0.1000000\n",
      "2021-01-30 23:24:57,839 DEV : loss 0.05016002804040909 - score 0.99\n",
      "2021-01-30 23:24:57,866 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:25:01,542 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:02,218 epoch 17 - iter 4/49 - loss 0.13408482 - samples/sec: 189.91 - lr: 0.100000\n",
      "2021-01-30 23:25:02,887 epoch 17 - iter 8/49 - loss 0.11984482 - samples/sec: 191.33 - lr: 0.100000\n",
      "2021-01-30 23:25:03,535 epoch 17 - iter 12/49 - loss 0.11728527 - samples/sec: 197.53 - lr: 0.100000\n",
      "2021-01-30 23:25:04,186 epoch 17 - iter 16/49 - loss 0.12085760 - samples/sec: 196.93 - lr: 0.100000\n",
      "2021-01-30 23:25:04,852 epoch 17 - iter 20/49 - loss 0.15115347 - samples/sec: 192.48 - lr: 0.100000\n",
      "2021-01-30 23:25:05,514 epoch 17 - iter 24/49 - loss 0.13838236 - samples/sec: 193.65 - lr: 0.100000\n",
      "2021-01-30 23:25:06,176 epoch 17 - iter 28/49 - loss 0.13397535 - samples/sec: 193.94 - lr: 0.100000\n",
      "2021-01-30 23:25:06,879 epoch 17 - iter 32/49 - loss 0.12889479 - samples/sec: 182.60 - lr: 0.100000\n",
      "2021-01-30 23:25:07,563 epoch 17 - iter 36/49 - loss 0.12641804 - samples/sec: 187.12 - lr: 0.100000\n",
      "2021-01-30 23:25:08,232 epoch 17 - iter 40/49 - loss 0.13043044 - samples/sec: 191.63 - lr: 0.100000\n",
      "2021-01-30 23:25:08,859 epoch 17 - iter 44/49 - loss 0.13229918 - samples/sec: 204.48 - lr: 0.100000\n",
      "2021-01-30 23:25:09,492 epoch 17 - iter 48/49 - loss 0.13253817 - samples/sec: 202.53 - lr: 0.100000\n",
      "2021-01-30 23:25:09,624 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:09,625 EPOCH 17 done: loss 0.1319 - lr 0.1000000\n",
      "2021-01-30 23:25:11,372 DEV : loss 0.04806772246956825 - score 0.987\n",
      "2021-01-30 23:25:11,400 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:25:11,401 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:12,061 epoch 18 - iter 4/49 - loss 0.13484585 - samples/sec: 194.53 - lr: 0.100000\n",
      "2021-01-30 23:25:12,754 epoch 18 - iter 8/49 - loss 0.14368695 - samples/sec: 184.97 - lr: 0.100000\n",
      "2021-01-30 23:25:13,438 epoch 18 - iter 12/49 - loss 0.13666455 - samples/sec: 187.41 - lr: 0.100000\n",
      "2021-01-30 23:25:14,055 epoch 18 - iter 16/49 - loss 0.12535806 - samples/sec: 207.79 - lr: 0.100000\n",
      "2021-01-30 23:25:14,701 epoch 18 - iter 20/49 - loss 0.11803920 - samples/sec: 198.45 - lr: 0.100000\n",
      "2021-01-30 23:25:15,394 epoch 18 - iter 24/49 - loss 0.12844051 - samples/sec: 184.70 - lr: 0.100000\n",
      "2021-01-30 23:25:16,021 epoch 18 - iter 28/49 - loss 0.12311603 - samples/sec: 204.49 - lr: 0.100000\n",
      "2021-01-30 23:25:16,666 epoch 18 - iter 32/49 - loss 0.11887876 - samples/sec: 198.76 - lr: 0.100000\n",
      "2021-01-30 23:25:17,309 epoch 18 - iter 36/49 - loss 0.11958380 - samples/sec: 199.06 - lr: 0.100000\n",
      "2021-01-30 23:25:18,006 epoch 18 - iter 40/49 - loss 0.11893151 - samples/sec: 184.17 - lr: 0.100000\n",
      "2021-01-30 23:25:18,677 epoch 18 - iter 44/49 - loss 0.11273124 - samples/sec: 191.03 - lr: 0.100000\n",
      "2021-01-30 23:25:19,361 epoch 18 - iter 48/49 - loss 0.11474284 - samples/sec: 187.13 - lr: 0.100000\n",
      "2021-01-30 23:25:19,495 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:19,495 EPOCH 18 done: loss 0.1225 - lr 0.1000000\n",
      "2021-01-30 23:25:21,277 DEV : loss 0.03790959343314171 - score 0.9831\n",
      "2021-01-30 23:25:21,303 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:25:21,305 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:21,962 epoch 19 - iter 4/49 - loss 0.15596461 - samples/sec: 195.11 - lr: 0.100000\n",
      "2021-01-30 23:25:22,631 epoch 19 - iter 8/49 - loss 0.18317291 - samples/sec: 191.57 - lr: 0.100000\n",
      "2021-01-30 23:25:23,301 epoch 19 - iter 12/49 - loss 0.14771670 - samples/sec: 191.33 - lr: 0.100000\n",
      "2021-01-30 23:25:23,954 epoch 19 - iter 16/49 - loss 0.13248514 - samples/sec: 196.32 - lr: 0.100000\n",
      "2021-01-30 23:25:24,649 epoch 19 - iter 20/49 - loss 0.12647649 - samples/sec: 184.17 - lr: 0.100000\n",
      "2021-01-30 23:25:25,293 epoch 19 - iter 24/49 - loss 0.15287452 - samples/sec: 198.75 - lr: 0.100000\n",
      "2021-01-30 23:25:25,922 epoch 19 - iter 28/49 - loss 0.14202012 - samples/sec: 204.02 - lr: 0.100000\n",
      "2021-01-30 23:25:26,609 epoch 19 - iter 32/49 - loss 0.13523597 - samples/sec: 186.58 - lr: 0.100000\n",
      "2021-01-30 23:25:27,260 epoch 19 - iter 36/49 - loss 0.13445393 - samples/sec: 197.14 - lr: 0.100000\n",
      "2021-01-30 23:25:27,907 epoch 19 - iter 40/49 - loss 0.12964849 - samples/sec: 198.12 - lr: 0.100000\n",
      "2021-01-30 23:25:28,672 epoch 19 - iter 44/49 - loss 0.13483113 - samples/sec: 167.98 - lr: 0.100000\n",
      "2021-01-30 23:25:29,469 epoch 19 - iter 48/49 - loss 0.12837945 - samples/sec: 160.46 - lr: 0.100000\n",
      "2021-01-30 23:25:29,633 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:29,634 EPOCH 19 done: loss 0.1264 - lr 0.1000000\n",
      "2021-01-30 23:25:31,379 DEV : loss 0.04612664505839348 - score 0.987\n",
      "2021-01-30 23:25:31,407 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:25:31,408 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:32,046 epoch 20 - iter 4/49 - loss 0.07020646 - samples/sec: 201.24 - lr: 0.100000\n",
      "2021-01-30 23:25:32,686 epoch 20 - iter 8/49 - loss 0.08662060 - samples/sec: 200.62 - lr: 0.100000\n",
      "2021-01-30 23:25:33,348 epoch 20 - iter 12/49 - loss 0.10355991 - samples/sec: 193.93 - lr: 0.100000\n",
      "2021-01-30 23:25:34,058 epoch 20 - iter 16/49 - loss 0.11265995 - samples/sec: 180.70 - lr: 0.100000\n",
      "2021-01-30 23:25:34,720 epoch 20 - iter 20/49 - loss 0.10867227 - samples/sec: 193.66 - lr: 0.100000\n",
      "2021-01-30 23:25:35,444 epoch 20 - iter 24/49 - loss 0.09834571 - samples/sec: 177.04 - lr: 0.100000\n",
      "2021-01-30 23:25:36,133 epoch 20 - iter 28/49 - loss 0.10547077 - samples/sec: 186.03 - lr: 0.100000\n",
      "2021-01-30 23:25:36,799 epoch 20 - iter 32/49 - loss 0.11051605 - samples/sec: 192.47 - lr: 0.100000\n",
      "2021-01-30 23:25:37,441 epoch 20 - iter 36/49 - loss 0.10640307 - samples/sec: 199.68 - lr: 0.100000\n",
      "2021-01-30 23:25:38,128 epoch 20 - iter 40/49 - loss 0.11726210 - samples/sec: 186.57 - lr: 0.100000\n",
      "2021-01-30 23:25:38,806 epoch 20 - iter 44/49 - loss 0.11335881 - samples/sec: 188.87 - lr: 0.100000\n",
      "2021-01-30 23:25:39,429 epoch 20 - iter 48/49 - loss 0.11074503 - samples/sec: 205.78 - lr: 0.100000\n",
      "2021-01-30 23:25:39,562 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:39,562 EPOCH 20 done: loss 0.1094 - lr 0.1000000\n",
      "2021-01-30 23:25:41,409 DEV : loss 0.03551793098449707 - score 0.985\n",
      "Epoch    20: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2021-01-30 23:25:41,436 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:25:41,437 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:42,079 epoch 21 - iter 4/49 - loss 0.04757947 - samples/sec: 199.69 - lr: 0.050000\n",
      "2021-01-30 23:25:42,756 epoch 21 - iter 8/49 - loss 0.05471039 - samples/sec: 189.08 - lr: 0.050000\n",
      "2021-01-30 23:25:43,467 epoch 21 - iter 12/49 - loss 0.06999328 - samples/sec: 180.01 - lr: 0.050000\n",
      "2021-01-30 23:25:44,103 epoch 21 - iter 16/49 - loss 0.08287209 - samples/sec: 201.27 - lr: 0.050000\n",
      "2021-01-30 23:25:44,802 epoch 21 - iter 20/49 - loss 0.08166723 - samples/sec: 183.39 - lr: 0.050000\n",
      "2021-01-30 23:25:45,459 epoch 21 - iter 24/49 - loss 0.08561181 - samples/sec: 195.12 - lr: 0.050000\n",
      "2021-01-30 23:25:46,229 epoch 21 - iter 28/49 - loss 0.08969639 - samples/sec: 166.44 - lr: 0.050000\n",
      "2021-01-30 23:25:46,869 epoch 21 - iter 32/49 - loss 0.09394444 - samples/sec: 200.02 - lr: 0.050000\n",
      "2021-01-30 23:25:47,533 epoch 21 - iter 36/49 - loss 0.09077649 - samples/sec: 192.91 - lr: 0.050000\n",
      "2021-01-30 23:25:48,188 epoch 21 - iter 40/49 - loss 0.09561868 - samples/sec: 195.56 - lr: 0.050000\n",
      "2021-01-30 23:25:48,861 epoch 21 - iter 44/49 - loss 0.09416071 - samples/sec: 190.48 - lr: 0.050000\n",
      "2021-01-30 23:25:49,502 epoch 21 - iter 48/49 - loss 0.09239919 - samples/sec: 200.00 - lr: 0.050000\n",
      "2021-01-30 23:25:49,637 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:49,638 EPOCH 21 done: loss 0.0911 - lr 0.0500000\n",
      "2021-01-30 23:25:51,508 DEV : loss 0.04033815115690231 - score 0.989\n",
      "2021-01-30 23:25:51,536 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:25:51,537 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:52,224 epoch 22 - iter 4/49 - loss 0.07560027 - samples/sec: 186.52 - lr: 0.050000\n",
      "2021-01-30 23:25:52,872 epoch 22 - iter 8/49 - loss 0.11493778 - samples/sec: 197.52 - lr: 0.050000\n",
      "2021-01-30 23:25:53,516 epoch 22 - iter 12/49 - loss 0.11809707 - samples/sec: 198.99 - lr: 0.050000\n",
      "2021-01-30 23:25:54,220 epoch 22 - iter 16/49 - loss 0.11315544 - samples/sec: 182.05 - lr: 0.050000\n",
      "2021-01-30 23:25:54,860 epoch 22 - iter 20/49 - loss 0.10839024 - samples/sec: 200.30 - lr: 0.050000\n",
      "2021-01-30 23:25:55,568 epoch 22 - iter 24/49 - loss 0.10496115 - samples/sec: 181.00 - lr: 0.050000\n",
      "2021-01-30 23:25:56,314 epoch 22 - iter 28/49 - loss 0.10582934 - samples/sec: 171.58 - lr: 0.050000\n",
      "2021-01-30 23:25:56,989 epoch 22 - iter 32/49 - loss 0.10629951 - samples/sec: 189.42 - lr: 0.050000\n",
      "2021-01-30 23:25:57,704 epoch 22 - iter 36/49 - loss 0.10484051 - samples/sec: 179.48 - lr: 0.050000\n",
      "2021-01-30 23:25:58,374 epoch 22 - iter 40/49 - loss 0.10416720 - samples/sec: 190.89 - lr: 0.050000\n",
      "2021-01-30 23:25:59,043 epoch 22 - iter 44/49 - loss 0.10882147 - samples/sec: 191.77 - lr: 0.050000\n",
      "2021-01-30 23:25:59,703 epoch 22 - iter 48/49 - loss 0.10860206 - samples/sec: 194.19 - lr: 0.050000\n",
      "2021-01-30 23:25:59,867 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:25:59,868 EPOCH 22 done: loss 0.1074 - lr 0.0500000\n",
      "2021-01-30 23:26:01,634 DEV : loss 0.0352325513958931 - score 0.988\n",
      "2021-01-30 23:26:01,659 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:26:01,661 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:02,329 epoch 23 - iter 4/49 - loss 0.07336283 - samples/sec: 192.46 - lr: 0.050000\n",
      "2021-01-30 23:26:03,016 epoch 23 - iter 8/49 - loss 0.06889093 - samples/sec: 186.41 - lr: 0.050000\n",
      "2021-01-30 23:26:03,715 epoch 23 - iter 12/49 - loss 0.09435548 - samples/sec: 183.35 - lr: 0.050000\n",
      "2021-01-30 23:26:04,476 epoch 23 - iter 16/49 - loss 0.08607094 - samples/sec: 168.39 - lr: 0.050000\n",
      "2021-01-30 23:26:05,136 epoch 23 - iter 20/49 - loss 0.08846079 - samples/sec: 194.24 - lr: 0.050000\n",
      "2021-01-30 23:26:05,792 epoch 23 - iter 24/49 - loss 0.08556743 - samples/sec: 195.07 - lr: 0.050000\n",
      "2021-01-30 23:26:06,483 epoch 23 - iter 28/49 - loss 0.08200916 - samples/sec: 185.48 - lr: 0.050000\n",
      "2021-01-30 23:26:07,158 epoch 23 - iter 32/49 - loss 0.08207654 - samples/sec: 189.59 - lr: 0.050000\n",
      "2021-01-30 23:26:07,845 epoch 23 - iter 36/49 - loss 0.07978788 - samples/sec: 186.84 - lr: 0.050000\n",
      "2021-01-30 23:26:08,530 epoch 23 - iter 40/49 - loss 0.08235729 - samples/sec: 187.10 - lr: 0.050000\n",
      "2021-01-30 23:26:09,177 epoch 23 - iter 44/49 - loss 0.08230753 - samples/sec: 198.14 - lr: 0.050000\n",
      "2021-01-30 23:26:09,804 epoch 23 - iter 48/49 - loss 0.08075483 - samples/sec: 204.46 - lr: 0.050000\n",
      "2021-01-30 23:26:09,950 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:09,951 EPOCH 23 done: loss 0.0812 - lr 0.0500000\n",
      "2021-01-30 23:26:11,861 DEV : loss 0.03287301957607269 - score 0.991\n",
      "2021-01-30 23:26:11,888 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:26:15,362 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:16,016 epoch 24 - iter 4/49 - loss 0.09290117 - samples/sec: 196.01 - lr: 0.050000\n",
      "2021-01-30 23:26:16,658 epoch 24 - iter 8/49 - loss 0.11171833 - samples/sec: 199.70 - lr: 0.050000\n",
      "2021-01-30 23:26:17,331 epoch 24 - iter 12/49 - loss 0.08729829 - samples/sec: 190.74 - lr: 0.050000\n",
      "2021-01-30 23:26:18,036 epoch 24 - iter 16/49 - loss 0.08402261 - samples/sec: 181.83 - lr: 0.050000\n",
      "2021-01-30 23:26:18,722 epoch 24 - iter 20/49 - loss 0.08927627 - samples/sec: 186.86 - lr: 0.050000\n",
      "2021-01-30 23:26:19,372 epoch 24 - iter 24/49 - loss 0.08559020 - samples/sec: 197.24 - lr: 0.050000\n",
      "2021-01-30 23:26:20,008 epoch 24 - iter 28/49 - loss 0.08170663 - samples/sec: 201.58 - lr: 0.050000\n",
      "2021-01-30 23:26:20,631 epoch 24 - iter 32/49 - loss 0.08742862 - samples/sec: 205.46 - lr: 0.050000\n",
      "2021-01-30 23:26:21,309 epoch 24 - iter 36/49 - loss 0.09509068 - samples/sec: 189.06 - lr: 0.050000\n",
      "2021-01-30 23:26:21,960 epoch 24 - iter 40/49 - loss 0.09061965 - samples/sec: 196.93 - lr: 0.050000\n",
      "2021-01-30 23:26:22,606 epoch 24 - iter 44/49 - loss 0.08619356 - samples/sec: 198.14 - lr: 0.050000\n",
      "2021-01-30 23:26:23,303 epoch 24 - iter 48/49 - loss 0.08892545 - samples/sec: 183.64 - lr: 0.050000\n",
      "2021-01-30 23:26:23,436 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:23,436 EPOCH 24 done: loss 0.0881 - lr 0.0500000\n",
      "2021-01-30 23:26:25,135 DEV : loss 0.03307567536830902 - score 0.99\n",
      "2021-01-30 23:26:25,163 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:26:25,164 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:25,842 epoch 25 - iter 4/49 - loss 0.14362174 - samples/sec: 189.54 - lr: 0.050000\n",
      "2021-01-30 23:26:26,542 epoch 25 - iter 8/49 - loss 0.15547067 - samples/sec: 182.86 - lr: 0.050000\n",
      "2021-01-30 23:26:27,249 epoch 25 - iter 12/49 - loss 0.12914429 - samples/sec: 181.30 - lr: 0.050000\n",
      "2021-01-30 23:26:27,912 epoch 25 - iter 16/49 - loss 0.10878837 - samples/sec: 193.36 - lr: 0.050000\n",
      "2021-01-30 23:26:28,620 epoch 25 - iter 20/49 - loss 0.10244945 - samples/sec: 181.05 - lr: 0.050000\n",
      "2021-01-30 23:26:29,310 epoch 25 - iter 24/49 - loss 0.09814132 - samples/sec: 185.51 - lr: 0.050000\n",
      "2021-01-30 23:26:29,970 epoch 25 - iter 28/49 - loss 0.09297786 - samples/sec: 193.94 - lr: 0.050000\n",
      "2021-01-30 23:26:30,610 epoch 25 - iter 32/49 - loss 0.09047747 - samples/sec: 200.30 - lr: 0.050000\n",
      "2021-01-30 23:26:31,332 epoch 25 - iter 36/49 - loss 0.09454330 - samples/sec: 177.53 - lr: 0.050000\n",
      "2021-01-30 23:26:31,999 epoch 25 - iter 40/49 - loss 0.09256398 - samples/sec: 192.20 - lr: 0.050000\n",
      "2021-01-30 23:26:32,648 epoch 25 - iter 44/49 - loss 0.09131405 - samples/sec: 197.84 - lr: 0.050000\n",
      "2021-01-30 23:26:33,288 epoch 25 - iter 48/49 - loss 0.09478794 - samples/sec: 200.31 - lr: 0.050000\n",
      "2021-01-30 23:26:33,426 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:33,427 EPOCH 25 done: loss 0.0971 - lr 0.0500000\n",
      "2021-01-30 23:26:35,247 DEV : loss 0.0465129129588604 - score 0.991\n",
      "2021-01-30 23:26:35,274 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:26:35,276 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:36,005 epoch 26 - iter 4/49 - loss 0.10812247 - samples/sec: 176.30 - lr: 0.050000\n",
      "2021-01-30 23:26:36,635 epoch 26 - iter 8/49 - loss 0.11132976 - samples/sec: 203.50 - lr: 0.050000\n",
      "2021-01-30 23:26:37,273 epoch 26 - iter 12/49 - loss 0.08960521 - samples/sec: 200.94 - lr: 0.050000\n",
      "2021-01-30 23:26:37,934 epoch 26 - iter 16/49 - loss 0.09085019 - samples/sec: 193.94 - lr: 0.050000\n",
      "2021-01-30 23:26:38,588 epoch 26 - iter 20/49 - loss 0.08877003 - samples/sec: 196.03 - lr: 0.050000\n",
      "2021-01-30 23:26:39,269 epoch 26 - iter 24/49 - loss 0.09342151 - samples/sec: 187.95 - lr: 0.050000\n",
      "2021-01-30 23:26:39,927 epoch 26 - iter 28/49 - loss 0.09301637 - samples/sec: 194.51 - lr: 0.050000\n",
      "2021-01-30 23:26:40,650 epoch 26 - iter 32/49 - loss 0.09754139 - samples/sec: 177.29 - lr: 0.050000\n",
      "2021-01-30 23:26:41,297 epoch 26 - iter 36/49 - loss 0.09881679 - samples/sec: 198.12 - lr: 0.050000\n",
      "2021-01-30 23:26:41,951 epoch 26 - iter 40/49 - loss 0.09796737 - samples/sec: 196.02 - lr: 0.050000\n",
      "2021-01-30 23:26:42,650 epoch 26 - iter 44/49 - loss 0.10005324 - samples/sec: 183.60 - lr: 0.050000\n",
      "2021-01-30 23:26:43,296 epoch 26 - iter 48/49 - loss 0.09707602 - samples/sec: 198.44 - lr: 0.050000\n",
      "2021-01-30 23:26:43,424 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:43,424 EPOCH 26 done: loss 0.0975 - lr 0.0500000\n",
      "2021-01-30 23:26:45,211 DEV : loss 0.031111037358641624 - score 0.989\n",
      "2021-01-30 23:26:45,238 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:26:45,240 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:45,904 epoch 27 - iter 4/49 - loss 0.05528790 - samples/sec: 193.48 - lr: 0.050000\n",
      "2021-01-30 23:26:46,581 epoch 27 - iter 8/49 - loss 0.08658481 - samples/sec: 189.25 - lr: 0.050000\n",
      "2021-01-30 23:26:47,232 epoch 27 - iter 12/49 - loss 0.07016955 - samples/sec: 197.20 - lr: 0.050000\n",
      "2021-01-30 23:26:47,966 epoch 27 - iter 16/49 - loss 0.06806575 - samples/sec: 174.59 - lr: 0.050000\n",
      "2021-01-30 23:26:48,609 epoch 27 - iter 20/49 - loss 0.07189218 - samples/sec: 199.21 - lr: 0.050000\n",
      "2021-01-30 23:26:49,281 epoch 27 - iter 24/49 - loss 0.07342040 - samples/sec: 191.02 - lr: 0.050000\n",
      "2021-01-30 23:26:49,984 epoch 27 - iter 28/49 - loss 0.07858149 - samples/sec: 182.32 - lr: 0.050000\n",
      "2021-01-30 23:26:50,654 epoch 27 - iter 32/49 - loss 0.08465149 - samples/sec: 191.32 - lr: 0.050000\n",
      "2021-01-30 23:26:51,367 epoch 27 - iter 36/49 - loss 0.07939773 - samples/sec: 179.71 - lr: 0.050000\n",
      "2021-01-30 23:26:52,015 epoch 27 - iter 40/49 - loss 0.08470340 - samples/sec: 197.78 - lr: 0.050000\n",
      "2021-01-30 23:26:52,646 epoch 27 - iter 44/49 - loss 0.08317307 - samples/sec: 202.84 - lr: 0.050000\n",
      "2021-01-30 23:26:53,288 epoch 27 - iter 48/49 - loss 0.08307148 - samples/sec: 199.98 - lr: 0.050000\n",
      "2021-01-30 23:26:53,427 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:53,427 EPOCH 27 done: loss 0.0820 - lr 0.0500000\n",
      "2021-01-30 23:26:55,217 DEV : loss 0.028597040101885796 - score 0.991\n",
      "2021-01-30 23:26:55,244 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:26:58,759 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:26:59,420 epoch 28 - iter 4/49 - loss 0.10007346 - samples/sec: 193.95 - lr: 0.050000\n",
      "2021-01-30 23:27:00,058 epoch 28 - iter 8/49 - loss 0.10499951 - samples/sec: 200.60 - lr: 0.050000\n",
      "2021-01-30 23:27:00,732 epoch 28 - iter 12/49 - loss 0.08723934 - samples/sec: 190.16 - lr: 0.050000\n",
      "2021-01-30 23:27:01,424 epoch 28 - iter 16/49 - loss 0.09459548 - samples/sec: 185.24 - lr: 0.050000\n",
      "2021-01-30 23:27:02,072 epoch 28 - iter 20/49 - loss 0.09297230 - samples/sec: 197.52 - lr: 0.050000\n",
      "2021-01-30 23:27:02,764 epoch 28 - iter 24/49 - loss 0.09170998 - samples/sec: 185.47 - lr: 0.050000\n",
      "2021-01-30 23:27:03,409 epoch 28 - iter 28/49 - loss 0.08590440 - samples/sec: 198.45 - lr: 0.050000\n",
      "2021-01-30 23:27:04,097 epoch 28 - iter 32/49 - loss 0.08605529 - samples/sec: 186.30 - lr: 0.050000\n",
      "2021-01-30 23:27:04,736 epoch 28 - iter 36/49 - loss 0.08507849 - samples/sec: 200.62 - lr: 0.050000\n",
      "2021-01-30 23:27:05,385 epoch 28 - iter 40/49 - loss 0.09060429 - samples/sec: 197.19 - lr: 0.050000\n",
      "2021-01-30 23:27:06,083 epoch 28 - iter 44/49 - loss 0.08628312 - samples/sec: 183.65 - lr: 0.050000\n",
      "2021-01-30 23:27:06,722 epoch 28 - iter 48/49 - loss 0.08302095 - samples/sec: 200.60 - lr: 0.050000\n",
      "2021-01-30 23:27:06,856 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:06,856 EPOCH 28 done: loss 0.0819 - lr 0.0500000\n",
      "2021-01-30 23:27:08,632 DEV : loss 0.029941432178020477 - score 0.993\n",
      "2021-01-30 23:27:08,659 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:27:12,131 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:12,794 epoch 29 - iter 4/49 - loss 0.09633100 - samples/sec: 193.85 - lr: 0.050000\n",
      "2021-01-30 23:27:13,464 epoch 29 - iter 8/49 - loss 0.08441266 - samples/sec: 191.31 - lr: 0.050000\n",
      "2021-01-30 23:27:14,120 epoch 29 - iter 12/49 - loss 0.09470093 - samples/sec: 195.42 - lr: 0.050000\n",
      "2021-01-30 23:27:14,775 epoch 29 - iter 16/49 - loss 0.08621062 - samples/sec: 195.38 - lr: 0.050000\n",
      "2021-01-30 23:27:15,497 epoch 29 - iter 20/49 - loss 0.07772063 - samples/sec: 177.76 - lr: 0.050000\n",
      "2021-01-30 23:27:16,140 epoch 29 - iter 24/49 - loss 0.09007567 - samples/sec: 199.35 - lr: 0.050000\n",
      "2021-01-30 23:27:16,780 epoch 29 - iter 28/49 - loss 0.09730423 - samples/sec: 199.97 - lr: 0.050000\n",
      "2021-01-30 23:27:17,446 epoch 29 - iter 32/49 - loss 0.09080729 - samples/sec: 192.76 - lr: 0.050000\n",
      "2021-01-30 23:27:18,055 epoch 29 - iter 36/49 - loss 0.08918972 - samples/sec: 210.85 - lr: 0.050000\n",
      "2021-01-30 23:27:18,695 epoch 29 - iter 40/49 - loss 0.08594103 - samples/sec: 200.31 - lr: 0.050000\n",
      "2021-01-30 23:27:19,369 epoch 29 - iter 44/49 - loss 0.08199203 - samples/sec: 190.18 - lr: 0.050000\n",
      "2021-01-30 23:27:20,068 epoch 29 - iter 48/49 - loss 0.07886591 - samples/sec: 183.36 - lr: 0.050000\n",
      "2021-01-30 23:27:20,198 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:20,198 EPOCH 29 done: loss 0.0776 - lr 0.0500000\n",
      "2021-01-30 23:27:21,967 DEV : loss 0.035040829330682755 - score 0.989\n",
      "2021-01-30 23:27:21,995 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:27:21,996 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:22,659 epoch 30 - iter 4/49 - loss 0.02025408 - samples/sec: 193.32 - lr: 0.050000\n",
      "2021-01-30 23:27:23,320 epoch 30 - iter 8/49 - loss 0.07948646 - samples/sec: 193.64 - lr: 0.050000\n",
      "2021-01-30 23:27:23,984 epoch 30 - iter 12/49 - loss 0.06491830 - samples/sec: 193.04 - lr: 0.050000\n",
      "2021-01-30 23:27:24,641 epoch 30 - iter 16/49 - loss 0.05794805 - samples/sec: 195.11 - lr: 0.050000\n",
      "2021-01-30 23:27:25,254 epoch 30 - iter 20/49 - loss 0.06258988 - samples/sec: 209.46 - lr: 0.050000\n",
      "2021-01-30 23:27:25,865 epoch 30 - iter 24/49 - loss 0.06257550 - samples/sec: 209.84 - lr: 0.050000\n",
      "2021-01-30 23:27:26,518 epoch 30 - iter 28/49 - loss 0.06112110 - samples/sec: 196.01 - lr: 0.050000\n",
      "2021-01-30 23:27:27,169 epoch 30 - iter 32/49 - loss 0.06499366 - samples/sec: 196.91 - lr: 0.050000\n",
      "2021-01-30 23:27:27,795 epoch 30 - iter 36/49 - loss 0.07379961 - samples/sec: 204.80 - lr: 0.050000\n",
      "2021-01-30 23:27:28,451 epoch 30 - iter 40/49 - loss 0.07945615 - samples/sec: 195.42 - lr: 0.050000\n",
      "2021-01-30 23:27:29,132 epoch 30 - iter 44/49 - loss 0.08704598 - samples/sec: 188.51 - lr: 0.050000\n",
      "2021-01-30 23:27:29,737 epoch 30 - iter 48/49 - loss 0.08794724 - samples/sec: 211.59 - lr: 0.050000\n",
      "2021-01-30 23:27:29,864 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:29,865 EPOCH 30 done: loss 0.0876 - lr 0.0500000\n",
      "2021-01-30 23:27:31,588 DEV : loss 0.03432858735322952 - score 0.991\n",
      "2021-01-30 23:27:31,615 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:27:31,617 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:32,263 epoch 31 - iter 4/49 - loss 0.02665216 - samples/sec: 198.40 - lr: 0.050000\n",
      "2021-01-30 23:27:32,899 epoch 31 - iter 8/49 - loss 0.05918187 - samples/sec: 201.58 - lr: 0.050000\n",
      "2021-01-30 23:27:33,563 epoch 31 - iter 12/49 - loss 0.08495923 - samples/sec: 192.91 - lr: 0.050000\n",
      "2021-01-30 23:27:34,206 epoch 31 - iter 16/49 - loss 0.08041942 - samples/sec: 199.06 - lr: 0.050000\n",
      "2021-01-30 23:27:34,842 epoch 31 - iter 20/49 - loss 0.07962003 - samples/sec: 201.56 - lr: 0.050000\n",
      "2021-01-30 23:27:35,495 epoch 31 - iter 24/49 - loss 0.07123160 - samples/sec: 196.00 - lr: 0.050000\n",
      "2021-01-30 23:27:36,192 epoch 31 - iter 28/49 - loss 0.06537840 - samples/sec: 184.14 - lr: 0.050000\n",
      "2021-01-30 23:27:36,853 epoch 31 - iter 32/49 - loss 0.08122690 - samples/sec: 193.94 - lr: 0.050000\n",
      "2021-01-30 23:27:37,505 epoch 31 - iter 36/49 - loss 0.08041295 - samples/sec: 196.32 - lr: 0.050000\n",
      "2021-01-30 23:27:38,173 epoch 31 - iter 40/49 - loss 0.08197404 - samples/sec: 191.91 - lr: 0.050000\n",
      "2021-01-30 23:27:38,829 epoch 31 - iter 44/49 - loss 0.08710446 - samples/sec: 195.36 - lr: 0.050000\n",
      "2021-01-30 23:27:39,528 epoch 31 - iter 48/49 - loss 0.08880516 - samples/sec: 183.36 - lr: 0.050000\n",
      "2021-01-30 23:27:39,657 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:39,657 EPOCH 31 done: loss 0.0882 - lr 0.0500000\n",
      "2021-01-30 23:27:41,667 DEV : loss 0.029697012156248093 - score 0.989\n",
      "2021-01-30 23:27:41,693 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:27:41,695 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:42,339 epoch 32 - iter 4/49 - loss 0.07195830 - samples/sec: 199.04 - lr: 0.050000\n",
      "2021-01-30 23:27:43,025 epoch 32 - iter 8/49 - loss 0.05677328 - samples/sec: 186.57 - lr: 0.050000\n",
      "2021-01-30 23:27:43,673 epoch 32 - iter 12/49 - loss 0.06779672 - samples/sec: 197.82 - lr: 0.050000\n",
      "2021-01-30 23:27:44,340 epoch 32 - iter 16/49 - loss 0.07275682 - samples/sec: 192.46 - lr: 0.050000\n",
      "2021-01-30 23:27:44,977 epoch 32 - iter 20/49 - loss 0.06708421 - samples/sec: 200.93 - lr: 0.050000\n",
      "2021-01-30 23:27:45,651 epoch 32 - iter 24/49 - loss 0.07039890 - samples/sec: 190.19 - lr: 0.050000\n",
      "2021-01-30 23:27:46,355 epoch 32 - iter 28/49 - loss 0.07224368 - samples/sec: 182.07 - lr: 0.050000\n",
      "2021-01-30 23:27:47,055 epoch 32 - iter 32/49 - loss 0.06517422 - samples/sec: 183.52 - lr: 0.050000\n",
      "2021-01-30 23:27:47,733 epoch 32 - iter 36/49 - loss 0.07674740 - samples/sec: 188.97 - lr: 0.050000\n",
      "2021-01-30 23:27:48,427 epoch 32 - iter 40/49 - loss 0.08108295 - samples/sec: 184.69 - lr: 0.050000\n",
      "2021-01-30 23:27:49,067 epoch 32 - iter 44/49 - loss 0.08055287 - samples/sec: 200.31 - lr: 0.050000\n",
      "2021-01-30 23:27:49,710 epoch 32 - iter 48/49 - loss 0.07970701 - samples/sec: 199.04 - lr: 0.050000\n",
      "2021-01-30 23:27:49,844 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:49,846 EPOCH 32 done: loss 0.0787 - lr 0.0500000\n",
      "2021-01-30 23:27:51,880 DEV : loss 0.029899822548031807 - score 0.991\n",
      "Epoch    32: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2021-01-30 23:27:51,908 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:27:51,909 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:27:52,564 epoch 33 - iter 4/49 - loss 0.11508816 - samples/sec: 195.71 - lr: 0.025000\n",
      "2021-01-30 23:27:53,279 epoch 33 - iter 8/49 - loss 0.09259802 - samples/sec: 179.01 - lr: 0.025000\n",
      "2021-01-30 23:27:53,911 epoch 33 - iter 12/49 - loss 0.08959607 - samples/sec: 202.85 - lr: 0.025000\n",
      "2021-01-30 23:27:54,541 epoch 33 - iter 16/49 - loss 0.08454603 - samples/sec: 203.50 - lr: 0.025000\n",
      "2021-01-30 23:27:55,176 epoch 33 - iter 20/49 - loss 0.08778605 - samples/sec: 201.54 - lr: 0.025000\n",
      "2021-01-30 23:27:55,859 epoch 33 - iter 24/49 - loss 0.08624502 - samples/sec: 188.15 - lr: 0.025000\n",
      "2021-01-30 23:27:56,571 epoch 33 - iter 28/49 - loss 0.09107411 - samples/sec: 180.01 - lr: 0.025000\n",
      "2021-01-30 23:27:57,260 epoch 33 - iter 32/49 - loss 0.08723716 - samples/sec: 186.05 - lr: 0.025000\n",
      "2021-01-30 23:27:57,909 epoch 33 - iter 36/49 - loss 0.08282539 - samples/sec: 197.53 - lr: 0.025000\n",
      "2021-01-30 23:27:58,570 epoch 33 - iter 40/49 - loss 0.08579938 - samples/sec: 194.24 - lr: 0.025000\n",
      "2021-01-30 23:27:59,233 epoch 33 - iter 44/49 - loss 0.08268088 - samples/sec: 193.34 - lr: 0.025000\n",
      "2021-01-30 23:27:59,923 epoch 33 - iter 48/49 - loss 0.07896363 - samples/sec: 186.06 - lr: 0.025000\n",
      "2021-01-30 23:28:00,053 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:00,053 EPOCH 33 done: loss 0.0777 - lr 0.0250000\n",
      "2021-01-30 23:28:02,012 DEV : loss 0.027515677735209465 - score 0.993\n",
      "2021-01-30 23:28:02,039 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:28:05,490 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:06,145 epoch 34 - iter 4/49 - loss 0.06033373 - samples/sec: 195.72 - lr: 0.025000\n",
      "2021-01-30 23:28:06,806 epoch 34 - iter 8/49 - loss 0.05240533 - samples/sec: 194.07 - lr: 0.025000\n",
      "2021-01-30 23:28:07,427 epoch 34 - iter 12/49 - loss 0.07424096 - samples/sec: 206.13 - lr: 0.025000\n",
      "2021-01-30 23:28:08,091 epoch 34 - iter 16/49 - loss 0.07356746 - samples/sec: 193.06 - lr: 0.025000\n",
      "2021-01-30 23:28:08,758 epoch 34 - iter 20/49 - loss 0.06663426 - samples/sec: 191.83 - lr: 0.025000\n",
      "2021-01-30 23:28:09,420 epoch 34 - iter 24/49 - loss 0.07075292 - samples/sec: 193.35 - lr: 0.025000\n",
      "2021-01-30 23:28:10,084 epoch 34 - iter 28/49 - loss 0.07224549 - samples/sec: 192.77 - lr: 0.025000\n",
      "2021-01-30 23:28:10,717 epoch 34 - iter 32/49 - loss 0.07130874 - samples/sec: 202.53 - lr: 0.025000\n",
      "2021-01-30 23:28:11,338 epoch 34 - iter 36/49 - loss 0.07195900 - samples/sec: 206.45 - lr: 0.025000\n",
      "2021-01-30 23:28:11,981 epoch 34 - iter 40/49 - loss 0.08058199 - samples/sec: 199.38 - lr: 0.025000\n",
      "2021-01-30 23:28:12,638 epoch 34 - iter 44/49 - loss 0.07784868 - samples/sec: 194.83 - lr: 0.025000\n",
      "2021-01-30 23:28:13,328 epoch 34 - iter 48/49 - loss 0.07756421 - samples/sec: 185.51 - lr: 0.025000\n",
      "2021-01-30 23:28:13,459 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:13,459 EPOCH 34 done: loss 0.0767 - lr 0.0250000\n",
      "2021-01-30 23:28:15,215 DEV : loss 0.028914157301187515 - score 0.993\n",
      "2021-01-30 23:28:15,243 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:28:15,244 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:15,927 epoch 35 - iter 4/49 - loss 0.02661496 - samples/sec: 187.68 - lr: 0.025000\n",
      "2021-01-30 23:28:16,597 epoch 35 - iter 8/49 - loss 0.03699166 - samples/sec: 191.33 - lr: 0.025000\n",
      "2021-01-30 23:28:17,293 epoch 35 - iter 12/49 - loss 0.05482477 - samples/sec: 184.17 - lr: 0.025000\n",
      "2021-01-30 23:28:17,956 epoch 35 - iter 16/49 - loss 0.04674465 - samples/sec: 193.35 - lr: 0.025000\n",
      "2021-01-30 23:28:18,684 epoch 35 - iter 20/49 - loss 0.05759386 - samples/sec: 175.82 - lr: 0.025000\n",
      "2021-01-30 23:28:19,405 epoch 35 - iter 24/49 - loss 0.05995576 - samples/sec: 177.78 - lr: 0.025000\n",
      "2021-01-30 23:28:20,071 epoch 35 - iter 28/49 - loss 0.06797081 - samples/sec: 192.57 - lr: 0.025000\n",
      "2021-01-30 23:28:20,760 epoch 35 - iter 32/49 - loss 0.06617000 - samples/sec: 185.75 - lr: 0.025000\n",
      "2021-01-30 23:28:21,460 epoch 35 - iter 36/49 - loss 0.06697086 - samples/sec: 183.60 - lr: 0.025000\n",
      "2021-01-30 23:28:22,102 epoch 35 - iter 40/49 - loss 0.06740054 - samples/sec: 199.31 - lr: 0.025000\n",
      "2021-01-30 23:28:22,788 epoch 35 - iter 44/49 - loss 0.07258124 - samples/sec: 186.73 - lr: 0.025000\n",
      "2021-01-30 23:28:23,471 epoch 35 - iter 48/49 - loss 0.07401142 - samples/sec: 187.65 - lr: 0.025000\n",
      "2021-01-30 23:28:23,636 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:23,637 EPOCH 35 done: loss 0.0745 - lr 0.0250000\n",
      "2021-01-30 23:28:25,447 DEV : loss 0.025525346398353577 - score 0.99\n",
      "2021-01-30 23:28:25,476 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:28:25,477 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:26,137 epoch 36 - iter 4/49 - loss 0.05747694 - samples/sec: 194.17 - lr: 0.025000\n",
      "2021-01-30 23:28:26,776 epoch 36 - iter 8/49 - loss 0.04700434 - samples/sec: 200.57 - lr: 0.025000\n",
      "2021-01-30 23:28:27,436 epoch 36 - iter 12/49 - loss 0.07721972 - samples/sec: 194.51 - lr: 0.025000\n",
      "2021-01-30 23:28:28,096 epoch 36 - iter 16/49 - loss 0.09526080 - samples/sec: 194.22 - lr: 0.025000\n",
      "2021-01-30 23:28:28,731 epoch 36 - iter 20/49 - loss 0.09049436 - samples/sec: 201.86 - lr: 0.025000\n",
      "2021-01-30 23:28:29,398 epoch 36 - iter 24/49 - loss 0.08090217 - samples/sec: 192.18 - lr: 0.025000\n",
      "2021-01-30 23:28:30,097 epoch 36 - iter 28/49 - loss 0.08146280 - samples/sec: 183.38 - lr: 0.025000\n",
      "2021-01-30 23:28:30,747 epoch 36 - iter 32/49 - loss 0.08150900 - samples/sec: 196.86 - lr: 0.025000\n",
      "2021-01-30 23:28:31,453 epoch 36 - iter 36/49 - loss 0.07893097 - samples/sec: 181.54 - lr: 0.025000\n",
      "2021-01-30 23:28:32,105 epoch 36 - iter 40/49 - loss 0.07767899 - samples/sec: 196.25 - lr: 0.025000\n",
      "2021-01-30 23:28:32,744 epoch 36 - iter 44/49 - loss 0.08100704 - samples/sec: 200.25 - lr: 0.025000\n",
      "2021-01-30 23:28:33,461 epoch 36 - iter 48/49 - loss 0.07762555 - samples/sec: 178.74 - lr: 0.025000\n",
      "2021-01-30 23:28:33,607 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:33,608 EPOCH 36 done: loss 0.0768 - lr 0.0250000\n",
      "2021-01-30 23:28:35,368 DEV : loss 0.02800874225795269 - score 0.993\n",
      "2021-01-30 23:28:35,395 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:28:35,395 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:36,046 epoch 37 - iter 4/49 - loss 0.06294525 - samples/sec: 197.52 - lr: 0.025000\n",
      "2021-01-30 23:28:36,760 epoch 37 - iter 8/49 - loss 0.05397907 - samples/sec: 179.77 - lr: 0.025000\n",
      "2021-01-30 23:28:37,403 epoch 37 - iter 12/49 - loss 0.08024226 - samples/sec: 199.05 - lr: 0.025000\n",
      "2021-01-30 23:28:38,063 epoch 37 - iter 16/49 - loss 0.07861000 - samples/sec: 193.98 - lr: 0.025000\n",
      "2021-01-30 23:28:38,707 epoch 37 - iter 20/49 - loss 0.06720290 - samples/sec: 198.97 - lr: 0.025000\n",
      "2021-01-30 23:28:39,375 epoch 37 - iter 24/49 - loss 0.07568080 - samples/sec: 191.60 - lr: 0.025000\n",
      "2021-01-30 23:28:40,071 epoch 37 - iter 28/49 - loss 0.07812208 - samples/sec: 183.87 - lr: 0.025000\n",
      "2021-01-30 23:28:40,714 epoch 37 - iter 32/49 - loss 0.07840322 - samples/sec: 199.49 - lr: 0.025000\n",
      "2021-01-30 23:28:41,365 epoch 37 - iter 36/49 - loss 0.07492750 - samples/sec: 196.92 - lr: 0.025000\n",
      "2021-01-30 23:28:42,048 epoch 37 - iter 40/49 - loss 0.07682008 - samples/sec: 187.61 - lr: 0.025000\n",
      "2021-01-30 23:28:42,704 epoch 37 - iter 44/49 - loss 0.07495783 - samples/sec: 195.33 - lr: 0.025000\n",
      "2021-01-30 23:28:43,331 epoch 37 - iter 48/49 - loss 0.07165774 - samples/sec: 204.44 - lr: 0.025000\n",
      "2021-01-30 23:28:43,464 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:43,465 EPOCH 37 done: loss 0.0712 - lr 0.0250000\n",
      "2021-01-30 23:28:45,278 DEV : loss 0.027406496927142143 - score 0.991\n",
      "Epoch    37: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2021-01-30 23:28:45,304 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:28:45,305 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:46,003 epoch 38 - iter 4/49 - loss 0.03717536 - samples/sec: 183.62 - lr: 0.012500\n",
      "2021-01-30 23:28:46,634 epoch 38 - iter 8/49 - loss 0.05910397 - samples/sec: 203.13 - lr: 0.012500\n",
      "2021-01-30 23:28:47,266 epoch 38 - iter 12/49 - loss 0.05270529 - samples/sec: 202.82 - lr: 0.012500\n",
      "2021-01-30 23:28:47,934 epoch 38 - iter 16/49 - loss 0.07148439 - samples/sec: 191.88 - lr: 0.012500\n",
      "2021-01-30 23:28:48,576 epoch 38 - iter 20/49 - loss 0.06585053 - samples/sec: 199.68 - lr: 0.012500\n",
      "2021-01-30 23:28:49,207 epoch 38 - iter 24/49 - loss 0.06640262 - samples/sec: 203.13 - lr: 0.012500\n",
      "2021-01-30 23:28:49,846 epoch 38 - iter 28/49 - loss 0.06701326 - samples/sec: 200.62 - lr: 0.012500\n",
      "2021-01-30 23:28:50,500 epoch 38 - iter 32/49 - loss 0.07768709 - samples/sec: 195.96 - lr: 0.012500\n",
      "2021-01-30 23:28:51,173 epoch 38 - iter 36/49 - loss 0.08744624 - samples/sec: 190.59 - lr: 0.012500\n",
      "2021-01-30 23:28:51,848 epoch 38 - iter 40/49 - loss 0.08311332 - samples/sec: 189.87 - lr: 0.012500\n",
      "2021-01-30 23:28:52,548 epoch 38 - iter 44/49 - loss 0.08202141 - samples/sec: 183.09 - lr: 0.012500\n",
      "2021-01-30 23:28:53,193 epoch 38 - iter 48/49 - loss 0.08084493 - samples/sec: 198.53 - lr: 0.012500\n",
      "2021-01-30 23:28:53,318 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:53,318 EPOCH 38 done: loss 0.0799 - lr 0.0125000\n",
      "2021-01-30 23:28:55,072 DEV : loss 0.028856122866272926 - score 0.991\n",
      "2021-01-30 23:28:55,100 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:28:55,101 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:28:55,758 epoch 39 - iter 4/49 - loss 0.04345918 - samples/sec: 195.11 - lr: 0.012500\n",
      "2021-01-30 23:28:56,460 epoch 39 - iter 8/49 - loss 0.05628702 - samples/sec: 182.26 - lr: 0.012500\n",
      "2021-01-30 23:28:57,146 epoch 39 - iter 12/49 - loss 0.05060933 - samples/sec: 186.83 - lr: 0.012500\n",
      "2021-01-30 23:28:57,772 epoch 39 - iter 16/49 - loss 0.06015414 - samples/sec: 204.78 - lr: 0.012500\n",
      "2021-01-30 23:28:58,515 epoch 39 - iter 20/49 - loss 0.05541346 - samples/sec: 172.72 - lr: 0.012500\n",
      "2021-01-30 23:28:59,190 epoch 39 - iter 24/49 - loss 0.05433023 - samples/sec: 189.87 - lr: 0.012500\n",
      "2021-01-30 23:28:59,813 epoch 39 - iter 28/49 - loss 0.05763681 - samples/sec: 205.79 - lr: 0.012500\n",
      "2021-01-30 23:29:00,481 epoch 39 - iter 32/49 - loss 0.06960312 - samples/sec: 192.11 - lr: 0.012500\n",
      "2021-01-30 23:29:01,197 epoch 39 - iter 36/49 - loss 0.07691055 - samples/sec: 179.03 - lr: 0.012500\n",
      "2021-01-30 23:29:01,830 epoch 39 - iter 40/49 - loss 0.07901034 - samples/sec: 202.47 - lr: 0.012500\n",
      "2021-01-30 23:29:02,480 epoch 39 - iter 44/49 - loss 0.07528060 - samples/sec: 197.20 - lr: 0.012500\n",
      "2021-01-30 23:29:03,163 epoch 39 - iter 48/49 - loss 0.08264540 - samples/sec: 187.66 - lr: 0.012500\n",
      "2021-01-30 23:29:03,306 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:03,307 EPOCH 39 done: loss 0.0822 - lr 0.0125000\n",
      "2021-01-30 23:29:05,022 DEV : loss 0.027710676193237305 - score 0.991\n",
      "2021-01-30 23:29:05,049 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:29:05,051 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:05,764 epoch 40 - iter 4/49 - loss 0.06408066 - samples/sec: 179.74 - lr: 0.012500\n",
      "2021-01-30 23:29:06,385 epoch 40 - iter 8/49 - loss 0.05488542 - samples/sec: 206.42 - lr: 0.012500\n",
      "2021-01-30 23:29:07,013 epoch 40 - iter 12/49 - loss 0.05516088 - samples/sec: 204.13 - lr: 0.012500\n",
      "2021-01-30 23:29:07,665 epoch 40 - iter 16/49 - loss 0.06515487 - samples/sec: 196.85 - lr: 0.012500\n",
      "2021-01-30 23:29:08,277 epoch 40 - iter 20/49 - loss 0.07711899 - samples/sec: 209.48 - lr: 0.012500\n",
      "2021-01-30 23:29:08,917 epoch 40 - iter 24/49 - loss 0.07322169 - samples/sec: 200.60 - lr: 0.012500\n",
      "2021-01-30 23:29:09,636 epoch 40 - iter 28/49 - loss 0.07015015 - samples/sec: 178.24 - lr: 0.012500\n",
      "2021-01-30 23:29:10,271 epoch 40 - iter 32/49 - loss 0.06664073 - samples/sec: 201.87 - lr: 0.012500\n",
      "2021-01-30 23:29:10,911 epoch 40 - iter 36/49 - loss 0.06351771 - samples/sec: 200.27 - lr: 0.012500\n",
      "2021-01-30 23:29:11,549 epoch 40 - iter 40/49 - loss 0.06641209 - samples/sec: 200.91 - lr: 0.012500\n",
      "2021-01-30 23:29:12,222 epoch 40 - iter 44/49 - loss 0.06585933 - samples/sec: 190.47 - lr: 0.012500\n",
      "2021-01-30 23:29:12,910 epoch 40 - iter 48/49 - loss 0.06712894 - samples/sec: 186.42 - lr: 0.012500\n",
      "2021-01-30 23:29:13,044 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:13,045 EPOCH 40 done: loss 0.0667 - lr 0.0125000\n",
      "2021-01-30 23:29:14,798 DEV : loss 0.028246402740478516 - score 0.991\n",
      "2021-01-30 23:29:14,824 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:29:14,825 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:15,467 epoch 41 - iter 4/49 - loss 0.16044694 - samples/sec: 199.60 - lr: 0.012500\n",
      "2021-01-30 23:29:16,121 epoch 41 - iter 8/49 - loss 0.11623874 - samples/sec: 196.02 - lr: 0.012500\n",
      "2021-01-30 23:29:16,795 epoch 41 - iter 12/49 - loss 0.10020111 - samples/sec: 190.04 - lr: 0.012500\n",
      "2021-01-30 23:29:17,452 epoch 41 - iter 16/49 - loss 0.09242605 - samples/sec: 195.43 - lr: 0.012500\n",
      "2021-01-30 23:29:18,124 epoch 41 - iter 20/49 - loss 0.09035438 - samples/sec: 190.73 - lr: 0.012500\n",
      "2021-01-30 23:29:18,743 epoch 41 - iter 24/49 - loss 0.09305500 - samples/sec: 206.79 - lr: 0.012500\n",
      "2021-01-30 23:29:19,374 epoch 41 - iter 28/49 - loss 0.08958977 - samples/sec: 203.47 - lr: 0.012500\n",
      "2021-01-30 23:29:20,069 epoch 41 - iter 32/49 - loss 0.08897640 - samples/sec: 184.42 - lr: 0.012500\n",
      "2021-01-30 23:29:20,765 epoch 41 - iter 36/49 - loss 0.08944901 - samples/sec: 184.17 - lr: 0.012500\n",
      "2021-01-30 23:29:21,445 epoch 41 - iter 40/49 - loss 0.08358586 - samples/sec: 188.51 - lr: 0.012500\n",
      "2021-01-30 23:29:22,165 epoch 41 - iter 44/49 - loss 0.07955338 - samples/sec: 177.97 - lr: 0.012500\n",
      "2021-01-30 23:29:22,852 epoch 41 - iter 48/49 - loss 0.08096179 - samples/sec: 186.30 - lr: 0.012500\n",
      "2021-01-30 23:29:22,975 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:22,976 EPOCH 41 done: loss 0.0798 - lr 0.0125000\n",
      "2021-01-30 23:29:25,051 DEV : loss 0.026461755856871605 - score 0.991\n",
      "Epoch    41: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2021-01-30 23:29:25,078 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:29:25,080 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:25,761 epoch 42 - iter 4/49 - loss 0.08115625 - samples/sec: 187.93 - lr: 0.006250\n",
      "2021-01-30 23:29:26,401 epoch 42 - iter 8/49 - loss 0.06909773 - samples/sec: 199.98 - lr: 0.006250\n",
      "2021-01-30 23:29:27,040 epoch 42 - iter 12/49 - loss 0.07864636 - samples/sec: 200.31 - lr: 0.006250\n",
      "2021-01-30 23:29:27,723 epoch 42 - iter 16/49 - loss 0.06712151 - samples/sec: 188.07 - lr: 0.006250\n",
      "2021-01-30 23:29:28,382 epoch 42 - iter 20/49 - loss 0.06051118 - samples/sec: 194.23 - lr: 0.006250\n",
      "2021-01-30 23:29:29,031 epoch 42 - iter 24/49 - loss 0.05865675 - samples/sec: 197.53 - lr: 0.006250\n",
      "2021-01-30 23:29:29,746 epoch 42 - iter 28/49 - loss 0.06153396 - samples/sec: 179.26 - lr: 0.006250\n",
      "2021-01-30 23:29:30,394 epoch 42 - iter 32/49 - loss 0.06635844 - samples/sec: 197.51 - lr: 0.006250\n",
      "2021-01-30 23:29:31,111 epoch 42 - iter 36/49 - loss 0.06531995 - samples/sec: 178.78 - lr: 0.006250\n",
      "2021-01-30 23:29:31,775 epoch 42 - iter 40/49 - loss 0.06414318 - samples/sec: 193.04 - lr: 0.006250\n",
      "2021-01-30 23:29:32,421 epoch 42 - iter 44/49 - loss 0.06398944 - samples/sec: 198.90 - lr: 0.006250\n",
      "2021-01-30 23:29:33,078 epoch 42 - iter 48/49 - loss 0.06560082 - samples/sec: 195.03 - lr: 0.006250\n",
      "2021-01-30 23:29:33,221 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:33,221 EPOCH 42 done: loss 0.0644 - lr 0.0062500\n",
      "2021-01-30 23:29:35,066 DEV : loss 0.02779288776218891 - score 0.991\n",
      "2021-01-30 23:29:35,094 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:29:35,095 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:35,824 epoch 43 - iter 4/49 - loss 0.08796346 - samples/sec: 175.94 - lr: 0.006250\n",
      "2021-01-30 23:29:36,521 epoch 43 - iter 8/49 - loss 0.09932300 - samples/sec: 183.88 - lr: 0.006250\n",
      "2021-01-30 23:29:37,201 epoch 43 - iter 12/49 - loss 0.08316329 - samples/sec: 188.50 - lr: 0.006250\n",
      "2021-01-30 23:29:37,828 epoch 43 - iter 16/49 - loss 0.08819214 - samples/sec: 204.45 - lr: 0.006250\n",
      "2021-01-30 23:29:38,506 epoch 43 - iter 20/49 - loss 0.08321977 - samples/sec: 189.05 - lr: 0.006250\n",
      "2021-01-30 23:29:39,143 epoch 43 - iter 24/49 - loss 0.07716779 - samples/sec: 200.93 - lr: 0.006250\n",
      "2021-01-30 23:29:39,806 epoch 43 - iter 28/49 - loss 0.07021612 - samples/sec: 193.34 - lr: 0.006250\n",
      "2021-01-30 23:29:40,462 epoch 43 - iter 32/49 - loss 0.07084259 - samples/sec: 195.35 - lr: 0.006250\n",
      "2021-01-30 23:29:41,096 epoch 43 - iter 36/49 - loss 0.06636597 - samples/sec: 202.18 - lr: 0.006250\n",
      "2021-01-30 23:29:41,741 epoch 43 - iter 40/49 - loss 0.06281848 - samples/sec: 198.74 - lr: 0.006250\n",
      "2021-01-30 23:29:42,412 epoch 43 - iter 44/49 - loss 0.06080228 - samples/sec: 191.33 - lr: 0.006250\n",
      "2021-01-30 23:29:43,136 epoch 43 - iter 48/49 - loss 0.05810339 - samples/sec: 177.03 - lr: 0.006250\n",
      "2021-01-30 23:29:43,276 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:43,276 EPOCH 43 done: loss 0.0573 - lr 0.0062500\n",
      "2021-01-30 23:29:45,019 DEV : loss 0.0275571346282959 - score 0.991\n",
      "2021-01-30 23:29:45,045 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:29:45,046 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:45,672 epoch 44 - iter 4/49 - loss 0.11119688 - samples/sec: 204.79 - lr: 0.006250\n",
      "2021-01-30 23:29:46,368 epoch 44 - iter 8/49 - loss 0.11360592 - samples/sec: 184.37 - lr: 0.006250\n",
      "2021-01-30 23:29:46,995 epoch 44 - iter 12/49 - loss 0.08665717 - samples/sec: 204.59 - lr: 0.006250\n",
      "2021-01-30 23:29:47,657 epoch 44 - iter 16/49 - loss 0.07125570 - samples/sec: 193.62 - lr: 0.006250\n",
      "2021-01-30 23:29:48,293 epoch 44 - iter 20/49 - loss 0.06368160 - samples/sec: 201.57 - lr: 0.006250\n",
      "2021-01-30 23:29:48,996 epoch 44 - iter 24/49 - loss 0.06893883 - samples/sec: 182.07 - lr: 0.006250\n",
      "2021-01-30 23:29:49,643 epoch 44 - iter 28/49 - loss 0.06766011 - samples/sec: 198.15 - lr: 0.006250\n",
      "2021-01-30 23:29:50,281 epoch 44 - iter 32/49 - loss 0.06733968 - samples/sec: 200.91 - lr: 0.006250\n",
      "2021-01-30 23:29:50,936 epoch 44 - iter 36/49 - loss 0.08294685 - samples/sec: 195.69 - lr: 0.006250\n",
      "2021-01-30 23:29:51,599 epoch 44 - iter 40/49 - loss 0.08782362 - samples/sec: 193.51 - lr: 0.006250\n",
      "2021-01-30 23:29:52,248 epoch 44 - iter 44/49 - loss 0.08852512 - samples/sec: 197.54 - lr: 0.006250\n",
      "2021-01-30 23:29:52,952 epoch 44 - iter 48/49 - loss 0.08474204 - samples/sec: 182.08 - lr: 0.006250\n",
      "2021-01-30 23:29:53,094 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:53,094 EPOCH 44 done: loss 0.0832 - lr 0.0062500\n",
      "2021-01-30 23:29:54,932 DEV : loss 0.026057230308651924 - score 0.991\n",
      "2021-01-30 23:29:54,959 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:29:54,961 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:29:55,611 epoch 45 - iter 4/49 - loss 0.04898989 - samples/sec: 197.20 - lr: 0.006250\n",
      "2021-01-30 23:29:56,282 epoch 45 - iter 8/49 - loss 0.06641465 - samples/sec: 191.06 - lr: 0.006250\n",
      "2021-01-30 23:29:56,921 epoch 45 - iter 12/49 - loss 0.05466930 - samples/sec: 200.93 - lr: 0.006250\n",
      "2021-01-30 23:29:57,590 epoch 45 - iter 16/49 - loss 0.05921298 - samples/sec: 191.33 - lr: 0.006250\n",
      "2021-01-30 23:29:58,252 epoch 45 - iter 20/49 - loss 0.07485117 - samples/sec: 193.52 - lr: 0.006250\n",
      "2021-01-30 23:29:58,954 epoch 45 - iter 24/49 - loss 0.07866446 - samples/sec: 182.78 - lr: 0.006250\n",
      "2021-01-30 23:29:59,739 epoch 45 - iter 28/49 - loss 0.07422619 - samples/sec: 163.24 - lr: 0.006250\n",
      "2021-01-30 23:30:00,435 epoch 45 - iter 32/49 - loss 0.06825195 - samples/sec: 184.15 - lr: 0.006250\n",
      "2021-01-30 23:30:01,100 epoch 45 - iter 36/49 - loss 0.06782444 - samples/sec: 192.76 - lr: 0.006250\n",
      "2021-01-30 23:30:01,740 epoch 45 - iter 40/49 - loss 0.06476286 - samples/sec: 200.62 - lr: 0.006250\n",
      "2021-01-30 23:30:02,396 epoch 45 - iter 44/49 - loss 0.07228502 - samples/sec: 195.13 - lr: 0.006250\n",
      "2021-01-30 23:30:03,061 epoch 45 - iter 48/49 - loss 0.06858383 - samples/sec: 192.75 - lr: 0.006250\n",
      "2021-01-30 23:30:03,221 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:03,222 EPOCH 45 done: loss 0.0674 - lr 0.0062500\n",
      "2021-01-30 23:30:04,940 DEV : loss 0.0255995225161314 - score 0.991\n",
      "Epoch    45: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2021-01-30 23:30:04,967 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:30:04,969 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:05,628 epoch 46 - iter 4/49 - loss 0.03532743 - samples/sec: 194.49 - lr: 0.003125\n",
      "2021-01-30 23:30:06,306 epoch 46 - iter 8/49 - loss 0.05792052 - samples/sec: 189.05 - lr: 0.003125\n",
      "2021-01-30 23:30:06,978 epoch 46 - iter 12/49 - loss 0.06211470 - samples/sec: 190.92 - lr: 0.003125\n",
      "2021-01-30 23:30:07,615 epoch 46 - iter 16/49 - loss 0.08522595 - samples/sec: 200.94 - lr: 0.003125\n",
      "2021-01-30 23:30:08,291 epoch 46 - iter 20/49 - loss 0.08226788 - samples/sec: 189.53 - lr: 0.003125\n",
      "2021-01-30 23:30:08,931 epoch 46 - iter 24/49 - loss 0.07966891 - samples/sec: 200.32 - lr: 0.003125\n",
      "2021-01-30 23:30:09,553 epoch 46 - iter 28/49 - loss 0.08295449 - samples/sec: 206.00 - lr: 0.003125\n",
      "2021-01-30 23:30:10,195 epoch 46 - iter 32/49 - loss 0.07915986 - samples/sec: 199.70 - lr: 0.003125\n",
      "2021-01-30 23:30:10,837 epoch 46 - iter 36/49 - loss 0.07514893 - samples/sec: 199.66 - lr: 0.003125\n",
      "2021-01-30 23:30:11,493 epoch 46 - iter 40/49 - loss 0.07408651 - samples/sec: 195.42 - lr: 0.003125\n",
      "2021-01-30 23:30:12,130 epoch 46 - iter 44/49 - loss 0.07696934 - samples/sec: 200.94 - lr: 0.003125\n",
      "2021-01-30 23:30:12,761 epoch 46 - iter 48/49 - loss 0.08060783 - samples/sec: 203.50 - lr: 0.003125\n",
      "2021-01-30 23:30:12,885 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:12,885 EPOCH 46 done: loss 0.0792 - lr 0.0031250\n",
      "2021-01-30 23:30:14,570 DEV : loss 0.025060037150979042 - score 0.991\n",
      "2021-01-30 23:30:14,596 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:30:14,597 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:15,229 epoch 47 - iter 4/49 - loss 0.06430739 - samples/sec: 202.84 - lr: 0.003125\n",
      "2021-01-30 23:30:15,840 epoch 47 - iter 8/49 - loss 0.05507791 - samples/sec: 209.84 - lr: 0.003125\n",
      "2021-01-30 23:30:16,535 epoch 47 - iter 12/49 - loss 0.06016797 - samples/sec: 184.40 - lr: 0.003125\n",
      "2021-01-30 23:30:17,198 epoch 47 - iter 16/49 - loss 0.05173393 - samples/sec: 193.07 - lr: 0.003125\n",
      "2021-01-30 23:30:17,838 epoch 47 - iter 20/49 - loss 0.04941157 - samples/sec: 199.96 - lr: 0.003125\n",
      "2021-01-30 23:30:18,488 epoch 47 - iter 24/49 - loss 0.05230191 - samples/sec: 197.20 - lr: 0.003125\n",
      "2021-01-30 23:30:19,116 epoch 47 - iter 28/49 - loss 0.05214366 - samples/sec: 204.13 - lr: 0.003125\n",
      "2021-01-30 23:30:19,808 epoch 47 - iter 32/49 - loss 0.05018383 - samples/sec: 185.51 - lr: 0.003125\n",
      "2021-01-30 23:30:20,459 epoch 47 - iter 36/49 - loss 0.04674159 - samples/sec: 196.88 - lr: 0.003125\n",
      "2021-01-30 23:30:21,127 epoch 47 - iter 40/49 - loss 0.04958965 - samples/sec: 191.89 - lr: 0.003125\n",
      "2021-01-30 23:30:21,831 epoch 47 - iter 44/49 - loss 0.04983796 - samples/sec: 181.83 - lr: 0.003125\n",
      "2021-01-30 23:30:22,537 epoch 47 - iter 48/49 - loss 0.05652858 - samples/sec: 181.54 - lr: 0.003125\n",
      "2021-01-30 23:30:22,680 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:22,681 EPOCH 47 done: loss 0.0562 - lr 0.0031250\n",
      "2021-01-30 23:30:24,467 DEV : loss 0.02522234432399273 - score 0.991\n",
      "2021-01-30 23:30:24,493 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:30:24,495 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:25,147 epoch 48 - iter 4/49 - loss 0.10120714 - samples/sec: 196.60 - lr: 0.003125\n",
      "2021-01-30 23:30:25,793 epoch 48 - iter 8/49 - loss 0.09106579 - samples/sec: 198.72 - lr: 0.003125\n",
      "2021-01-30 23:30:26,439 epoch 48 - iter 12/49 - loss 0.09805636 - samples/sec: 198.44 - lr: 0.003125\n",
      "2021-01-30 23:30:27,053 epoch 48 - iter 16/49 - loss 0.08188953 - samples/sec: 208.47 - lr: 0.003125\n",
      "2021-01-30 23:30:27,714 epoch 48 - iter 20/49 - loss 0.08915009 - samples/sec: 193.65 - lr: 0.003125\n",
      "2021-01-30 23:30:28,411 epoch 48 - iter 24/49 - loss 0.08682012 - samples/sec: 183.90 - lr: 0.003125\n",
      "2021-01-30 23:30:29,150 epoch 48 - iter 28/49 - loss 0.08045892 - samples/sec: 173.22 - lr: 0.003125\n",
      "2021-01-30 23:30:29,792 epoch 48 - iter 32/49 - loss 0.07621194 - samples/sec: 199.37 - lr: 0.003125\n",
      "2021-01-30 23:30:30,467 epoch 48 - iter 36/49 - loss 0.07500978 - samples/sec: 189.91 - lr: 0.003125\n",
      "2021-01-30 23:30:31,128 epoch 48 - iter 40/49 - loss 0.07209996 - samples/sec: 193.66 - lr: 0.003125\n",
      "2021-01-30 23:30:31,752 epoch 48 - iter 44/49 - loss 0.07994988 - samples/sec: 205.43 - lr: 0.003125\n",
      "2021-01-30 23:30:32,400 epoch 48 - iter 48/49 - loss 0.07626120 - samples/sec: 197.82 - lr: 0.003125\n",
      "2021-01-30 23:30:32,535 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:32,536 EPOCH 48 done: loss 0.0751 - lr 0.0031250\n",
      "2021-01-30 23:30:34,349 DEV : loss 0.02476445399224758 - score 0.991\n",
      "2021-01-30 23:30:34,377 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:30:34,378 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:35,038 epoch 49 - iter 4/49 - loss 0.03701162 - samples/sec: 194.44 - lr: 0.003125\n",
      "2021-01-30 23:30:35,737 epoch 49 - iter 8/49 - loss 0.07230422 - samples/sec: 183.35 - lr: 0.003125\n",
      "2021-01-30 23:30:36,384 epoch 49 - iter 12/49 - loss 0.07263972 - samples/sec: 198.14 - lr: 0.003125\n",
      "2021-01-30 23:30:37,033 epoch 49 - iter 16/49 - loss 0.05885819 - samples/sec: 197.53 - lr: 0.003125\n",
      "2021-01-30 23:30:37,672 epoch 49 - iter 20/49 - loss 0.05567908 - samples/sec: 200.60 - lr: 0.003125\n",
      "2021-01-30 23:30:38,316 epoch 49 - iter 24/49 - loss 0.06603412 - samples/sec: 199.20 - lr: 0.003125\n",
      "2021-01-30 23:30:38,974 epoch 49 - iter 28/49 - loss 0.07085102 - samples/sec: 194.75 - lr: 0.003125\n",
      "2021-01-30 23:30:39,726 epoch 49 - iter 32/49 - loss 0.06642468 - samples/sec: 170.43 - lr: 0.003125\n",
      "2021-01-30 23:30:40,357 epoch 49 - iter 36/49 - loss 0.06856217 - samples/sec: 203.15 - lr: 0.003125\n",
      "2021-01-30 23:30:41,017 epoch 49 - iter 40/49 - loss 0.06580993 - samples/sec: 193.94 - lr: 0.003125\n",
      "2021-01-30 23:30:41,657 epoch 49 - iter 44/49 - loss 0.06185600 - samples/sec: 199.98 - lr: 0.003125\n",
      "2021-01-30 23:30:42,322 epoch 49 - iter 48/49 - loss 0.06231208 - samples/sec: 192.44 - lr: 0.003125\n",
      "2021-01-30 23:30:42,447 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:42,448 EPOCH 49 done: loss 0.0617 - lr 0.0031250\n",
      "2021-01-30 23:30:44,266 DEV : loss 0.02501545287668705 - score 0.991\n",
      "Epoch    49: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2021-01-30 23:30:44,293 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:30:44,294 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:45,005 epoch 50 - iter 4/49 - loss 0.02450037 - samples/sec: 180.28 - lr: 0.001563\n",
      "2021-01-30 23:30:45,643 epoch 50 - iter 8/49 - loss 0.06191164 - samples/sec: 200.59 - lr: 0.001563\n",
      "2021-01-30 23:30:46,327 epoch 50 - iter 12/49 - loss 0.07036904 - samples/sec: 187.42 - lr: 0.001563\n",
      "2021-01-30 23:30:46,936 epoch 50 - iter 16/49 - loss 0.07449542 - samples/sec: 210.44 - lr: 0.001563\n",
      "2021-01-30 23:30:47,610 epoch 50 - iter 20/49 - loss 0.06764815 - samples/sec: 190.15 - lr: 0.001563\n",
      "2021-01-30 23:30:48,273 epoch 50 - iter 24/49 - loss 0.06339683 - samples/sec: 193.03 - lr: 0.001563\n",
      "2021-01-30 23:30:48,932 epoch 50 - iter 28/49 - loss 0.06130155 - samples/sec: 194.52 - lr: 0.001563\n",
      "2021-01-30 23:30:49,633 epoch 50 - iter 32/49 - loss 0.06246014 - samples/sec: 182.79 - lr: 0.001563\n",
      "2021-01-30 23:30:50,261 epoch 50 - iter 36/49 - loss 0.06165640 - samples/sec: 204.15 - lr: 0.001563\n",
      "2021-01-30 23:30:50,892 epoch 50 - iter 40/49 - loss 0.05945792 - samples/sec: 203.19 - lr: 0.001563\n",
      "2021-01-30 23:30:51,535 epoch 50 - iter 44/49 - loss 0.06274640 - samples/sec: 199.04 - lr: 0.001563\n",
      "2021-01-30 23:30:52,209 epoch 50 - iter 48/49 - loss 0.06267381 - samples/sec: 190.10 - lr: 0.001563\n",
      "2021-01-30 23:30:52,336 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:52,337 EPOCH 50 done: loss 0.0625 - lr 0.0015625\n",
      "2021-01-30 23:30:54,094 DEV : loss 0.024791745468974113 - score 0.991\n",
      "2021-01-30 23:30:54,120 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:30:54,121 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:30:54,954 epoch 51 - iter 4/49 - loss 0.01826268 - samples/sec: 153.73 - lr: 0.001563\n",
      "2021-01-30 23:30:55,607 epoch 51 - iter 8/49 - loss 0.02827784 - samples/sec: 196.29 - lr: 0.001563\n",
      "2021-01-30 23:30:56,253 epoch 51 - iter 12/49 - loss 0.03513036 - samples/sec: 198.71 - lr: 0.001563\n",
      "2021-01-30 23:30:56,869 epoch 51 - iter 16/49 - loss 0.07120098 - samples/sec: 208.13 - lr: 0.001563\n",
      "2021-01-30 23:30:57,532 epoch 51 - iter 20/49 - loss 0.08511218 - samples/sec: 193.34 - lr: 0.001563\n",
      "2021-01-30 23:30:58,228 epoch 51 - iter 24/49 - loss 0.09387745 - samples/sec: 184.16 - lr: 0.001563\n",
      "2021-01-30 23:30:58,955 epoch 51 - iter 28/49 - loss 0.08548849 - samples/sec: 176.31 - lr: 0.001563\n",
      "2021-01-30 23:30:59,617 epoch 51 - iter 32/49 - loss 0.08347463 - samples/sec: 193.64 - lr: 0.001563\n",
      "2021-01-30 23:31:00,250 epoch 51 - iter 36/49 - loss 0.08731477 - samples/sec: 202.55 - lr: 0.001563\n",
      "2021-01-30 23:31:00,944 epoch 51 - iter 40/49 - loss 0.08331867 - samples/sec: 184.41 - lr: 0.001563\n",
      "2021-01-30 23:31:01,582 epoch 51 - iter 44/49 - loss 0.07930443 - samples/sec: 200.92 - lr: 0.001563\n",
      "2021-01-30 23:31:02,220 epoch 51 - iter 48/49 - loss 0.07760172 - samples/sec: 200.94 - lr: 0.001563\n",
      "2021-01-30 23:31:02,355 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:02,355 EPOCH 51 done: loss 0.0844 - lr 0.0015625\n",
      "2021-01-30 23:31:04,151 DEV : loss 0.02511679381132126 - score 0.993\n",
      "2021-01-30 23:31:04,181 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:31:07,733 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:08,459 epoch 52 - iter 4/49 - loss 0.07150471 - samples/sec: 176.55 - lr: 0.001563\n",
      "2021-01-30 23:31:09,090 epoch 52 - iter 8/49 - loss 0.08447278 - samples/sec: 203.25 - lr: 0.001563\n",
      "2021-01-30 23:31:09,728 epoch 52 - iter 12/49 - loss 0.09910635 - samples/sec: 200.95 - lr: 0.001563\n",
      "2021-01-30 23:31:10,352 epoch 52 - iter 16/49 - loss 0.09088834 - samples/sec: 205.47 - lr: 0.001563\n",
      "2021-01-30 23:31:11,078 epoch 52 - iter 20/49 - loss 0.09075913 - samples/sec: 176.32 - lr: 0.001563\n",
      "2021-01-30 23:31:11,726 epoch 52 - iter 24/49 - loss 0.08522405 - samples/sec: 197.82 - lr: 0.001563\n",
      "2021-01-30 23:31:12,379 epoch 52 - iter 28/49 - loss 0.07521049 - samples/sec: 196.30 - lr: 0.001563\n",
      "2021-01-30 23:31:13,032 epoch 52 - iter 32/49 - loss 0.07943774 - samples/sec: 196.62 - lr: 0.001563\n",
      "2021-01-30 23:31:13,647 epoch 52 - iter 36/49 - loss 0.07801370 - samples/sec: 208.46 - lr: 0.001563\n",
      "2021-01-30 23:31:14,377 epoch 52 - iter 40/49 - loss 0.07225277 - samples/sec: 175.57 - lr: 0.001563\n",
      "2021-01-30 23:31:15,015 epoch 52 - iter 44/49 - loss 0.07645319 - samples/sec: 200.93 - lr: 0.001563\n",
      "2021-01-30 23:31:15,683 epoch 52 - iter 48/49 - loss 0.07514833 - samples/sec: 191.86 - lr: 0.001563\n",
      "2021-01-30 23:31:15,818 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:15,819 EPOCH 52 done: loss 0.0749 - lr 0.0015625\n",
      "2021-01-30 23:31:17,740 DEV : loss 0.024800581857562065 - score 0.993\n",
      "2021-01-30 23:31:17,768 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:31:21,209 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:21,922 epoch 53 - iter 4/49 - loss 0.02993196 - samples/sec: 179.75 - lr: 0.001563\n",
      "2021-01-30 23:31:22,604 epoch 53 - iter 8/49 - loss 0.05916247 - samples/sec: 187.94 - lr: 0.001563\n",
      "2021-01-30 23:31:23,234 epoch 53 - iter 12/49 - loss 0.07305380 - samples/sec: 203.79 - lr: 0.001563\n",
      "2021-01-30 23:31:23,910 epoch 53 - iter 16/49 - loss 0.07079679 - samples/sec: 189.33 - lr: 0.001563\n",
      "2021-01-30 23:31:24,548 epoch 53 - iter 20/49 - loss 0.07333082 - samples/sec: 200.60 - lr: 0.001563\n",
      "2021-01-30 23:31:25,200 epoch 53 - iter 24/49 - loss 0.07217149 - samples/sec: 196.58 - lr: 0.001563\n",
      "2021-01-30 23:31:25,843 epoch 53 - iter 28/49 - loss 0.07672384 - samples/sec: 199.34 - lr: 0.001563\n",
      "2021-01-30 23:31:26,489 epoch 53 - iter 32/49 - loss 0.07893319 - samples/sec: 198.28 - lr: 0.001563\n",
      "2021-01-30 23:31:27,181 epoch 53 - iter 36/49 - loss 0.07453743 - samples/sec: 185.45 - lr: 0.001563\n",
      "2021-01-30 23:31:27,867 epoch 53 - iter 40/49 - loss 0.07025481 - samples/sec: 186.58 - lr: 0.001563\n",
      "2021-01-30 23:31:28,565 epoch 53 - iter 44/49 - loss 0.07294657 - samples/sec: 183.27 - lr: 0.001563\n",
      "2021-01-30 23:31:29,221 epoch 53 - iter 48/49 - loss 0.07099382 - samples/sec: 195.12 - lr: 0.001563\n",
      "2021-01-30 23:31:29,362 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:29,362 EPOCH 53 done: loss 0.0699 - lr 0.0015625\n",
      "2021-01-30 23:31:31,122 DEV : loss 0.024602806195616722 - score 0.993\n",
      "2021-01-30 23:31:31,149 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:31:34,566 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:35,218 epoch 54 - iter 4/49 - loss 0.04538000 - samples/sec: 196.88 - lr: 0.001563\n",
      "2021-01-30 23:31:35,863 epoch 54 - iter 8/49 - loss 0.06975552 - samples/sec: 198.76 - lr: 0.001563\n",
      "2021-01-30 23:31:36,537 epoch 54 - iter 12/49 - loss 0.07442711 - samples/sec: 189.90 - lr: 0.001563\n",
      "2021-01-30 23:31:37,212 epoch 54 - iter 16/49 - loss 0.06533816 - samples/sec: 189.91 - lr: 0.001563\n",
      "2021-01-30 23:31:37,894 epoch 54 - iter 20/49 - loss 0.09203849 - samples/sec: 187.69 - lr: 0.001563\n",
      "2021-01-30 23:31:38,546 epoch 54 - iter 24/49 - loss 0.08288609 - samples/sec: 196.62 - lr: 0.001563\n",
      "2021-01-30 23:31:39,189 epoch 54 - iter 28/49 - loss 0.08160515 - samples/sec: 199.54 - lr: 0.001563\n",
      "2021-01-30 23:31:39,815 epoch 54 - iter 32/49 - loss 0.07696827 - samples/sec: 204.44 - lr: 0.001563\n",
      "2021-01-30 23:31:40,494 epoch 54 - iter 36/49 - loss 0.07343705 - samples/sec: 188.80 - lr: 0.001563\n",
      "2021-01-30 23:31:41,164 epoch 54 - iter 40/49 - loss 0.07228594 - samples/sec: 191.33 - lr: 0.001563\n",
      "2021-01-30 23:31:41,796 epoch 54 - iter 44/49 - loss 0.07366578 - samples/sec: 202.96 - lr: 0.001563\n",
      "2021-01-30 23:31:42,434 epoch 54 - iter 48/49 - loss 0.07199245 - samples/sec: 200.87 - lr: 0.001563\n",
      "2021-01-30 23:31:42,566 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:42,567 EPOCH 54 done: loss 0.0715 - lr 0.0015625\n",
      "2021-01-30 23:31:44,264 DEV : loss 0.024844156578183174 - score 0.993\n",
      "2021-01-30 23:31:44,290 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:31:44,291 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:44,961 epoch 55 - iter 4/49 - loss 0.04368883 - samples/sec: 191.49 - lr: 0.001563\n",
      "2021-01-30 23:31:45,596 epoch 55 - iter 8/49 - loss 0.04446161 - samples/sec: 201.98 - lr: 0.001563\n",
      "2021-01-30 23:31:46,214 epoch 55 - iter 12/49 - loss 0.04161372 - samples/sec: 207.44 - lr: 0.001563\n",
      "2021-01-30 23:31:46,850 epoch 55 - iter 16/49 - loss 0.05423529 - samples/sec: 201.55 - lr: 0.001563\n",
      "2021-01-30 23:31:47,535 epoch 55 - iter 20/49 - loss 0.05511034 - samples/sec: 187.12 - lr: 0.001563\n",
      "2021-01-30 23:31:48,176 epoch 55 - iter 24/49 - loss 0.06202238 - samples/sec: 199.97 - lr: 0.001563\n",
      "2021-01-30 23:31:48,844 epoch 55 - iter 28/49 - loss 0.06099446 - samples/sec: 191.90 - lr: 0.001563\n",
      "2021-01-30 23:31:49,485 epoch 55 - iter 32/49 - loss 0.06858069 - samples/sec: 199.90 - lr: 0.001563\n",
      "2021-01-30 23:31:50,171 epoch 55 - iter 36/49 - loss 0.07952708 - samples/sec: 186.84 - lr: 0.001563\n",
      "2021-01-30 23:31:50,823 epoch 55 - iter 40/49 - loss 0.07372060 - samples/sec: 196.60 - lr: 0.001563\n",
      "2021-01-30 23:31:51,455 epoch 55 - iter 44/49 - loss 0.07753348 - samples/sec: 202.84 - lr: 0.001563\n",
      "2021-01-30 23:31:52,109 epoch 55 - iter 48/49 - loss 0.07404080 - samples/sec: 196.01 - lr: 0.001563\n",
      "2021-01-30 23:31:52,229 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:52,230 EPOCH 55 done: loss 0.0736 - lr 0.0015625\n",
      "2021-01-30 23:31:53,910 DEV : loss 0.024956170469522476 - score 0.993\n",
      "2021-01-30 23:31:53,936 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:31:53,937 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:31:54,609 epoch 56 - iter 4/49 - loss 0.07104713 - samples/sec: 190.73 - lr: 0.001563\n",
      "2021-01-30 23:31:55,244 epoch 56 - iter 8/49 - loss 0.05394995 - samples/sec: 201.56 - lr: 0.001563\n",
      "2021-01-30 23:31:55,915 epoch 56 - iter 12/49 - loss 0.07648037 - samples/sec: 190.98 - lr: 0.001563\n",
      "2021-01-30 23:31:56,582 epoch 56 - iter 16/49 - loss 0.08261015 - samples/sec: 192.17 - lr: 0.001563\n",
      "2021-01-30 23:31:57,298 epoch 56 - iter 20/49 - loss 0.08025687 - samples/sec: 178.76 - lr: 0.001563\n",
      "2021-01-30 23:31:57,944 epoch 56 - iter 24/49 - loss 0.07282865 - samples/sec: 198.40 - lr: 0.001563\n",
      "2021-01-30 23:31:58,591 epoch 56 - iter 28/49 - loss 0.07517294 - samples/sec: 198.54 - lr: 0.001563\n",
      "2021-01-30 23:31:59,274 epoch 56 - iter 32/49 - loss 0.06879419 - samples/sec: 187.64 - lr: 0.001563\n",
      "2021-01-30 23:31:59,902 epoch 56 - iter 36/49 - loss 0.06463042 - samples/sec: 204.12 - lr: 0.001563\n",
      "2021-01-30 23:32:00,580 epoch 56 - iter 40/49 - loss 0.06276592 - samples/sec: 189.02 - lr: 0.001563\n",
      "2021-01-30 23:32:01,274 epoch 56 - iter 44/49 - loss 0.06804005 - samples/sec: 184.58 - lr: 0.001563\n",
      "2021-01-30 23:32:01,951 epoch 56 - iter 48/49 - loss 0.06916797 - samples/sec: 189.88 - lr: 0.001563\n",
      "2021-01-30 23:32:02,114 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:02,115 EPOCH 56 done: loss 0.0688 - lr 0.0015625\n",
      "2021-01-30 23:32:03,848 DEV : loss 0.024931009858846664 - score 0.993\n",
      "2021-01-30 23:32:03,875 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:32:03,877 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:04,538 epoch 57 - iter 4/49 - loss 0.03072065 - samples/sec: 193.87 - lr: 0.001563\n",
      "2021-01-30 23:32:05,230 epoch 57 - iter 8/49 - loss 0.09044069 - samples/sec: 185.18 - lr: 0.001563\n",
      "2021-01-30 23:32:05,869 epoch 57 - iter 12/49 - loss 0.08734925 - samples/sec: 200.60 - lr: 0.001563\n",
      "2021-01-30 23:32:06,534 epoch 57 - iter 16/49 - loss 0.07272553 - samples/sec: 193.30 - lr: 0.001563\n",
      "2021-01-30 23:32:07,146 epoch 57 - iter 20/49 - loss 0.09112210 - samples/sec: 209.15 - lr: 0.001563\n",
      "2021-01-30 23:32:07,822 epoch 57 - iter 24/49 - loss 0.08976551 - samples/sec: 189.60 - lr: 0.001563\n",
      "2021-01-30 23:32:08,472 epoch 57 - iter 28/49 - loss 0.08577804 - samples/sec: 197.19 - lr: 0.001563\n",
      "2021-01-30 23:32:09,133 epoch 57 - iter 32/49 - loss 0.08926531 - samples/sec: 194.19 - lr: 0.001563\n",
      "2021-01-30 23:32:09,777 epoch 57 - iter 36/49 - loss 0.08139985 - samples/sec: 199.03 - lr: 0.001563\n",
      "2021-01-30 23:32:10,444 epoch 57 - iter 40/49 - loss 0.08189103 - samples/sec: 192.17 - lr: 0.001563\n",
      "2021-01-30 23:32:11,088 epoch 57 - iter 44/49 - loss 0.07998368 - samples/sec: 199.35 - lr: 0.001563\n",
      "2021-01-30 23:32:11,752 epoch 57 - iter 48/49 - loss 0.07701315 - samples/sec: 193.02 - lr: 0.001563\n",
      "2021-01-30 23:32:11,890 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:11,890 EPOCH 57 done: loss 0.0758 - lr 0.0015625\n",
      "2021-01-30 23:32:13,605 DEV : loss 0.024710599333047867 - score 0.993\n",
      "Epoch    57: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2021-01-30 23:32:13,631 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:32:13,632 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:14,267 epoch 58 - iter 4/49 - loss 0.06281656 - samples/sec: 201.77 - lr: 0.000781\n",
      "2021-01-30 23:32:14,908 epoch 58 - iter 8/49 - loss 0.05832002 - samples/sec: 200.20 - lr: 0.000781\n",
      "2021-01-30 23:32:15,540 epoch 58 - iter 12/49 - loss 0.05944584 - samples/sec: 202.53 - lr: 0.000781\n",
      "2021-01-30 23:32:16,148 epoch 58 - iter 16/49 - loss 0.08820866 - samples/sec: 210.86 - lr: 0.000781\n",
      "2021-01-30 23:32:16,838 epoch 58 - iter 20/49 - loss 0.08793589 - samples/sec: 185.68 - lr: 0.000781\n",
      "2021-01-30 23:32:17,500 epoch 58 - iter 24/49 - loss 0.09682097 - samples/sec: 193.50 - lr: 0.000781\n",
      "2021-01-30 23:32:18,131 epoch 58 - iter 28/49 - loss 0.09264476 - samples/sec: 203.43 - lr: 0.000781\n",
      "2021-01-30 23:32:18,771 epoch 58 - iter 32/49 - loss 0.08916364 - samples/sec: 200.32 - lr: 0.000781\n",
      "2021-01-30 23:32:19,442 epoch 58 - iter 36/49 - loss 0.08332626 - samples/sec: 190.76 - lr: 0.000781\n",
      "2021-01-30 23:32:20,146 epoch 58 - iter 40/49 - loss 0.07962447 - samples/sec: 182.06 - lr: 0.000781\n",
      "2021-01-30 23:32:20,851 epoch 58 - iter 44/49 - loss 0.07710044 - samples/sec: 181.82 - lr: 0.000781\n",
      "2021-01-30 23:32:21,552 epoch 58 - iter 48/49 - loss 0.07451445 - samples/sec: 182.86 - lr: 0.000781\n",
      "2021-01-30 23:32:21,671 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:21,671 EPOCH 58 done: loss 0.0742 - lr 0.0007813\n",
      "2021-01-30 23:32:23,438 DEV : loss 0.024505209177732468 - score 0.993\n",
      "2021-01-30 23:32:23,466 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:32:26,795 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:27,520 epoch 59 - iter 4/49 - loss 0.03656298 - samples/sec: 176.78 - lr: 0.000781\n",
      "2021-01-30 23:32:28,165 epoch 59 - iter 8/49 - loss 0.03610483 - samples/sec: 198.77 - lr: 0.000781\n",
      "2021-01-30 23:32:28,788 epoch 59 - iter 12/49 - loss 0.03427567 - samples/sec: 205.44 - lr: 0.000781\n",
      "2021-01-30 23:32:29,440 epoch 59 - iter 16/49 - loss 0.05923945 - samples/sec: 196.62 - lr: 0.000781\n",
      "2021-01-30 23:32:30,097 epoch 59 - iter 20/49 - loss 0.06638149 - samples/sec: 195.37 - lr: 0.000781\n",
      "2021-01-30 23:32:30,736 epoch 59 - iter 24/49 - loss 0.06817678 - samples/sec: 200.61 - lr: 0.000781\n",
      "2021-01-30 23:32:31,428 epoch 59 - iter 28/49 - loss 0.07313204 - samples/sec: 184.96 - lr: 0.000781\n",
      "2021-01-30 23:32:32,067 epoch 59 - iter 32/49 - loss 0.07229612 - samples/sec: 200.92 - lr: 0.000781\n",
      "2021-01-30 23:32:32,680 epoch 59 - iter 36/49 - loss 0.07052780 - samples/sec: 208.79 - lr: 0.000781\n",
      "2021-01-30 23:32:33,347 epoch 59 - iter 40/49 - loss 0.07007894 - samples/sec: 192.47 - lr: 0.000781\n",
      "2021-01-30 23:32:34,008 epoch 59 - iter 44/49 - loss 0.07618844 - samples/sec: 193.91 - lr: 0.000781\n",
      "2021-01-30 23:32:34,663 epoch 59 - iter 48/49 - loss 0.07591525 - samples/sec: 195.42 - lr: 0.000781\n",
      "2021-01-30 23:32:34,817 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:34,817 EPOCH 59 done: loss 0.0830 - lr 0.0007813\n",
      "2021-01-30 23:32:36,754 DEV : loss 0.024399617686867714 - score 0.993\n",
      "2021-01-30 23:32:36,782 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:32:40,108 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:40,773 epoch 60 - iter 4/49 - loss 0.06218743 - samples/sec: 192.73 - lr: 0.000781\n",
      "2021-01-30 23:32:41,424 epoch 60 - iter 8/49 - loss 0.05236322 - samples/sec: 196.84 - lr: 0.000781\n",
      "2021-01-30 23:32:42,084 epoch 60 - iter 12/49 - loss 0.07344405 - samples/sec: 194.51 - lr: 0.000781\n",
      "2021-01-30 23:32:42,752 epoch 60 - iter 16/49 - loss 0.06836225 - samples/sec: 191.91 - lr: 0.000781\n",
      "2021-01-30 23:32:43,438 epoch 60 - iter 20/49 - loss 0.07040671 - samples/sec: 186.84 - lr: 0.000781\n",
      "2021-01-30 23:32:44,072 epoch 60 - iter 24/49 - loss 0.07190851 - samples/sec: 201.87 - lr: 0.000781\n",
      "2021-01-30 23:32:44,706 epoch 60 - iter 28/49 - loss 0.06994140 - samples/sec: 202.21 - lr: 0.000781\n",
      "2021-01-30 23:32:45,318 epoch 60 - iter 32/49 - loss 0.07682524 - samples/sec: 209.49 - lr: 0.000781\n",
      "2021-01-30 23:32:45,979 epoch 60 - iter 36/49 - loss 0.07149578 - samples/sec: 194.21 - lr: 0.000781\n",
      "2021-01-30 23:32:46,615 epoch 60 - iter 40/49 - loss 0.06920920 - samples/sec: 201.53 - lr: 0.000781\n",
      "2021-01-30 23:32:47,266 epoch 60 - iter 44/49 - loss 0.06714114 - samples/sec: 196.46 - lr: 0.000781\n",
      "2021-01-30 23:32:47,910 epoch 60 - iter 48/49 - loss 0.06359895 - samples/sec: 199.05 - lr: 0.000781\n",
      "2021-01-30 23:32:48,042 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:48,043 EPOCH 60 done: loss 0.0634 - lr 0.0007813\n",
      "2021-01-30 23:32:49,781 DEV : loss 0.024320336058735847 - score 0.993\n",
      "2021-01-30 23:32:49,809 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:32:53,174 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:32:53,911 epoch 61 - iter 4/49 - loss 0.09630108 - samples/sec: 173.90 - lr: 0.000781\n",
      "2021-01-30 23:32:54,574 epoch 61 - iter 8/49 - loss 0.07947958 - samples/sec: 193.34 - lr: 0.000781\n",
      "2021-01-30 23:32:55,228 epoch 61 - iter 12/49 - loss 0.07250752 - samples/sec: 196.00 - lr: 0.000781\n",
      "2021-01-30 23:32:55,857 epoch 61 - iter 16/49 - loss 0.06063779 - samples/sec: 203.81 - lr: 0.000781\n",
      "2021-01-30 23:32:56,496 epoch 61 - iter 20/49 - loss 0.05208715 - samples/sec: 200.17 - lr: 0.000781\n",
      "2021-01-30 23:32:57,141 epoch 61 - iter 24/49 - loss 0.05796303 - samples/sec: 198.69 - lr: 0.000781\n",
      "2021-01-30 23:32:57,760 epoch 61 - iter 28/49 - loss 0.05991656 - samples/sec: 206.75 - lr: 0.000781\n",
      "2021-01-30 23:32:58,421 epoch 61 - iter 32/49 - loss 0.07185883 - samples/sec: 193.85 - lr: 0.000781\n",
      "2021-01-30 23:32:59,140 epoch 61 - iter 36/49 - loss 0.06829543 - samples/sec: 178.26 - lr: 0.000781\n",
      "2021-01-30 23:32:59,909 epoch 61 - iter 40/49 - loss 0.06563099 - samples/sec: 166.38 - lr: 0.000781\n",
      "2021-01-30 23:33:00,583 epoch 61 - iter 44/49 - loss 0.06985474 - samples/sec: 190.39 - lr: 0.000781\n",
      "2021-01-30 23:33:01,227 epoch 61 - iter 48/49 - loss 0.07739715 - samples/sec: 198.75 - lr: 0.000781\n",
      "2021-01-30 23:33:01,357 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:01,358 EPOCH 61 done: loss 0.0788 - lr 0.0007813\n",
      "2021-01-30 23:33:03,221 DEV : loss 0.024065662175416946 - score 0.993\n",
      "2021-01-30 23:33:03,251 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-30 23:33:06,578 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:07,263 epoch 62 - iter 4/49 - loss 0.06886685 - samples/sec: 187.10 - lr: 0.000781\n",
      "2021-01-30 23:33:07,995 epoch 62 - iter 8/49 - loss 0.05883935 - samples/sec: 175.32 - lr: 0.000781\n",
      "2021-01-30 23:33:08,599 epoch 62 - iter 12/49 - loss 0.05865149 - samples/sec: 212.22 - lr: 0.000781\n",
      "2021-01-30 23:33:09,230 epoch 62 - iter 16/49 - loss 0.05544715 - samples/sec: 202.84 - lr: 0.000781\n",
      "2021-01-30 23:33:09,863 epoch 62 - iter 20/49 - loss 0.05460997 - samples/sec: 202.52 - lr: 0.000781\n",
      "2021-01-30 23:33:10,553 epoch 62 - iter 24/49 - loss 0.05520009 - samples/sec: 185.68 - lr: 0.000781\n",
      "2021-01-30 23:33:11,214 epoch 62 - iter 28/49 - loss 0.05313057 - samples/sec: 193.92 - lr: 0.000781\n",
      "2021-01-30 23:33:11,913 epoch 62 - iter 32/49 - loss 0.05092491 - samples/sec: 183.36 - lr: 0.000781\n",
      "2021-01-30 23:33:12,583 epoch 62 - iter 36/49 - loss 0.05299032 - samples/sec: 191.32 - lr: 0.000781\n",
      "2021-01-30 23:33:13,217 epoch 62 - iter 40/49 - loss 0.04965097 - samples/sec: 201.88 - lr: 0.000781\n",
      "2021-01-30 23:33:13,863 epoch 62 - iter 44/49 - loss 0.05242757 - samples/sec: 198.74 - lr: 0.000781\n",
      "2021-01-30 23:33:14,488 epoch 62 - iter 48/49 - loss 0.05682380 - samples/sec: 205.10 - lr: 0.000781\n",
      "2021-01-30 23:33:14,616 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:14,617 EPOCH 62 done: loss 0.0564 - lr 0.0007813\n",
      "2021-01-30 23:33:16,324 DEV : loss 0.024069715291261673 - score 0.993\n",
      "2021-01-30 23:33:16,353 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:33:16,354 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:16,992 epoch 63 - iter 4/49 - loss 0.15605152 - samples/sec: 201.25 - lr: 0.000781\n",
      "2021-01-30 23:33:17,674 epoch 63 - iter 8/49 - loss 0.12250656 - samples/sec: 187.58 - lr: 0.000781\n",
      "2021-01-30 23:33:18,339 epoch 63 - iter 12/49 - loss 0.10290994 - samples/sec: 192.72 - lr: 0.000781\n",
      "2021-01-30 23:33:19,026 epoch 63 - iter 16/49 - loss 0.09197000 - samples/sec: 186.82 - lr: 0.000781\n",
      "2021-01-30 23:33:19,678 epoch 63 - iter 20/49 - loss 0.09342490 - samples/sec: 196.59 - lr: 0.000781\n",
      "2021-01-30 23:33:20,323 epoch 63 - iter 24/49 - loss 0.08745812 - samples/sec: 198.45 - lr: 0.000781\n",
      "2021-01-30 23:33:20,944 epoch 63 - iter 28/49 - loss 0.08436212 - samples/sec: 206.12 - lr: 0.000781\n",
      "2021-01-30 23:33:21,582 epoch 63 - iter 32/49 - loss 0.08715905 - samples/sec: 200.90 - lr: 0.000781\n",
      "2021-01-30 23:33:22,221 epoch 63 - iter 36/49 - loss 0.08889842 - samples/sec: 200.61 - lr: 0.000781\n",
      "2021-01-30 23:33:22,872 epoch 63 - iter 40/49 - loss 0.08258831 - samples/sec: 196.79 - lr: 0.000781\n",
      "2021-01-30 23:33:23,507 epoch 63 - iter 44/49 - loss 0.08172248 - samples/sec: 201.85 - lr: 0.000781\n",
      "2021-01-30 23:33:24,147 epoch 63 - iter 48/49 - loss 0.08260708 - samples/sec: 200.55 - lr: 0.000781\n",
      "2021-01-30 23:33:24,268 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:24,268 EPOCH 63 done: loss 0.0813 - lr 0.0007813\n",
      "2021-01-30 23:33:26,005 DEV : loss 0.02408709190785885 - score 0.993\n",
      "2021-01-30 23:33:26,032 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:33:26,033 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:26,694 epoch 64 - iter 4/49 - loss 0.02098590 - samples/sec: 193.92 - lr: 0.000781\n",
      "2021-01-30 23:33:27,344 epoch 64 - iter 8/49 - loss 0.03937748 - samples/sec: 197.20 - lr: 0.000781\n",
      "2021-01-30 23:33:28,063 epoch 64 - iter 12/49 - loss 0.04319187 - samples/sec: 178.23 - lr: 0.000781\n",
      "2021-01-30 23:33:28,791 epoch 64 - iter 16/49 - loss 0.04231052 - samples/sec: 176.05 - lr: 0.000781\n",
      "2021-01-30 23:33:29,448 epoch 64 - iter 20/49 - loss 0.04969245 - samples/sec: 195.10 - lr: 0.000781\n",
      "2021-01-30 23:33:30,105 epoch 64 - iter 24/49 - loss 0.06541211 - samples/sec: 195.31 - lr: 0.000781\n",
      "2021-01-30 23:33:30,783 epoch 64 - iter 28/49 - loss 0.07097091 - samples/sec: 188.79 - lr: 0.000781\n",
      "2021-01-30 23:33:31,447 epoch 64 - iter 32/49 - loss 0.07308436 - samples/sec: 193.14 - lr: 0.000781\n",
      "2021-01-30 23:33:32,078 epoch 64 - iter 36/49 - loss 0.08096765 - samples/sec: 203.19 - lr: 0.000781\n",
      "2021-01-30 23:33:32,754 epoch 64 - iter 40/49 - loss 0.07493048 - samples/sec: 189.63 - lr: 0.000781\n",
      "2021-01-30 23:33:33,418 epoch 64 - iter 44/49 - loss 0.07065923 - samples/sec: 192.77 - lr: 0.000781\n",
      "2021-01-30 23:33:34,027 epoch 64 - iter 48/49 - loss 0.06872129 - samples/sec: 210.53 - lr: 0.000781\n",
      "2021-01-30 23:33:34,157 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:34,158 EPOCH 64 done: loss 0.0680 - lr 0.0007813\n",
      "2021-01-30 23:33:36,026 DEV : loss 0.024140525609254837 - score 0.993\n",
      "2021-01-30 23:33:36,054 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:33:36,055 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:36,684 epoch 65 - iter 4/49 - loss 0.02632606 - samples/sec: 204.16 - lr: 0.000781\n",
      "2021-01-30 23:33:37,341 epoch 65 - iter 8/49 - loss 0.03495318 - samples/sec: 195.12 - lr: 0.000781\n",
      "2021-01-30 23:33:37,998 epoch 65 - iter 12/49 - loss 0.07771744 - samples/sec: 195.12 - lr: 0.000781\n",
      "2021-01-30 23:33:38,673 epoch 65 - iter 16/49 - loss 0.07118426 - samples/sec: 190.20 - lr: 0.000781\n",
      "2021-01-30 23:33:39,339 epoch 65 - iter 20/49 - loss 0.06573122 - samples/sec: 192.19 - lr: 0.000781\n",
      "2021-01-30 23:33:39,990 epoch 65 - iter 24/49 - loss 0.07657670 - samples/sec: 196.92 - lr: 0.000781\n",
      "2021-01-30 23:33:40,589 epoch 65 - iter 28/49 - loss 0.07788774 - samples/sec: 213.60 - lr: 0.000781\n",
      "2021-01-30 23:33:41,224 epoch 65 - iter 32/49 - loss 0.07154355 - samples/sec: 201.89 - lr: 0.000781\n",
      "2021-01-30 23:33:41,903 epoch 65 - iter 36/49 - loss 0.07791668 - samples/sec: 188.47 - lr: 0.000781\n",
      "2021-01-30 23:33:42,560 epoch 65 - iter 40/49 - loss 0.07901360 - samples/sec: 195.41 - lr: 0.000781\n",
      "2021-01-30 23:33:43,181 epoch 65 - iter 44/49 - loss 0.08405564 - samples/sec: 206.78 - lr: 0.000781\n",
      "2021-01-30 23:33:43,883 epoch 65 - iter 48/49 - loss 0.08562751 - samples/sec: 182.58 - lr: 0.000781\n",
      "2021-01-30 23:33:44,040 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:44,041 EPOCH 65 done: loss 0.0842 - lr 0.0007813\n",
      "2021-01-30 23:33:45,919 DEV : loss 0.024170538410544395 - score 0.993\n",
      "Epoch    65: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2021-01-30 23:33:45,945 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:33:45,946 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:46,638 epoch 66 - iter 4/49 - loss 0.05541119 - samples/sec: 185.33 - lr: 0.000391\n",
      "2021-01-30 23:33:47,265 epoch 66 - iter 8/49 - loss 0.04253928 - samples/sec: 204.46 - lr: 0.000391\n",
      "2021-01-30 23:33:47,902 epoch 66 - iter 12/49 - loss 0.05924075 - samples/sec: 201.25 - lr: 0.000391\n",
      "2021-01-30 23:33:48,561 epoch 66 - iter 16/49 - loss 0.06706257 - samples/sec: 194.52 - lr: 0.000391\n",
      "2021-01-30 23:33:49,203 epoch 66 - iter 20/49 - loss 0.06301242 - samples/sec: 199.68 - lr: 0.000391\n",
      "2021-01-30 23:33:49,820 epoch 66 - iter 24/49 - loss 0.07150006 - samples/sec: 207.79 - lr: 0.000391\n",
      "2021-01-30 23:33:50,500 epoch 66 - iter 28/49 - loss 0.06448127 - samples/sec: 188.22 - lr: 0.000391\n",
      "2021-01-30 23:33:51,145 epoch 66 - iter 32/49 - loss 0.06504996 - samples/sec: 198.68 - lr: 0.000391\n",
      "2021-01-30 23:33:51,821 epoch 66 - iter 36/49 - loss 0.06728995 - samples/sec: 189.90 - lr: 0.000391\n",
      "2021-01-30 23:33:52,496 epoch 66 - iter 40/49 - loss 0.07219001 - samples/sec: 190.14 - lr: 0.000391\n",
      "2021-01-30 23:33:53,225 epoch 66 - iter 44/49 - loss 0.07222198 - samples/sec: 176.05 - lr: 0.000391\n",
      "2021-01-30 23:33:53,958 epoch 66 - iter 48/49 - loss 0.06881165 - samples/sec: 174.61 - lr: 0.000391\n",
      "2021-01-30 23:33:54,085 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:54,086 EPOCH 66 done: loss 0.0701 - lr 0.0003906\n",
      "2021-01-30 23:33:55,826 DEV : loss 0.024156780913472176 - score 0.993\n",
      "2021-01-30 23:33:55,853 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:33:55,854 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:33:56,536 epoch 67 - iter 4/49 - loss 0.07689112 - samples/sec: 188.22 - lr: 0.000391\n",
      "2021-01-30 23:33:57,218 epoch 67 - iter 8/49 - loss 0.07374975 - samples/sec: 187.97 - lr: 0.000391\n",
      "2021-01-30 23:33:57,864 epoch 67 - iter 12/49 - loss 0.07827632 - samples/sec: 198.43 - lr: 0.000391\n",
      "2021-01-30 23:33:58,544 epoch 67 - iter 16/49 - loss 0.06538342 - samples/sec: 188.52 - lr: 0.000391\n",
      "2021-01-30 23:33:59,207 epoch 67 - iter 20/49 - loss 0.05857542 - samples/sec: 193.40 - lr: 0.000391\n",
      "2021-01-30 23:33:59,862 epoch 67 - iter 24/49 - loss 0.05546592 - samples/sec: 195.41 - lr: 0.000391\n",
      "2021-01-30 23:34:00,514 epoch 67 - iter 28/49 - loss 0.05441194 - samples/sec: 196.61 - lr: 0.000391\n",
      "2021-01-30 23:34:01,146 epoch 67 - iter 32/49 - loss 0.05431274 - samples/sec: 202.84 - lr: 0.000391\n",
      "2021-01-30 23:34:01,787 epoch 67 - iter 36/49 - loss 0.06660246 - samples/sec: 199.98 - lr: 0.000391\n",
      "2021-01-30 23:34:02,434 epoch 67 - iter 40/49 - loss 0.06579644 - samples/sec: 198.13 - lr: 0.000391\n",
      "2021-01-30 23:34:03,109 epoch 67 - iter 44/49 - loss 0.06310574 - samples/sec: 190.14 - lr: 0.000391\n",
      "2021-01-30 23:34:03,758 epoch 67 - iter 48/49 - loss 0.06334190 - samples/sec: 197.53 - lr: 0.000391\n",
      "2021-01-30 23:34:03,887 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:03,887 EPOCH 67 done: loss 0.0623 - lr 0.0003906\n",
      "2021-01-30 23:34:05,593 DEV : loss 0.02413870394229889 - score 0.993\n",
      "2021-01-30 23:34:05,620 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:34:05,621 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:06,301 epoch 68 - iter 4/49 - loss 0.11992061 - samples/sec: 188.50 - lr: 0.000391\n",
      "2021-01-30 23:34:06,940 epoch 68 - iter 8/49 - loss 0.07701486 - samples/sec: 200.64 - lr: 0.000391\n",
      "2021-01-30 23:34:07,582 epoch 68 - iter 12/49 - loss 0.06104704 - samples/sec: 199.35 - lr: 0.000391\n",
      "2021-01-30 23:34:08,202 epoch 68 - iter 16/49 - loss 0.06435472 - samples/sec: 206.77 - lr: 0.000391\n",
      "2021-01-30 23:34:08,824 epoch 68 - iter 20/49 - loss 0.06665689 - samples/sec: 206.11 - lr: 0.000391\n",
      "2021-01-30 23:34:09,450 epoch 68 - iter 24/49 - loss 0.06003525 - samples/sec: 204.81 - lr: 0.000391\n",
      "2021-01-30 23:34:10,084 epoch 68 - iter 28/49 - loss 0.06268900 - samples/sec: 202.20 - lr: 0.000391\n",
      "2021-01-30 23:34:10,781 epoch 68 - iter 32/49 - loss 0.06118148 - samples/sec: 183.92 - lr: 0.000391\n",
      "2021-01-30 23:34:11,396 epoch 68 - iter 36/49 - loss 0.06022760 - samples/sec: 208.46 - lr: 0.000391\n",
      "2021-01-30 23:34:12,062 epoch 68 - iter 40/49 - loss 0.05879304 - samples/sec: 192.48 - lr: 0.000391\n",
      "2021-01-30 23:34:12,711 epoch 68 - iter 44/49 - loss 0.06061430 - samples/sec: 197.53 - lr: 0.000391\n",
      "2021-01-30 23:34:13,354 epoch 68 - iter 48/49 - loss 0.06062794 - samples/sec: 199.67 - lr: 0.000391\n",
      "2021-01-30 23:34:13,488 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:13,489 EPOCH 68 done: loss 0.0597 - lr 0.0003906\n",
      "2021-01-30 23:34:15,408 DEV : loss 0.024130554869771004 - score 0.993\n",
      "2021-01-30 23:34:15,436 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:34:15,438 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:16,079 epoch 69 - iter 4/49 - loss 0.05292666 - samples/sec: 200.27 - lr: 0.000391\n",
      "2021-01-30 23:34:16,724 epoch 69 - iter 8/49 - loss 0.05106896 - samples/sec: 198.45 - lr: 0.000391\n",
      "2021-01-30 23:34:17,355 epoch 69 - iter 12/49 - loss 0.04394563 - samples/sec: 202.84 - lr: 0.000391\n",
      "2021-01-30 23:34:18,011 epoch 69 - iter 16/49 - loss 0.05680846 - samples/sec: 195.10 - lr: 0.000391\n",
      "2021-01-30 23:34:18,627 epoch 69 - iter 20/49 - loss 0.05319129 - samples/sec: 208.13 - lr: 0.000391\n",
      "2021-01-30 23:34:19,303 epoch 69 - iter 24/49 - loss 0.05068952 - samples/sec: 189.56 - lr: 0.000391\n",
      "2021-01-30 23:34:19,938 epoch 69 - iter 28/49 - loss 0.05088027 - samples/sec: 201.57 - lr: 0.000391\n",
      "2021-01-30 23:34:20,612 epoch 69 - iter 32/49 - loss 0.06002495 - samples/sec: 190.19 - lr: 0.000391\n",
      "2021-01-30 23:34:21,263 epoch 69 - iter 36/49 - loss 0.05843992 - samples/sec: 196.92 - lr: 0.000391\n",
      "2021-01-30 23:34:21,949 epoch 69 - iter 40/49 - loss 0.05622384 - samples/sec: 187.14 - lr: 0.000391\n",
      "2021-01-30 23:34:22,583 epoch 69 - iter 44/49 - loss 0.05572625 - samples/sec: 202.20 - lr: 0.000391\n",
      "2021-01-30 23:34:23,195 epoch 69 - iter 48/49 - loss 0.05867497 - samples/sec: 209.46 - lr: 0.000391\n",
      "2021-01-30 23:34:23,339 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:23,340 EPOCH 69 done: loss 0.0594 - lr 0.0003906\n",
      "2021-01-30 23:34:25,155 DEV : loss 0.024138998240232468 - score 0.993\n",
      "Epoch    69: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2021-01-30 23:34:25,184 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:34:25,186 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:25,834 epoch 70 - iter 4/49 - loss 0.12779576 - samples/sec: 197.84 - lr: 0.000195\n",
      "2021-01-30 23:34:26,532 epoch 70 - iter 8/49 - loss 0.08249795 - samples/sec: 183.35 - lr: 0.000195\n",
      "2021-01-30 23:34:27,150 epoch 70 - iter 12/49 - loss 0.08120535 - samples/sec: 207.46 - lr: 0.000195\n",
      "2021-01-30 23:34:27,861 epoch 70 - iter 16/49 - loss 0.07081351 - samples/sec: 180.02 - lr: 0.000195\n",
      "2021-01-30 23:34:28,572 epoch 70 - iter 20/49 - loss 0.06439842 - samples/sec: 180.02 - lr: 0.000195\n",
      "2021-01-30 23:34:29,193 epoch 70 - iter 24/49 - loss 0.06232630 - samples/sec: 206.45 - lr: 0.000195\n",
      "2021-01-30 23:34:29,809 epoch 70 - iter 28/49 - loss 0.05851098 - samples/sec: 208.47 - lr: 0.000195\n",
      "2021-01-30 23:34:30,448 epoch 70 - iter 32/49 - loss 0.05473942 - samples/sec: 200.62 - lr: 0.000195\n",
      "2021-01-30 23:34:31,133 epoch 70 - iter 36/49 - loss 0.06323120 - samples/sec: 186.86 - lr: 0.000195\n",
      "2021-01-30 23:34:31,808 epoch 70 - iter 40/49 - loss 0.06410197 - samples/sec: 189.91 - lr: 0.000195\n",
      "2021-01-30 23:34:32,489 epoch 70 - iter 44/49 - loss 0.07137194 - samples/sec: 187.96 - lr: 0.000195\n",
      "2021-01-30 23:34:33,124 epoch 70 - iter 48/49 - loss 0.07358638 - samples/sec: 201.87 - lr: 0.000195\n",
      "2021-01-30 23:34:33,257 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:33,258 EPOCH 70 done: loss 0.0737 - lr 0.0001953\n",
      "2021-01-30 23:34:35,006 DEV : loss 0.024163274094462395 - score 0.993\n",
      "2021-01-30 23:34:35,033 BAD EPOCHS (no improvement): 1\n",
      "2021-01-30 23:34:35,034 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:35,706 epoch 71 - iter 4/49 - loss 0.07117823 - samples/sec: 191.02 - lr: 0.000195\n",
      "2021-01-30 23:34:36,346 epoch 71 - iter 8/49 - loss 0.09631197 - samples/sec: 200.01 - lr: 0.000195\n",
      "2021-01-30 23:34:37,063 epoch 71 - iter 12/49 - loss 0.08493200 - samples/sec: 179.01 - lr: 0.000195\n",
      "2021-01-30 23:34:37,716 epoch 71 - iter 16/49 - loss 0.09428021 - samples/sec: 195.73 - lr: 0.000195\n",
      "2021-01-30 23:34:38,539 epoch 71 - iter 20/49 - loss 0.08360814 - samples/sec: 155.53 - lr: 0.000195\n",
      "2021-01-30 23:34:39,245 epoch 71 - iter 24/49 - loss 0.08559858 - samples/sec: 181.68 - lr: 0.000195\n",
      "2021-01-30 23:34:39,911 epoch 71 - iter 28/49 - loss 0.08059937 - samples/sec: 192.49 - lr: 0.000195\n",
      "2021-01-30 23:34:40,605 epoch 71 - iter 32/49 - loss 0.07720241 - samples/sec: 184.69 - lr: 0.000195\n",
      "2021-01-30 23:34:41,270 epoch 71 - iter 36/49 - loss 0.07274195 - samples/sec: 192.49 - lr: 0.000195\n",
      "2021-01-30 23:34:41,909 epoch 71 - iter 40/49 - loss 0.07057552 - samples/sec: 200.32 - lr: 0.000195\n",
      "2021-01-30 23:34:42,546 epoch 71 - iter 44/49 - loss 0.06727610 - samples/sec: 201.26 - lr: 0.000195\n",
      "2021-01-30 23:34:43,171 epoch 71 - iter 48/49 - loss 0.06885728 - samples/sec: 205.12 - lr: 0.000195\n",
      "2021-01-30 23:34:43,301 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:43,301 EPOCH 71 done: loss 0.0680 - lr 0.0001953\n",
      "2021-01-30 23:34:45,259 DEV : loss 0.02417691983282566 - score 0.993\n",
      "2021-01-30 23:34:45,285 BAD EPOCHS (no improvement): 2\n",
      "2021-01-30 23:34:45,286 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:45,954 epoch 72 - iter 4/49 - loss 0.11339259 - samples/sec: 192.17 - lr: 0.000195\n",
      "2021-01-30 23:34:46,613 epoch 72 - iter 8/49 - loss 0.08969706 - samples/sec: 194.24 - lr: 0.000195\n",
      "2021-01-30 23:34:47,272 epoch 72 - iter 12/49 - loss 0.08096455 - samples/sec: 194.54 - lr: 0.000195\n",
      "2021-01-30 23:34:47,910 epoch 72 - iter 16/49 - loss 0.07307495 - samples/sec: 200.63 - lr: 0.000195\n",
      "2021-01-30 23:34:48,536 epoch 72 - iter 20/49 - loss 0.06879666 - samples/sec: 204.46 - lr: 0.000195\n",
      "2021-01-30 23:34:49,193 epoch 72 - iter 24/49 - loss 0.07863328 - samples/sec: 195.13 - lr: 0.000195\n",
      "2021-01-30 23:34:49,916 epoch 72 - iter 28/49 - loss 0.07712131 - samples/sec: 177.28 - lr: 0.000195\n",
      "2021-01-30 23:34:50,575 epoch 72 - iter 32/49 - loss 0.08748610 - samples/sec: 194.53 - lr: 0.000195\n",
      "2021-01-30 23:34:51,260 epoch 72 - iter 36/49 - loss 0.08805405 - samples/sec: 186.86 - lr: 0.000195\n",
      "2021-01-30 23:34:51,918 epoch 72 - iter 40/49 - loss 0.08384596 - samples/sec: 194.82 - lr: 0.000195\n",
      "2021-01-30 23:34:52,590 epoch 72 - iter 44/49 - loss 0.08047137 - samples/sec: 190.77 - lr: 0.000195\n",
      "2021-01-30 23:34:53,290 epoch 72 - iter 48/49 - loss 0.07810818 - samples/sec: 182.96 - lr: 0.000195\n",
      "2021-01-30 23:34:53,414 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:53,415 EPOCH 72 done: loss 0.0794 - lr 0.0001953\n",
      "2021-01-30 23:34:55,126 DEV : loss 0.024148674681782722 - score 0.993\n",
      "2021-01-30 23:34:55,153 BAD EPOCHS (no improvement): 3\n",
      "2021-01-30 23:34:55,154 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:34:55,756 epoch 73 - iter 4/49 - loss 0.05100608 - samples/sec: 212.97 - lr: 0.000195\n",
      "2021-01-30 23:34:56,391 epoch 73 - iter 8/49 - loss 0.07268280 - samples/sec: 201.57 - lr: 0.000195\n",
      "2021-01-30 23:34:57,070 epoch 73 - iter 12/49 - loss 0.06797846 - samples/sec: 188.79 - lr: 0.000195\n",
      "2021-01-30 23:34:57,697 epoch 73 - iter 16/49 - loss 0.08338183 - samples/sec: 204.47 - lr: 0.000195\n",
      "2021-01-30 23:34:58,428 epoch 73 - iter 20/49 - loss 0.07824231 - samples/sec: 175.30 - lr: 0.000195\n",
      "2021-01-30 23:34:59,118 epoch 73 - iter 24/49 - loss 0.07779866 - samples/sec: 185.78 - lr: 0.000195\n",
      "2021-01-30 23:34:59,796 epoch 73 - iter 28/49 - loss 0.08402197 - samples/sec: 189.07 - lr: 0.000195\n",
      "2021-01-30 23:35:00,446 epoch 73 - iter 32/49 - loss 0.08586457 - samples/sec: 197.20 - lr: 0.000195\n",
      "2021-01-30 23:35:01,104 epoch 73 - iter 36/49 - loss 0.07984327 - samples/sec: 194.80 - lr: 0.000195\n",
      "2021-01-30 23:35:01,782 epoch 73 - iter 40/49 - loss 0.07845913 - samples/sec: 188.79 - lr: 0.000195\n",
      "2021-01-30 23:35:02,445 epoch 73 - iter 44/49 - loss 0.07792664 - samples/sec: 193.36 - lr: 0.000195\n",
      "2021-01-30 23:35:03,088 epoch 73 - iter 48/49 - loss 0.07534755 - samples/sec: 199.34 - lr: 0.000195\n",
      "2021-01-30 23:35:03,219 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:35:03,219 EPOCH 73 done: loss 0.0740 - lr 0.0001953\n",
      "2021-01-30 23:35:04,908 DEV : loss 0.024153919890522957 - score 0.993\n",
      "Epoch    73: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2021-01-30 23:35:04,936 BAD EPOCHS (no improvement): 4\n",
      "2021-01-30 23:35:04,937 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:35:04,937 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:35:04,938 learning rate too small - quitting training!\n",
      "2021-01-30 23:35:04,938 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:35:08,332 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-30 23:35:08,333 Testing using best model ...\n",
      "2021-01-30 23:35:08,334 loading file taggers\\pii-ner-v0\\best-model.pt\n",
      "2021-01-30 23:35:14,135 1.0000\t0.9980\t0.9990\n",
      "2021-01-30 23:35:14,136 \n",
      "Results:\n",
      "- F1-score (micro) 0.9990\n",
      "- F1-score (macro) 0.9996\n",
      "\n",
      "By class:\n",
      "Address    tp: 200 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "CreditCardNumber tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "Email      tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "Name       tp: 199 - fp: 0 - fn: 1 - precision: 1.0000 - recall: 0.9950 - f1-score: 0.9975\n",
      "Phone_number tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "Plates     tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "SSN        tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "2021-01-30 23:35:14,136 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'test_score': 0.998998998998999,\n",
       " 'dev_score_history': [0.7730727470141152,\n",
       "  0.8715415019762845,\n",
       "  0.9346534653465346,\n",
       "  0.8726554787759132,\n",
       "  0.9689689689689689,\n",
       "  0.97,\n",
       "  0.9760479041916168,\n",
       "  0.9770687936191426,\n",
       "  0.9790628115653042,\n",
       "  0.986986986986987,\n",
       "  0.983016983016983,\n",
       "  0.988988988988989,\n",
       "  0.983016983016983,\n",
       "  0.9850149850149851,\n",
       "  0.988,\n",
       "  0.9899799599198397,\n",
       "  0.987012987012987,\n",
       "  0.9830508474576272,\n",
       "  0.986986986986987,\n",
       "  0.9850448654037887,\n",
       "  0.989010989010989,\n",
       "  0.988,\n",
       "  0.990990990990991,\n",
       "  0.99,\n",
       "  0.990990990990991,\n",
       "  0.988988988988989,\n",
       "  0.990990990990991,\n",
       "  0.9929929929929929,\n",
       "  0.988988988988989,\n",
       "  0.990990990990991,\n",
       "  0.988988988988989,\n",
       "  0.990990990990991,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.99,\n",
       "  0.9929929929929929,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.990990990990991,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929,\n",
       "  0.9929929929929929],\n",
       " 'train_loss_history': [8.048351891186773,\n",
       "  1.6799560687979873,\n",
       "  0.9602584060357542,\n",
       "  0.6436182053721681,\n",
       "  0.5517618595337381,\n",
       "  0.4094772983570488,\n",
       "  0.3757366124464541,\n",
       "  0.30632804060468866,\n",
       "  0.22720068328234613,\n",
       "  0.2453560920394197,\n",
       "  0.20155171152888512,\n",
       "  0.1977972222530112,\n",
       "  0.16845192075992116,\n",
       "  0.15571171349408675,\n",
       "  0.13132974003650705,\n",
       "  0.16619715398671675,\n",
       "  0.1318693817878256,\n",
       "  0.12253217064604467,\n",
       "  0.12636123548204803,\n",
       "  0.10937083497339366,\n",
       "  0.09107951162268921,\n",
       "  0.10743007208315694,\n",
       "  0.08118660930468112,\n",
       "  0.08813924692115005,\n",
       "  0.0970912149974278,\n",
       "  0.09745918335963269,\n",
       "  0.08198445347346822,\n",
       "  0.08187060537082809,\n",
       "  0.07759720535606754,\n",
       "  0.08761328017833281,\n",
       "  0.08821673463193738,\n",
       "  0.07870144100517643,\n",
       "  0.0777096083501772,\n",
       "  0.07665430609973109,\n",
       "  0.0745047437293189,\n",
       "  0.0768346543214759,\n",
       "  0.07119955175689288,\n",
       "  0.0799233540892601,\n",
       "  0.08217396222207012,\n",
       "  0.06666144386542086,\n",
       "  0.07978238705165532,\n",
       "  0.06444742971537065,\n",
       "  0.05726466780262334,\n",
       "  0.08317724377753175,\n",
       "  0.06742347259910739,\n",
       "  0.07916790611889897,\n",
       "  0.056158337514011225,\n",
       "  0.07507090665856186,\n",
       "  0.06168312039606425,\n",
       "  0.062473900464116314,\n",
       "  0.08443379523802777,\n",
       "  0.07492032829596072,\n",
       "  0.06990689160872479,\n",
       "  0.07152437677188796,\n",
       "  0.07363452884007474,\n",
       "  0.06880818824378812,\n",
       "  0.07583128109726371,\n",
       "  0.07423067260153439,\n",
       "  0.08304097214523627,\n",
       "  0.06335096296911337,\n",
       "  0.07882099188103968,\n",
       "  0.0564272688055525,\n",
       "  0.08131907021208686,\n",
       "  0.06803322005636837,\n",
       "  0.0841724710462957,\n",
       "  0.07006521857514673,\n",
       "  0.06233221170853595,\n",
       "  0.05972268227107671,\n",
       "  0.05941579947058035,\n",
       "  0.07374973686373963,\n",
       "  0.06796020391036053,\n",
       "  0.07943467309280318,\n",
       "  0.07397702762058803],\n",
       " 'dev_loss_history': [1.898419737815857,\n",
       "  0.6449254155158997,\n",
       "  0.38109567761421204,\n",
       "  0.49562206864356995,\n",
       "  0.2230025827884674,\n",
       "  0.14185886085033417,\n",
       "  0.12086606025695801,\n",
       "  0.0914660096168518,\n",
       "  0.08476147055625916,\n",
       "  0.0742316022515297,\n",
       "  0.05912670120596886,\n",
       "  0.05627086013555527,\n",
       "  0.06355343759059906,\n",
       "  0.062009356915950775,\n",
       "  0.045114967972040176,\n",
       "  0.05016002804040909,\n",
       "  0.04806772246956825,\n",
       "  0.03790959343314171,\n",
       "  0.04612664505839348,\n",
       "  0.03551793098449707,\n",
       "  0.04033815115690231,\n",
       "  0.0352325513958931,\n",
       "  0.03287301957607269,\n",
       "  0.03307567536830902,\n",
       "  0.0465129129588604,\n",
       "  0.031111037358641624,\n",
       "  0.028597040101885796,\n",
       "  0.029941432178020477,\n",
       "  0.035040829330682755,\n",
       "  0.03432858735322952,\n",
       "  0.029697012156248093,\n",
       "  0.029899822548031807,\n",
       "  0.027515677735209465,\n",
       "  0.028914157301187515,\n",
       "  0.025525346398353577,\n",
       "  0.02800874225795269,\n",
       "  0.027406496927142143,\n",
       "  0.028856122866272926,\n",
       "  0.027710676193237305,\n",
       "  0.028246402740478516,\n",
       "  0.026461755856871605,\n",
       "  0.02779288776218891,\n",
       "  0.0275571346282959,\n",
       "  0.026057230308651924,\n",
       "  0.0255995225161314,\n",
       "  0.025060037150979042,\n",
       "  0.02522234432399273,\n",
       "  0.02476445399224758,\n",
       "  0.02501545287668705,\n",
       "  0.024791745468974113,\n",
       "  0.02511679381132126,\n",
       "  0.024800581857562065,\n",
       "  0.024602806195616722,\n",
       "  0.024844156578183174,\n",
       "  0.024956170469522476,\n",
       "  0.024931009858846664,\n",
       "  0.024710599333047867,\n",
       "  0.024505209177732468,\n",
       "  0.024399617686867714,\n",
       "  0.024320336058735847,\n",
       "  0.024065662175416946,\n",
       "  0.024069715291261673,\n",
       "  0.02408709190785885,\n",
       "  0.024140525609254837,\n",
       "  0.024170538410544395,\n",
       "  0.024156780913472176,\n",
       "  0.02413870394229889,\n",
       "  0.024130554869771004,\n",
       "  0.024138998240232468,\n",
       "  0.024163274094462395,\n",
       "  0.02417691983282566,\n",
       "  0.024148674681782722,\n",
       "  0.024153919890522957]}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# initialize trainer\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# start training\n",
    "trainer.train('./taggers/pii-ner-v0',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "source": [
    "## Scores\n",
    "\n",
    "In the interest of visibility I have copied over the final scores from the logs.\n",
    "```\n",
    "2021-01-30 23:35:08,333 Testing using best model ...\n",
    "2021-01-30 23:35:08,334 loading file taggers\\pii-ner-v0\\best-model.pt\n",
    "2021-01-30 23:35:14,135 1.0000\t0.9980\t0.9990\n",
    "2021-01-30 23:35:14,136 \n",
    "Results:\n",
    "- F1-score (micro) 0.9990\n",
    "- F1-score (macro) 0.9996\n",
    "\n",
    "By class:\n",
    "Address    tp: 200 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "CreditCardNumber tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "Email      tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "Name       tp: 199 - fp: 0 - fn: 1 - precision: 1.0000 - recall: 0.9950 - f1-score: 0.9975\n",
    "Phone_number tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "Plates     tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "SSN        tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-30 23:35:14,154 loading file ./taggers/pii-ner-v0/final-model.pt\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "model = SequenceTagger.load('./taggers/pii-ner-v0/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentence:\n",
      "Hold home fight nor customer defense. Shields Shake player something.\n",
      "Tagged Sentence:\n",
      "Hold home fight nor customer defense . Shields <B-Name> Shake player something .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [8]: \"Shields\"   [− Labels: Name (0.9508)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Box direction clear sense democratic power. Adult determine rule Deanna across sometimes according.\n",
      "Tagged Sentence:\n",
      "Box direction clear sense democratic power . Adult determine rule Deanna <B-Name> across sometimes according .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [11]: \"Deanna\"   [− Labels: Name (0.997)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "High same pass Smith change. Effort board fly onto middle detail. Ahead chance small ability reduce under. Middle policy use single become.\n",
      "Tagged Sentence:\n",
      "High same pass Smith <B-Name> change . Effort board fly onto middle detail . Ahead chance small ability reduce under . Middle policy use single become .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [4]: \"Smith\"   [− Labels: Name (0.9831)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Product similar final sense senior least. Model explain reveal American they behind source. Join Ariana White president other arm until feel force.\n",
      "Tagged Sentence:\n",
      "Product similar final sense senior least . Model explain reveal American they behind source . Join Ariana <B-Name> White <I-Name> president other arm until feel force .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [17,18]: \"Ariana White\"   [− Labels: Name (0.9971)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Matthew Haas Market Republican hand sign.\n",
      "Tagged Sentence:\n",
      "Matthew <B-Name> Haas <I-Name> Market Republican hand sign .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [1,2]: \"Matthew Haas\"   [− Labels: Name (0.9976)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Whom simple Franklin nice three car. Music answer southern performance glass around.\n",
      "Tagged Sentence:\n",
      "Whom simple Franklin <B-Name> nice three car . Music answer southern performance glass around .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [3]: \"Franklin\"   [− Labels: Name (0.988)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Everybody small suggest into president. Over manager Charles government they.\n",
      "Tagged Sentence:\n",
      "Everybody small suggest into president . Over manager Charles <B-Name> government they .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [9]: \"Charles\"   [− Labels: Name (0.9991)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Dark turn purpose attack set way. Significant impact book daughter manager behavior pressure. Price true we pressure culture design 22868 Strong Square Suite 603 serve answer.\n",
      "Tagged Sentence:\n",
      "Dark turn purpose attack set way . Significant impact book daughter manager behavior pressure . Price true we pressure culture design 22868 <B-Address> Strong <I-Address> Square <I-Address> Suite <I-Address> 603 <I-Address> serve answer .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [22,23,24,25,26]: \"22868 Strong Square Suite 603\"   [− Labels: Address (0.977)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Class speech structure ask prevent. Do tree actually 384 Moran River Suite 724 West Maureenport, NV 14327 forward.\n",
      "Tagged Sentence:\n",
      "Class speech structure ask prevent . Do tree actually 384 <B-Address> Moran <I-Address> River <I-Address> Suite <I-Address> 724 <I-Address> West <I-Address> Maureenport <I-Address> , <I-Address> NV <I-Address> 14327 <I-Address> forward .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [10,11,12,13,14,15,16,17,18,19]: \"384 Moran River Suite 724 West Maureenport , NV 14327\"   [− Labels: Address (0.9998)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Cold write close full likely actually plant method. Suite 139 Project father chair keep. Financial itself miss house reduce necessary.\n",
      "Tagged Sentence:\n",
      "Cold write close full likely actually plant method . Suite <B-Address> 139 <I-Address> Project father chair keep . Financial itself miss house reduce necessary .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [10,11]: \"Suite 139\"   [− Labels: Address (0.9267)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Cup happen say join improve would. Oil PM special parent executive foot series term. Operation adult result decision prevent talk well. 640 Eddie Mission Apt. 272 New Kimberly, ME 38505\n",
      "Tagged Sentence:\n",
      "Cup happen say join improve would . Oil PM special parent executive foot series term . Operation adult result decision prevent talk well . 640 <B-Address> Eddie <I-Address> Mission <I-Address> Apt <I-Address> . <I-Address> 272 <I-Address> New <I-Address> Kimberly <I-Address> , <I-Address> ME <I-Address> 38505 <I-Address>\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [25,26,27,28,29,30,31,32,33,34,35]: \"640 Eddie Mission Apt . 272 New Kimberly , ME 38505\"   [− Labels: Address (0.9669)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Book environmental site each produce more. Clearly 7112 Joanne Cape Apt. 685 ability support technology everything alone pressure.\n",
      "Tagged Sentence:\n",
      "Book environmental site each produce more . Clearly 7112 <B-Address> Joanne <I-Address> Cape <I-Address> Apt <I-Address> . <I-Address> 685 <I-Address> ability support technology everything alone pressure .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [9,10,11,12,13,14]: \"7112 Joanne Cape Apt . 685\"   [− Labels: Address (0.9874)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Suite 082 Behavior phone sign meeting service. Fish service attack present during security source.\n",
      "Tagged Sentence:\n",
      "Suite <B-Address> 082 <I-Address> Behavior phone sign meeting service . Fish service attack present during security source .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [1,2]: \"Suite 082\"   [− Labels: Address (0.9545)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Medical eye inside respond. Ability international change ccc 2224009433974117 ccc could what American actually rate. Whole although chance.\n",
      "Tagged Sentence:\n",
      "Medical eye inside respond . Ability international change ccc 2224009433974117 <B-CreditCardNumber> ccc could what American actually rate . Whole although chance .\n",
      "True Label: CreditCardNumber\n",
      "Entity\n",
      "Span [10]: \"2224009433974117\"   [− Labels: CreditCardNumber (0.9981)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Rock movement call turn minute American act soldier. Next customer similar agency ccc 4371942766026400604 ccc training industry. Painting once itself camera go yes.\n",
      "Tagged Sentence:\n",
      "Rock movement call turn minute American act soldier . Next customer similar agency ccc 4371942766026400604 <B-CreditCardNumber> ccc training industry . Painting once itself camera go yes .\n",
      "True Label: CreditCardNumber\n",
      "Entity\n",
      "Span [15]: \"4371942766026400604\"   [− Labels: CreditCardNumber (0.9943)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Team deal growth check human. Small these American star subject loss ccc 4504414195582719 ccc measure.\n",
      "Tagged Sentence:\n",
      "Team deal growth check human . Small these American star subject loss ccc 4504414195582719 <B-CreditCardNumber> ccc measure .\n",
      "True Label: CreditCardNumber\n",
      "Entity\n",
      "Span [14]: \"4504414195582719\"   [− Labels: CreditCardNumber (0.9976)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Run society adult large. sss 070-94-9083 nnn Down phone many. Through admit involve life property decision data doctor.\n",
      "Tagged Sentence:\n",
      "Run society adult large . sss 070-94-9083 <B-SSN> nnn Down phone many . Through admit involve life property decision data doctor .\n",
      "True Label: SSN\n",
      "Entity\n",
      "Span [7]: \"070-94-9083\"   [− Labels: SSN (0.9987)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Sister their service tax water sit a. Hundred region bad source well else save. sss 617 15 2105 nnn\n",
      "Tagged Sentence:\n",
      "Sister their service tax water sit a . Hundred region bad source well else save . sss 617 <B-SSN> 15 <I-SSN> 2105 <I-SSN> nnn\n",
      "True Label: SSN\n",
      "Entity\n",
      "Span [18,19,20]: \"617 15 2105\"   [− Labels: SSN (0.997)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Produce military act sss 765 70 5679 nnn bill. Source carry discussion use such attorney before. Friend air last. Even project mother maintain allow partner.\n",
      "Tagged Sentence:\n",
      "Produce military act sss 765 <B-SSN> 70 <I-SSN> 5679 <I-SSN> nnn bill . Source carry discussion use such attorney before . Friend air last . Even project mother maintain allow partner .\n",
      "True Label: SSN\n",
      "Entity\n",
      "Span [5,6,7]: \"765 70 5679\"   [− Labels: SSN (0.9978)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "sss 573-70-8827 nnn Man open upon. Activity note area behavior. Page none two morning.\n",
      "Tagged Sentence:\n",
      "sss 573-70-8827 <B-SSN> nnn Man open upon . Activity note area behavior . Page none two morning .\n",
      "True Label: SSN\n",
      "Entity\n",
      "Span [2]: \"573-70-8827\"   [− Labels: SSN (0.9961)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Discover our nothing try chance federal candidate. Indeed design eee barbaracarpenter@yahoo.com mmm high people.\n",
      "Tagged Sentence:\n",
      "Discover our nothing try chance federal candidate . Indeed design eee barbaracarpenter <B-Email> @ <I-Email> yahoo.com <I-Email> mmm high people .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [12,13,14]: \"barbaracarpenter @ yahoo.com\"   [− Labels: Email (0.9979)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Magazine day physical. Eight fill on whatever glass technology. Act as pass tell action pattern eee huertabruce@yahoo.com mmm every.\n",
      "Tagged Sentence:\n",
      "Magazine day physical . Eight fill on whatever glass technology . Act as pass tell action pattern eee huertabruce <B-Email> @ <I-Email> yahoo.com <I-Email> mmm every .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [19,20,21]: \"huertabruce @ yahoo.com\"   [− Labels: Email (0.9984)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "eee hensleyedward@gmail.com mmm Increase several him marriage word truth sort. Among economic system. Usually serve candidate moment.\n",
      "Tagged Sentence:\n",
      "eee hensleyedward <B-Email> @ <I-Email> gmail.com <I-Email> mmm Increase several him marriage word truth sort . Among economic system . Usually serve candidate moment .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [2,3,4]: \"hensleyedward @ gmail.com\"   [− Labels: Email (0.9944)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Lose meet left kitchen organization herself. Business majority our. They job watch reason meet eee emily86@gmail.com mmm drive.\n",
      "Tagged Sentence:\n",
      "Lose meet left kitchen organization herself . Business majority our . They job watch reason meet eee emily86 <B-Email> @ <I-Email> gmail.com <I-Email> mmm drive .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [18,19,20]: \"emily86 @ gmail.com\"   [− Labels: Email (0.9867)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Save fall card care anyone pressure. Remember eee susan68@ramirez.biz mmm sister offer draw. Take field because return fear guess.\n",
      "Tagged Sentence:\n",
      "Save fall card care anyone pressure . Remember eee susan68 <B-Email> @ <I-Email> ramirez.biz <I-Email> mmm sister offer draw . Take field because return fear guess .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [10,11,12]: \"susan68 @ ramirez.biz\"   [− Labels: Email (0.977)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "General attorney record ten much remember. Eye live ask eee bridget58@gmail.com mmm support.\n",
      "Tagged Sentence:\n",
      "General attorney record ten much remember . Eye live ask eee bridget58 <B-Email> @ <I-Email> gmail.com <I-Email> mmm support .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [12,13,14]: \"bridget58 @ gmail.com\"   [− Labels: Email (0.9951)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Trouble religious hear environmental teacher get ZSH 214 forget. Test executive whole pass design four contain.\n",
      "Tagged Sentence:\n",
      "Trouble religious hear environmental teacher get ZSH <B-Plates> 214 <I-Plates> forget . Test executive whole pass design four contain .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [7,8]: \"ZSH 214\"   [− Labels: Plates (0.9422)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Draw 40LR5 feeling might. Under lawyer part senior.\n",
      "Tagged Sentence:\n",
      "Draw 40LR5 <B-Plates> feeling might . Under lawyer part senior .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [2]: \"40LR5\"   [− Labels: Plates (0.9975)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Able this character evidence woman it want. I require popular BAA0043 off maintain.\n",
      "Tagged Sentence:\n",
      "Able this character evidence woman it want . I require popular BAA0043 <B-Plates> off maintain .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [12]: \"BAA0043\"   [− Labels: Plates (0.9998)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Of staff international box would also. Arrive region actually training. 255-519\n",
      "Tagged Sentence:\n",
      "Of staff international box would also . Arrive region actually training . 255-519 <B-Plates>\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [13]: \"255-519\"   [− Labels: Plates (0.9212)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Population religious effort whatever contain. Employee general wife another thus mission others. 22-C881 Story year owner easy common late. Before build not gun pay upon.\n",
      "Tagged Sentence:\n",
      "Population religious effort whatever contain . Employee general wife another thus mission others . 22-C881 <B-Plates> Story year owner easy common late . Before build not gun pay upon .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [15]: \"22-C881\"   [− Labels: Plates (0.9993)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Whose raise soon participant S52 1IO alone. Value design teacher which.\n",
      "Tagged Sentence:\n",
      "Whose raise soon participant S52 <B-Plates> 1IO <I-Plates> alone . Value design teacher which .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [5,6]: \"S52 1IO\"   [− Labels: Plates (0.9781)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Ball idea ever move. Sign writer third teach drop perhaps sometimes. Explain happy me good enjoy.\n",
      "Tagged Sentence:\n",
      "Ball idea ever move . Sign writer third teach drop perhaps sometimes . Explain happy me good enjoy .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Usually cold thousand professional TV direction care. Carry but role strong sister few. Region base single investment.\n",
      "Tagged Sentence:\n",
      "Usually cold thousand professional TV direction care . Carry but role strong sister few . Region base single investment .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Old start difficult others. Move decide shake talk million candidate.\n",
      "Tagged Sentence:\n",
      "Old start difficult others . Move decide shake talk million candidate .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Manager physical respond that teach father together. Republican in recently ahead.\n",
      "Tagged Sentence:\n",
      "Manager physical respond that teach father together . Republican in recently ahead .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Couple job civil green road news senior. Occur put standard air collection actually thus. Single country would them.\n",
      "Tagged Sentence:\n",
      "Couple job civil green road news senior . Occur put standard air collection actually thus . Single country would them .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run some basic sanity checks\n",
    "\n",
    "tests = [\n",
    "    # name\n",
    "    (\"Hold home fight nor customer defense. Shields Shake player something.\",\"Name\"),\n",
    "    (\"Box direction clear sense democratic power. Adult determine rule Deanna across sometimes according.\",\"Name\"),\n",
    "    (\"High same pass Smith change. Effort board fly onto middle detail. Ahead chance small ability reduce under. Middle policy use single become.\",\"Name\"),\n",
    "    (\"Product similar final sense senior least. Model explain reveal American they behind source. Join Ariana White president other arm until feel force.\",\"Name\"),\n",
    "    (\"Matthew Haas Market Republican hand sign.\",\"Name\"),\n",
    "    (\"Whom simple Franklin nice three car. Music answer southern performance glass around.\",\"Name\"),\n",
    "    (\"Everybody small suggest into president. Over manager Charles government they.\",\"Name\"),\n",
    "    # address\n",
    "    (\"Dark turn purpose attack set way. Significant impact book daughter manager behavior pressure. Price true we pressure culture design 22868 Strong Square Suite 603 serve answer.\",\"Address\"),\n",
    "    (\"Class speech structure ask prevent. Do tree actually 384 Moran River Suite 724 West Maureenport, NV 14327 forward.\",\"Address\"),\n",
    "    (\"Cold write close full likely actually plant method. Suite 139 Project father chair keep. Financial itself miss house reduce necessary.\",\"Address\"),\n",
    "    (\"Cup happen say join improve would. Oil PM special parent executive foot series term. Operation adult result decision prevent talk well. 640 Eddie Mission Apt. 272 New Kimberly, ME 38505\",\"Address\"),\n",
    "    (\"Book environmental site each produce more. Clearly 7112 Joanne Cape Apt. 685 ability support technology everything alone pressure.\",\"Address\"),\n",
    "    (\"Suite 082 Behavior phone sign meeting service. Fish service attack present during security source.\",\"Address\"),\n",
    "    # credit card\n",
    "    (\"Medical eye inside respond. Ability international change 2224009433974117 could what American actually rate. Whole although chance.\",\"CreditCardNumber\"),\n",
    "    (\"Rock movement call turn minute American act soldier. Next customer similar agency 4371942766026400604 training industry. Painting once itself camera go yes.\",\"CreditCardNumber\"),\n",
    "    (\"Team deal growth check human. Small these American star subject loss 4504414195582719 measure.\",\"CreditCardNumber\"),\n",
    "    # ssn\n",
    "    (\"Run society adult large. 070-94-9083 Down phone many. Through admit involve life property decision data doctor.\",\"SSN\"),\n",
    "    (\"Sister their service tax water sit a. Hundred region bad source well else save. 617 15 2105\",\"SSN\"),\n",
    "    (\"Produce military act 765 70 5679 bill. Source carry discussion use such attorney before. Friend air last. Even project mother maintain allow partner.\",\"SSN\"),\n",
    "    (\"573-70-8827 Man open upon. Activity note area behavior. Page none two morning.\",\"SSN\"),\n",
    "    # email\n",
    "    (\"Discover our nothing try chance federal candidate. Indeed design barbaracarpenter@yahoo.com high people.\",\"Email\"),\n",
    "    (\"Magazine day physical. Eight fill on whatever glass technology. Act as pass tell action pattern huertabruce@yahoo.com every.\",\"Email\"),\n",
    "    (\"hensleyedward@gmail.com Increase several him marriage word truth sort. Among economic system. Usually serve candidate moment.\",\"Email\"),\n",
    "    (\"Lose meet left kitchen organization herself. Business majority our. They job watch reason meet emily86@gmail.com drive.\",\"Email\"),\n",
    "    (\"Save fall card care anyone pressure. Remember susan68@ramirez.biz sister offer draw. Take field because return fear guess.\",\"Email\"),\n",
    "    (\"General attorney record ten much remember. Eye live ask bridget58@gmail.com support.\",\"Email\"),\n",
    "    # plate\n",
    "    (\"Trouble religious hear environmental teacher get ZSH 214 forget. Test executive whole pass design four contain.\",\"Plate\"),\n",
    "    (\"Draw 40LR5 feeling might. Under lawyer part senior.\",\"Plate\"),\n",
    "    (\"Able this character evidence woman it want. I require popular BAA0043 off maintain.\",\"Plate\"),\n",
    "    (\"Of staff international box would also. Arrive region actually training. 255-519\",\"Plate\"),\n",
    "    (\"Population religious effort whatever contain. Employee general wife another thus mission others. 22-C881 Story year owner easy common late. Before build not gun pay upon.\",\"Plate\"),\n",
    "    (\"Whose raise soon participant S52 1IO alone. Value design teacher which.\",\"Plate\"),\n",
    "    # none\n",
    "    (\"Ball idea ever move. Sign writer third teach drop perhaps sometimes. Explain happy me good enjoy.\",\"None\"),\n",
    "    (\"Usually cold thousand professional TV direction care. Carry but role strong sister few. Region base single investment.\",\"None\"),\n",
    "    (\"Old start difficult others. Move decide shake talk million candidate.\",\"None\"),\n",
    "    (\"Manager physical respond that teach father together. Republican in recently ahead.\",\"None\"),\n",
    "    (\"Couple job civil green road news senior. Occur put standard air collection actually thus. Single country would them.\",\"None\"),\n",
    "\n",
    "]\n",
    "\n",
    "engine =rules.RulesEngine()\n",
    "\n",
    "for text, true_label in tests:\n",
    "    text = engine.pin_text(text)\n",
    "    sentence = Sentence(text)\n",
    "    # predict the tags\n",
    "    model.predict(sentence)\n",
    "    print(\"Sentence:\")\n",
    "    print(text)\n",
    "    print(\"Tagged Sentence:\")\n",
    "    print(sentence.to_tagged_string())\n",
    "    print(\"True Label:\", true_label)\n",
    "    print(\"Entity\")\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        print(entity)\n",
    "    print(\"\\n\")"
   ]
  }
 ]
}