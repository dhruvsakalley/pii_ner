{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('ner': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c9e9e9c2c630163d1306c3642fc8a6e53d34dc83778d6517d9e34b96a0c61c48"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# PII Data NER\n",
    "\n",
    "## Data\n",
    "An excel file containing these sheets:\n",
    "- Export Summary\n",
    "- PII Train Large Data - PII Trai (800 rows)\n",
    "- PII Test Data - PII Test Data (16000 rows\n",
    "\n",
    "## Initial observations/ assumptions:\n",
    "- The training data is very limited, making the exercise a good candiate for either transfer learning approach or if required semi-supervised learning approach with data augmentation.\n",
    "- A sentence can have more than one labels, which makes this a multilabel classification problem\n",
    "- Certain entities such as email, ssn, credit cards, follow a well known pattern. This makes them easier to detect with non-stocastic rule based methods\n",
    "- Other entities such as names and addresses have more pattern variance and might require a more machine learning centric approach.\n",
    "- On the other hand the test dataset only requires one label and one PII value, which means this problem forces an assumption that this is one-vs-all classification simplification.\n",
    "- Additionally, the instructions specifically ask for building a machine learning model, so it' best to skip the regex like rule based approaches since they would be trivial solutions, and not justify the intent of the exercise.\n",
    "- The problem does not constrain on the compute resources, and does not constrain on the inference time requirements, so it is safe to assume the best bet is to optimize for better accuract / f1- scores.\n",
    "- The solution should specifically address Entity ambiguity w.r.t overlapping classes (polysemic words) and just the PII, thereby contextual disambiguation needs to be implemented and detailed.\n",
    "\n",
    "## Solution Space\n",
    "- I'd treat this problem as a token sequence classification exercise where token is a unit comprising the sequence. \n",
    "- Since information is text is contiguous w.r.t token boundaries, it is safe to consider variable token descriptions, such as a token could be a character or a sub word or a word.\n",
    "- Standard approaches for named entity recorgnition can come in handy, the best expression of training data would be in CONLL format, including part of speed analysis followed IOB tagging using either RNN models or similar approaches.\n",
    "- Since the exercise is time bound, as a simplification, it is safe to start with off-the-shelf transformer models and then iteratively optimize.\n",
    "\n",
    "## Evaluation Criteria\n",
    "There will be a 2 part evaluation\n",
    "- To determine the performance on a holdout set (with crossvalidation for a real usage, skipped)\n",
    "  - Report microavg F1 Score, precision and recall for each class\n",
    "  - A full phrase match might be a good criteria for evaluation.\n",
    "\n",
    "- To determine perfomance of some known desired behavious with a custom checklist for model explainability and reliability. (Future, for now just test on a small list)\n",
    "    - Robustness estimates could be included to further harden the models.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "# local files\n",
    "import rules\n",
    "import preprocess\n",
    "import datagen\n",
    "\n",
    "from typing import List\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from flair.data import Sentence, Corpus\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.datasets import ColumnCorpus\n",
    "from flair.embeddings import FlairEmbeddings, WordEmbeddings, StackedEmbeddings, TokenEmbeddings,TransformerWordEmbeddings\n",
    "\n",
    "random.seed(369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_excel(\"../data/PII_Train_Large_Data_Test_Data.xlsx\",sheet_name=\"PII Train Large Data - PII Trai\", skiprows=1, index_col=None, na_values=['NA'], usecols = \"A,B,C\")\n",
    "# shuffle\n",
    "raw_data = raw_data.sample(frac=1,random_state=369).reset_index(drop=True)"
   ]
  },
  {
   "source": [
    "### Data Exploration\n",
    "Obervations:\n",
    "- total classes present = 8\n",
    "- classes are balanced\n",
    "- 60/20/20 split makes sense for train/test/dev\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                Text            Labels  \\\n",
       "0  Quality whom pay travel our 4914569109182 tabl...  CreditCardNumber   \n",
       "1  History effort 427 68 3081 system kitchen. Hea...               SSN   \n",
       "2  Team Republican him Jessica Ellis reveal. Play...              Name   \n",
       "3  Radio respond perhaps western loss blood. Turn...             Email   \n",
       "4      Ready off score 8H 67881 foot market protect.            Plates   \n",
       "\n",
       "                              PII  \n",
       "0                   4914569109182  \n",
       "1                     427 68 3081  \n",
       "2                   Jessica Ellis  \n",
       "3  jrodriguez@mccarthy-lawson.biz  \n",
       "4                        8H 67881  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Labels</th>\n      <th>PII</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Quality whom pay travel our 4914569109182 tabl...</td>\n      <td>CreditCardNumber</td>\n      <td>4914569109182</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>History effort 427 68 3081 system kitchen. Hea...</td>\n      <td>SSN</td>\n      <td>427 68 3081</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Team Republican him Jessica Ellis reveal. Play...</td>\n      <td>Name</td>\n      <td>Jessica Ellis</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Radio respond perhaps western loss blood. Turn...</td>\n      <td>Email</td>\n      <td>jrodriguez@mccarthy-lawson.biz</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ready off score 8H 67881 foot market protect.</td>\n      <td>Plates</td>\n      <td>8H 67881</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Labels  Text\n",
       "0           Address   100\n",
       "1  CreditCardNumber   100\n",
       "2             Email   100\n",
       "3              Name   100\n",
       "4              None   100\n",
       "5      Phone_number   100\n",
       "6            Plates   100\n",
       "7               SSN   100"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Labels</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Address</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CreditCardNumber</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Email</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Name</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Phone_number</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Plates</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SSN</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# show the distribution of class in the train set\n",
    "raw_data.groupby([\"Labels\"])['Text'].nunique().reset_index()"
   ]
  },
  {
   "source": [
    "## Data Augmentation\n",
    "- Less support for complex patterns such as <b>Name</b> and <b>Address</b> and those need to be augmented for a fair evaluation\n",
    "- Lucky for me there is an easy way to generate fake names and addresses, let's add those to the mix to increase support."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                Text   Labels  \\\n",
       "0  Form late billion probably blood. May growth J...     Name   \n",
       "1  Who wait fast develop 96947 Keller Squares Chr...  Address   \n",
       "2  Too response system laugh Brent Hawkins decisi...     Name   \n",
       "3  Institution action social become 238 Amber Cro...  Address   \n",
       "4  Between loss goal Angela Avery sea seem Republ...     Name   \n",
       "\n",
       "                                               PII  \n",
       "0                                 Jennifer Collier  \n",
       "1  96947 Keller Squares Christopherville, OR 83095  \n",
       "2                                    Brent Hawkins  \n",
       "3        238 Amber Crossroad Sandraburgh, OR 64251  \n",
       "4                                     Angela Avery  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Labels</th>\n      <th>PII</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Form late billion probably blood. May growth J...</td>\n      <td>Name</td>\n      <td>Jennifer Collier</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Who wait fast develop 96947 Keller Squares Chr...</td>\n      <td>Address</td>\n      <td>96947 Keller Squares Christopherville, OR 83095</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Too response system laugh Brent Hawkins decisi...</td>\n      <td>Name</td>\n      <td>Brent Hawkins</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Institution action social become 238 Amber Cro...</td>\n      <td>Address</td>\n      <td>238 Amber Crossroad Sandraburgh, OR 64251</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Between loss goal Angela Avery sea seem Republ...</td>\n      <td>Name</td>\n      <td>Angela Avery</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Ref: datagen.py for details\n",
    "gen = datagen.DataGenerator(max_nb_chars=80, n=400, seed=369)\n",
    "fake_data = gen.generate_fake_data()\n",
    "fake_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  Text   Labels        PII\n",
       "767  Other discuss light nature. Later cause Apt .1...  Address  Apt .1033\n",
       "771  Only allow attack think current. Apt 402 Call ...  Address    Apt 402\n",
       "775  Star large two leader foot Apt 958 your. Color...  Address    Apt 958\n",
       "793  Suffer despite Apt 3793 later on. Fine final c...  Address   Apt 3793\n",
       "799  Concern modern agent nice physical old. Apt .2...  Address  Apt .2955"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Labels</th>\n      <th>PII</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>767</th>\n      <td>Other discuss light nature. Later cause Apt .1...</td>\n      <td>Address</td>\n      <td>Apt .1033</td>\n    </tr>\n    <tr>\n      <th>771</th>\n      <td>Only allow attack think current. Apt 402 Call ...</td>\n      <td>Address</td>\n      <td>Apt 402</td>\n    </tr>\n    <tr>\n      <th>775</th>\n      <td>Star large two leader foot Apt 958 your. Color...</td>\n      <td>Address</td>\n      <td>Apt 958</td>\n    </tr>\n    <tr>\n      <th>793</th>\n      <td>Suffer despite Apt 3793 later on. Fine final c...</td>\n      <td>Address</td>\n      <td>Apt 3793</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>Concern modern agent nice physical old. Apt .2...</td>\n      <td>Address</td>\n      <td>Apt .2955</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# special patterns for address\n",
    "fake_data[fake_data['Labels']=='Address'][fake_data['PII'].map(lambda l: len(l)<10)].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented data is a combination of original data and the fake data\n",
    "aug_data = pd.concat([raw_data, fake_data])\n",
    "# shuffle again\n",
    "aug_data = aug_data.sample(frac=1,random_state=369).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Labels  Text\n",
       "0           Address   500\n",
       "1  CreditCardNumber   100\n",
       "2             Email   100\n",
       "3              Name   500\n",
       "4              None   100\n",
       "5      Phone_number   100\n",
       "6            Plates   100\n",
       "7               SSN   100"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Labels</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Address</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CreditCardNumber</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Email</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Name</td>\n      <td>500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Phone_number</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Plates</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SSN</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# show the distribution of class in the train set\n",
    "# Note: Now we have 500 examples of Name and Address\n",
    "aug_data.groupby([\"Labels\"])['Text'].nunique().reset_index()"
   ]
  },
  {
   "source": [
    "## Tokenization\n",
    "- This is one of the key aspects for getting the correct NER.\n",
    "- Known patterns can be pinned with deterministic tokens in order to aid the recognition.\n",
    "- Flair's internal tokenization handles special characters by adding spaces, which makes for special handling in case of email, where \"@\" symbol must be replaced with \" @ \" and an inverse transform might be needed on the predicted spans before consumption.\n",
    "\n",
    "Here is an example of email sentence tokenized, notice tokens <b>eee</b> @ <b>mmm</b>:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Email\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Film O\\n',\n",
       " 'range O\\n',\n",
       " 'sound. O\\n',\n",
       " 'People O\\n',\n",
       " 'age O\\n',\n",
       " 'that. O\\n',\n",
       " 'eeeee O\\n',\n",
       " 'douglaslewis B-Email\\n',\n",
       " '@ I-Email\\n',\n",
       " 'yahoo.com I-Email\\n',\n",
       " 'mmmmm O\\n',\n",
       " '\\n']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Here is an example of how the tokenization takes place.\n",
    "converter = preprocess.CoNLLConverter()\n",
    "index = 69\n",
    "print(aug_data['Labels'].iloc[index])\n",
    "converter.bio_tagger(aug_data['Text'].iloc[index], aug_data['Labels'].iloc[index], aug_data['PII'].iloc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Email\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Community O\\n',\n",
       " 'stand O\\n',\n",
       " 'nice O\\n',\n",
       " 'whatever O\\n',\n",
       " 'film. O\\n',\n",
       " 'Blood O\\n',\n",
       " 'go O\\n',\n",
       " 'particular O\\n',\n",
       " 'same O\\n',\n",
       " 'wait O\\n',\n",
       " 'record O\\n',\n",
       " 'interview. O\\n',\n",
       " 'Position O\\n',\n",
       " 'sometimes O\\n',\n",
       " 'test O\\n',\n",
       " 'shoulder O\\n',\n",
       " 'save O\\n',\n",
       " 'huge O\\n',\n",
       " 'course. O\\n',\n",
       " 'Almost O\\n',\n",
       " 'they O\\n',\n",
       " 'eeeee O\\n',\n",
       " 'diazamanda B-Email\\n',\n",
       " '@ I-Email\\n',\n",
       " 'johnson.info I-Email\\n',\n",
       " 'mmmmm O\\n',\n",
       " 'himself O\\n',\n",
       " 'less O\\n',\n",
       " 'interesting O\\n',\n",
       " 'education. O\\n',\n",
       " '\\n']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Here is an example of how the tokenization takes place for emails.\n",
    "converter = preprocess.CoNLLConverter()\n",
    "index = aug_data['Labels'][aug_data['Labels']==\"Email\"].index[0]\n",
    "print(aug_data['Labels'].iloc[index])\n",
    "converter.bio_tagger(aug_data['Text'].iloc[index], aug_data['Labels'].iloc[index], aug_data['PII'].iloc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             Labels  Text\n",
       "0           Address   100\n",
       "1  CreditCardNumber    20\n",
       "2             Email    20\n",
       "3              Name   100\n",
       "4              None    20\n",
       "5      Phone_number    20\n",
       "6            Plates    20\n",
       "7               SSN    20"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Labels</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Address</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CreditCardNumber</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Email</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Name</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>None</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Phone_number</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Plates</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SSN</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# partition data into train, test, dev\n",
    "X_train, X_test, y_train, y_test = train_test_split(aug_data.index, aug_data[\"Labels\"], test_size=0.2, random_state=369 ,stratify=aug_data[\"Labels\"])\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.25, random_state=369, stratify=y_train)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# verify split distribution is identical\n",
    "aug_data.loc[X_dev,:].groupby([\"Labels\"])['Text'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save splits for later evaluations\n",
    "aug_data.to_excel(\"../data/augmented_data.xlsx\", columns=['Text','Labels','PII'])\n",
    "aug_data.loc[X_train,:].to_excel(\"../data/augmented_data_train.xlsx\", columns=['Text','Labels','PII'])\n",
    "aug_data.loc[X_dev,:].to_excel(\"../data/augmented_data_test.xlsx\", columns=['Text','Labels','PII'])\n",
    "aug_data.loc[X_dev,:].to_excel(\"../data/augmented_data_dev.xlsx\", columns=['Text','Labels','PII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all tagged data for visual checks\n",
    "with open(\"../data/pii_conll_data_all.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for index, row in aug_data.iterrows():\n",
    "        tagged_data = converter.bio_tagger(row['Text'], row['Labels'], row['PII'])\n",
    "        f.writelines(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tagged train.txt\n",
    "with open(\"../data/train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for index, row in aug_data.loc[X_train,:].iterrows():\n",
    "        tagged_data = converter.bio_tagger(row['Text'], row['Labels'], row['PII'])\n",
    "        f.writelines(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tagged test.txt\n",
    "with open(\"../data/test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for index, row in aug_data.loc[X_test,:].iterrows():\n",
    "        tagged_data = converter.bio_tagger(row['Text'], row['Labels'], row['PII'])\n",
    "        f.writelines(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tagged dev.txt\n",
    "with open(\"../data/dev.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for index, row in aug_data.loc[X_dev,:].iterrows():\n",
    "        tagged_data = converter.bio_tagger(row['Text'], row['Labels'], row['PII'])\n",
    "        f.writelines(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-02-01 11:46:10,741 Reading data from ..\\data\n",
      "2021-02-01 11:46:10,742 Train: ..\\data\\train.txt\n",
      "2021-02-01 11:46:10,743 Dev: ..\\data\\dev.txt\n",
      "2021-02-01 11:46:10,744 Test: ..\\data\\test.txt\n"
     ]
    }
   ],
   "source": [
    "#Load the corpus\n",
    "# define columns\n",
    "columns = {0 : 'text', 1 : 'ner'}\n",
    "# directory where the data resides\n",
    "data_folder = '../data'\n",
    "# initializing the corpus\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file = 'train.txt',\n",
    "                              test_file = 'test.txt',\n",
    "                              dev_file = 'dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init Flair embeddings\n",
    "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
    "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
    "\n",
    "# ***\n",
    "# Note: This would be helpful if we had well formed sentences, this would really help in \n",
    "# the case of polysemic words, which we currently don't have in the train / test data\n",
    "# since that would mean having PER, LOC\n",
    "# ***\n",
    "\n",
    "# init multilingual BERT\n",
    "# bert_embedding = TransformerWordEmbeddings('bert-base-multilingual-cased')\n",
    "\n",
    "embedding_types : List[TokenEmbeddings] = [\n",
    "        WordEmbeddings('glove'),\n",
    "        ## other embeddings\n",
    "        flair_forward_embedding, \n",
    "        flair_backward_embedding, \n",
    "        # bert_embedding\n",
    "        ]\n",
    "embeddings : StackedEmbeddings = StackedEmbeddings(\n",
    "                                 embeddings=embedding_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dictionary with 16 tags: <unk>, O, B-Name, I-Name, B-Address, I-Address, B-Plates, B-Email, I-Email, B-SSN, I-SSN, B-Phone_number, I-Plates, B-CreditCardNumber, <START>, <STOP>\nSequenceTagger(\n  (embeddings): StackedEmbeddings(\n    (list_embedding_0): WordEmbeddings('glove')\n    (list_embedding_1): FlairEmbeddings(\n      (lm): LanguageModel(\n        (drop): Dropout(p=0.1, inplace=False)\n        (encoder): Embedding(11854, 100)\n        (rnn): LSTM(100, 2048)\n        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n      )\n    )\n    (list_embedding_2): FlairEmbeddings(\n      (lm): LanguageModel(\n        (drop): Dropout(p=0.1, inplace=False)\n        (encoder): Embedding(11854, 100)\n        (rnn): LSTM(100, 2048)\n        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n      )\n    )\n  )\n  (word_dropout): WordDropout(p=0.05)\n  (locked_dropout): LockedDropout(p=0.5)\n  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n  (linear): Linear(in_features=512, out_features=16, bias=True)\n  (beta): 1.0\n  (weights): None\n  (weight_tensor) None\n)\n"
     ]
    }
   ],
   "source": [
    "# prepare the tag for ner\n",
    "tag_type = 'ner'\n",
    "# make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)\n",
    "\n",
    "tagger : SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                       embeddings=embeddings,\n",
    "                                       tag_dictionary=tag_dictionary,\n",
    "                                       tag_type=tag_type,\n",
    "                                       use_crf=True)\n",
    "\n",
    "# describe the network\n",
    "print(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-02-01 11:46:15,487 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:15,488 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "    (list_embedding_1): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(11854, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (list_embedding_2): FlairEmbeddings(\n",
      "      (lm): LanguageModel(\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (encoder): Embedding(11854, 100)\n",
      "        (rnn): LSTM(100, 2048)\n",
      "        (decoder): Linear(in_features=2048, out_features=11854, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
      "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=16, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-02-01 11:46:15,489 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:15,489 Corpus: \"Corpus: 960 train + 320 dev + 320 test sentences\"\n",
      "2021-02-01 11:46:15,490 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:15,491 Parameters:\n",
      "2021-02-01 11:46:15,491  - learning_rate: \"0.1\"\n",
      "2021-02-01 11:46:15,492  - mini_batch_size: \"24\"\n",
      "2021-02-01 11:46:15,493  - patience: \"3\"\n",
      "2021-02-01 11:46:15,494  - anneal_factor: \"0.5\"\n",
      "2021-02-01 11:46:15,494  - max_epochs: \"150\"\n",
      "2021-02-01 11:46:15,495  - shuffle: \"True\"\n",
      "2021-02-01 11:46:15,496  - train_with_dev: \"False\"\n",
      "2021-02-01 11:46:15,497  - batch_growth_annealing: \"False\"\n",
      "2021-02-01 11:46:15,498 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:15,498 Model training base path: \"..\\model\\taggers\\pii-ner-v1\"\n",
      "2021-02-01 11:46:15,499 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:15,499 Device: cuda:0\n",
      "2021-02-01 11:46:15,500 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:15,501 Embeddings storage mode: cpu\n",
      "2021-02-01 11:46:15,503 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:17,045 epoch 1 - iter 4/40 - loss 32.63334608 - samples/sec: 62.30 - lr: 0.100000\n",
      "2021-02-01 11:46:18,340 epoch 1 - iter 8/40 - loss 23.43003392 - samples/sec: 74.19 - lr: 0.100000\n",
      "2021-02-01 11:46:19,797 epoch 1 - iter 12/40 - loss 19.50225910 - samples/sec: 65.93 - lr: 0.100000\n",
      "2021-02-01 11:46:21,114 epoch 1 - iter 16/40 - loss 17.37028801 - samples/sec: 72.89 - lr: 0.100000\n",
      "2021-02-01 11:46:22,420 epoch 1 - iter 20/40 - loss 15.75077481 - samples/sec: 73.51 - lr: 0.100000\n",
      "2021-02-01 11:46:23,757 epoch 1 - iter 24/40 - loss 14.29124749 - samples/sec: 71.80 - lr: 0.100000\n",
      "2021-02-01 11:46:25,110 epoch 1 - iter 28/40 - loss 13.23354999 - samples/sec: 71.05 - lr: 0.100000\n",
      "2021-02-01 11:46:26,484 epoch 1 - iter 32/40 - loss 12.37490404 - samples/sec: 69.90 - lr: 0.100000\n",
      "2021-02-01 11:46:27,743 epoch 1 - iter 36/40 - loss 11.60442287 - samples/sec: 76.28 - lr: 0.100000\n",
      "2021-02-01 11:46:29,092 epoch 1 - iter 40/40 - loss 10.89595441 - samples/sec: 71.20 - lr: 0.100000\n",
      "2021-02-01 11:46:29,093 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:29,094 EPOCH 1 done: loss 10.8960 - lr 0.1000000\n",
      "2021-02-01 11:46:33,032 DEV : loss 3.3010094165802 - score 0.4913\n",
      "2021-02-01 11:46:33,049 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:46:36,351 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:36,913 epoch 2 - iter 4/40 - loss 4.19314688 - samples/sec: 171.12 - lr: 0.100000\n",
      "2021-02-01 11:46:37,451 epoch 2 - iter 8/40 - loss 4.14951560 - samples/sec: 179.10 - lr: 0.100000\n",
      "2021-02-01 11:46:38,034 epoch 2 - iter 12/40 - loss 3.96029890 - samples/sec: 164.66 - lr: 0.100000\n",
      "2021-02-01 11:46:38,649 epoch 2 - iter 16/40 - loss 3.73111069 - samples/sec: 156.36 - lr: 0.100000\n",
      "2021-02-01 11:46:39,213 epoch 2 - iter 20/40 - loss 3.54048758 - samples/sec: 170.50 - lr: 0.100000\n",
      "2021-02-01 11:46:39,787 epoch 2 - iter 24/40 - loss 3.47637147 - samples/sec: 167.26 - lr: 0.100000\n",
      "2021-02-01 11:46:40,324 epoch 2 - iter 28/40 - loss 3.29570882 - samples/sec: 179.09 - lr: 0.100000\n",
      "2021-02-01 11:46:40,859 epoch 2 - iter 32/40 - loss 3.13372569 - samples/sec: 180.12 - lr: 0.100000\n",
      "2021-02-01 11:46:41,409 epoch 2 - iter 36/40 - loss 3.02655262 - samples/sec: 174.52 - lr: 0.100000\n",
      "2021-02-01 11:46:41,957 epoch 2 - iter 40/40 - loss 2.90112477 - samples/sec: 175.42 - lr: 0.100000\n",
      "2021-02-01 11:46:41,958 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:41,958 EPOCH 2 done: loss 2.9011 - lr 0.1000000\n",
      "2021-02-01 11:46:43,124 DEV : loss 1.079824686050415 - score 0.9205\n",
      "2021-02-01 11:46:43,142 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:46:46,480 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:47,076 epoch 3 - iter 4/40 - loss 2.12755924 - samples/sec: 161.34 - lr: 0.100000\n",
      "2021-02-01 11:46:47,644 epoch 3 - iter 8/40 - loss 1.90322509 - samples/sec: 169.02 - lr: 0.100000\n",
      "2021-02-01 11:46:48,167 epoch 3 - iter 12/40 - loss 1.83341030 - samples/sec: 183.54 - lr: 0.100000\n",
      "2021-02-01 11:46:48,709 epoch 3 - iter 16/40 - loss 1.79535506 - samples/sec: 177.34 - lr: 0.100000\n",
      "2021-02-01 11:46:49,245 epoch 3 - iter 20/40 - loss 1.72968959 - samples/sec: 179.10 - lr: 0.100000\n",
      "2021-02-01 11:46:49,829 epoch 3 - iter 24/40 - loss 1.68503507 - samples/sec: 164.38 - lr: 0.100000\n",
      "2021-02-01 11:46:50,414 epoch 3 - iter 28/40 - loss 1.62512663 - samples/sec: 164.37 - lr: 0.100000\n",
      "2021-02-01 11:46:50,973 epoch 3 - iter 32/40 - loss 1.58014049 - samples/sec: 172.05 - lr: 0.100000\n",
      "2021-02-01 11:46:51,511 epoch 3 - iter 36/40 - loss 1.54476080 - samples/sec: 178.77 - lr: 0.100000\n",
      "2021-02-01 11:46:52,065 epoch 3 - iter 40/40 - loss 1.52217090 - samples/sec: 173.61 - lr: 0.100000\n",
      "2021-02-01 11:46:52,066 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:52,067 EPOCH 3 done: loss 1.5222 - lr 0.1000000\n",
      "2021-02-01 11:46:53,251 DEV : loss 0.4938148856163025 - score 0.9601\n",
      "2021-02-01 11:46:53,269 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:46:56,616 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:46:57,185 epoch 4 - iter 4/40 - loss 0.82773665 - samples/sec: 169.00 - lr: 0.100000\n",
      "2021-02-01 11:46:57,749 epoch 4 - iter 8/40 - loss 0.92050364 - samples/sec: 170.53 - lr: 0.100000\n",
      "2021-02-01 11:46:58,315 epoch 4 - iter 12/40 - loss 0.94603077 - samples/sec: 169.91 - lr: 0.100000\n",
      "2021-02-01 11:46:58,860 epoch 4 - iter 16/40 - loss 0.98157887 - samples/sec: 176.48 - lr: 0.100000\n",
      "2021-02-01 11:46:59,411 epoch 4 - iter 20/40 - loss 0.96431136 - samples/sec: 174.23 - lr: 0.100000\n",
      "2021-02-01 11:46:59,932 epoch 4 - iter 24/40 - loss 0.95868684 - samples/sec: 184.63 - lr: 0.100000\n",
      "2021-02-01 11:47:00,465 epoch 4 - iter 28/40 - loss 0.97793637 - samples/sec: 180.77 - lr: 0.100000\n",
      "2021-02-01 11:47:01,033 epoch 4 - iter 32/40 - loss 1.00125060 - samples/sec: 169.02 - lr: 0.100000\n",
      "2021-02-01 11:47:01,570 epoch 4 - iter 36/40 - loss 1.00432878 - samples/sec: 178.76 - lr: 0.100000\n",
      "2021-02-01 11:47:02,153 epoch 4 - iter 40/40 - loss 0.96776272 - samples/sec: 164.94 - lr: 0.100000\n",
      "2021-02-01 11:47:02,154 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:02,155 EPOCH 4 done: loss 0.9678 - lr 0.1000000\n",
      "2021-02-01 11:47:03,307 DEV : loss 0.27678221464157104 - score 0.9684\n",
      "2021-02-01 11:47:03,325 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:47:06,584 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:07,152 epoch 5 - iter 4/40 - loss 0.68443283 - samples/sec: 169.24 - lr: 0.100000\n",
      "2021-02-01 11:47:07,708 epoch 5 - iter 8/40 - loss 0.79801139 - samples/sec: 172.98 - lr: 0.100000\n",
      "2021-02-01 11:47:08,252 epoch 5 - iter 12/40 - loss 0.78354090 - samples/sec: 176.47 - lr: 0.100000\n",
      "2021-02-01 11:47:08,793 epoch 5 - iter 16/40 - loss 0.72631327 - samples/sec: 178.12 - lr: 0.100000\n",
      "2021-02-01 11:47:09,358 epoch 5 - iter 20/40 - loss 0.70294623 - samples/sec: 170.21 - lr: 0.100000\n",
      "2021-02-01 11:47:09,931 epoch 5 - iter 24/40 - loss 0.71901227 - samples/sec: 167.54 - lr: 0.100000\n",
      "2021-02-01 11:47:10,490 epoch 5 - iter 28/40 - loss 0.72831753 - samples/sec: 172.05 - lr: 0.100000\n",
      "2021-02-01 11:47:11,012 epoch 5 - iter 32/40 - loss 0.69293771 - samples/sec: 183.91 - lr: 0.100000\n",
      "2021-02-01 11:47:11,563 epoch 5 - iter 36/40 - loss 0.66700932 - samples/sec: 174.56 - lr: 0.100000\n",
      "2021-02-01 11:47:12,104 epoch 5 - iter 40/40 - loss 0.65184528 - samples/sec: 177.78 - lr: 0.100000\n",
      "2021-02-01 11:47:12,105 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:12,105 EPOCH 5 done: loss 0.6518 - lr 0.1000000\n",
      "2021-02-01 11:47:13,276 DEV : loss 0.18717226386070251 - score 0.9668\n",
      "2021-02-01 11:47:13,293 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:47:13,295 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:13,838 epoch 6 - iter 4/40 - loss 0.47465842 - samples/sec: 177.45 - lr: 0.100000\n",
      "2021-02-01 11:47:14,366 epoch 6 - iter 8/40 - loss 0.44728252 - samples/sec: 182.16 - lr: 0.100000\n",
      "2021-02-01 11:47:14,909 epoch 6 - iter 12/40 - loss 0.53819315 - samples/sec: 176.80 - lr: 0.100000\n",
      "2021-02-01 11:47:15,453 epoch 6 - iter 16/40 - loss 0.50538464 - samples/sec: 176.81 - lr: 0.100000\n",
      "2021-02-01 11:47:15,994 epoch 6 - iter 20/40 - loss 0.53237935 - samples/sec: 177.62 - lr: 0.100000\n",
      "2021-02-01 11:47:16,554 epoch 6 - iter 24/40 - loss 0.56388108 - samples/sec: 171.74 - lr: 0.100000\n",
      "2021-02-01 11:47:17,075 epoch 6 - iter 28/40 - loss 0.55955676 - samples/sec: 184.25 - lr: 0.100000\n",
      "2021-02-01 11:47:17,642 epoch 6 - iter 32/40 - loss 0.54014546 - samples/sec: 169.60 - lr: 0.100000\n",
      "2021-02-01 11:47:18,212 epoch 6 - iter 36/40 - loss 0.53784659 - samples/sec: 168.77 - lr: 0.100000\n",
      "2021-02-01 11:47:18,767 epoch 6 - iter 40/40 - loss 0.51178527 - samples/sec: 172.97 - lr: 0.100000\n",
      "2021-02-01 11:47:18,768 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:18,769 EPOCH 6 done: loss 0.5118 - lr 0.1000000\n",
      "2021-02-01 11:47:19,912 DEV : loss 0.1504875272512436 - score 0.975\n",
      "2021-02-01 11:47:19,930 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:47:23,229 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:23,819 epoch 7 - iter 4/40 - loss 0.45522567 - samples/sec: 163.27 - lr: 0.100000\n",
      "2021-02-01 11:47:24,351 epoch 7 - iter 8/40 - loss 0.46645171 - samples/sec: 180.78 - lr: 0.100000\n",
      "2021-02-01 11:47:24,897 epoch 7 - iter 12/40 - loss 0.52439713 - samples/sec: 176.16 - lr: 0.100000\n",
      "2021-02-01 11:47:25,454 epoch 7 - iter 16/40 - loss 0.52020278 - samples/sec: 172.65 - lr: 0.100000\n",
      "2021-02-01 11:47:25,977 epoch 7 - iter 20/40 - loss 0.54886329 - samples/sec: 183.57 - lr: 0.100000\n",
      "2021-02-01 11:47:26,510 epoch 7 - iter 24/40 - loss 0.54210299 - samples/sec: 180.33 - lr: 0.100000\n",
      "2021-02-01 11:47:27,045 epoch 7 - iter 28/40 - loss 0.52204249 - samples/sec: 179.78 - lr: 0.100000\n",
      "2021-02-01 11:47:27,563 epoch 7 - iter 32/40 - loss 0.51091810 - samples/sec: 186.41 - lr: 0.100000\n",
      "2021-02-01 11:47:28,132 epoch 7 - iter 36/40 - loss 0.49033101 - samples/sec: 169.01 - lr: 0.100000\n",
      "2021-02-01 11:47:28,669 epoch 7 - iter 40/40 - loss 0.47517231 - samples/sec: 179.10 - lr: 0.100000\n",
      "2021-02-01 11:47:28,670 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:28,670 EPOCH 7 done: loss 0.4752 - lr 0.1000000\n",
      "2021-02-01 11:47:29,833 DEV : loss 0.10954887419939041 - score 0.9734\n",
      "2021-02-01 11:47:29,851 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:47:29,852 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:30,405 epoch 8 - iter 4/40 - loss 0.45661705 - samples/sec: 173.91 - lr: 0.100000\n",
      "2021-02-01 11:47:30,926 epoch 8 - iter 8/40 - loss 0.36894030 - samples/sec: 184.62 - lr: 0.100000\n",
      "2021-02-01 11:47:31,463 epoch 8 - iter 12/40 - loss 0.35527934 - samples/sec: 179.10 - lr: 0.100000\n",
      "2021-02-01 11:47:32,018 epoch 8 - iter 16/40 - loss 0.35952306 - samples/sec: 173.28 - lr: 0.100000\n",
      "2021-02-01 11:47:32,553 epoch 8 - iter 20/40 - loss 0.34455393 - samples/sec: 179.78 - lr: 0.100000\n",
      "2021-02-01 11:47:33,084 epoch 8 - iter 24/40 - loss 0.34524341 - samples/sec: 181.13 - lr: 0.100000\n",
      "2021-02-01 11:47:33,618 epoch 8 - iter 28/40 - loss 0.34380065 - samples/sec: 179.78 - lr: 0.100000\n",
      "2021-02-01 11:47:34,170 epoch 8 - iter 32/40 - loss 0.34346359 - samples/sec: 174.53 - lr: 0.100000\n",
      "2021-02-01 11:47:34,761 epoch 8 - iter 36/40 - loss 0.35584117 - samples/sec: 162.70 - lr: 0.100000\n",
      "2021-02-01 11:47:35,313 epoch 8 - iter 40/40 - loss 0.36300381 - samples/sec: 173.88 - lr: 0.100000\n",
      "2021-02-01 11:47:35,314 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:35,315 EPOCH 8 done: loss 0.3630 - lr 0.1000000\n",
      "2021-02-01 11:47:36,446 DEV : loss 0.10071191936731339 - score 0.9933\n",
      "2021-02-01 11:47:36,463 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:47:39,755 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:40,314 epoch 9 - iter 4/40 - loss 0.29158442 - samples/sec: 172.03 - lr: 0.100000\n",
      "2021-02-01 11:47:40,834 epoch 9 - iter 8/40 - loss 0.33261308 - samples/sec: 184.97 - lr: 0.100000\n",
      "2021-02-01 11:47:41,367 epoch 9 - iter 12/40 - loss 0.29890175 - samples/sec: 180.46 - lr: 0.100000\n",
      "2021-02-01 11:47:41,939 epoch 9 - iter 16/40 - loss 0.34784421 - samples/sec: 167.83 - lr: 0.100000\n",
      "2021-02-01 11:47:42,478 epoch 9 - iter 20/40 - loss 0.39640876 - samples/sec: 178.44 - lr: 0.100000\n",
      "2021-02-01 11:47:43,027 epoch 9 - iter 24/40 - loss 0.37908072 - samples/sec: 175.19 - lr: 0.100000\n",
      "2021-02-01 11:47:43,567 epoch 9 - iter 28/40 - loss 0.35781559 - samples/sec: 178.10 - lr: 0.100000\n",
      "2021-02-01 11:47:44,146 epoch 9 - iter 32/40 - loss 0.35211875 - samples/sec: 166.09 - lr: 0.100000\n",
      "2021-02-01 11:47:44,686 epoch 9 - iter 36/40 - loss 0.37153697 - samples/sec: 178.11 - lr: 0.100000\n",
      "2021-02-01 11:47:45,269 epoch 9 - iter 40/40 - loss 0.36819806 - samples/sec: 165.09 - lr: 0.100000\n",
      "2021-02-01 11:47:45,270 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:45,271 EPOCH 9 done: loss 0.3682 - lr 0.1000000\n",
      "2021-02-01 11:47:46,422 DEV : loss 0.07849925756454468 - score 0.9933\n",
      "2021-02-01 11:47:46,441 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:47:49,782 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:50,352 epoch 10 - iter 4/40 - loss 0.33927426 - samples/sec: 168.70 - lr: 0.100000\n",
      "2021-02-01 11:47:50,909 epoch 10 - iter 8/40 - loss 0.29355138 - samples/sec: 172.66 - lr: 0.100000\n",
      "2021-02-01 11:47:51,446 epoch 10 - iter 12/40 - loss 0.27220028 - samples/sec: 179.09 - lr: 0.100000\n",
      "2021-02-01 11:47:51,963 epoch 10 - iter 16/40 - loss 0.26415547 - samples/sec: 186.01 - lr: 0.100000\n",
      "2021-02-01 11:47:52,533 epoch 10 - iter 20/40 - loss 0.28195415 - samples/sec: 168.69 - lr: 0.100000\n",
      "2021-02-01 11:47:53,125 epoch 10 - iter 24/40 - loss 0.29711140 - samples/sec: 162.69 - lr: 0.100000\n",
      "2021-02-01 11:47:53,723 epoch 10 - iter 28/40 - loss 0.31159770 - samples/sec: 161.08 - lr: 0.100000\n",
      "2021-02-01 11:47:54,266 epoch 10 - iter 32/40 - loss 0.30260790 - samples/sec: 177.12 - lr: 0.100000\n",
      "2021-02-01 11:47:54,807 epoch 10 - iter 36/40 - loss 0.31698032 - samples/sec: 177.78 - lr: 0.100000\n",
      "2021-02-01 11:47:55,356 epoch 10 - iter 40/40 - loss 0.31912993 - samples/sec: 175.18 - lr: 0.100000\n",
      "2021-02-01 11:47:55,357 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:55,358 EPOCH 10 done: loss 0.3191 - lr 0.1000000\n",
      "2021-02-01 11:47:56,487 DEV : loss 0.07664277404546738 - score 0.9767\n",
      "2021-02-01 11:47:56,505 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:47:56,506 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:47:57,066 epoch 11 - iter 4/40 - loss 0.29971020 - samples/sec: 171.74 - lr: 0.100000\n",
      "2021-02-01 11:47:57,619 epoch 11 - iter 8/40 - loss 0.34728997 - samples/sec: 173.91 - lr: 0.100000\n",
      "2021-02-01 11:47:58,146 epoch 11 - iter 12/40 - loss 0.31776262 - samples/sec: 182.16 - lr: 0.100000\n",
      "2021-02-01 11:47:58,686 epoch 11 - iter 16/40 - loss 0.31450515 - samples/sec: 178.11 - lr: 0.100000\n",
      "2021-02-01 11:47:59,261 epoch 11 - iter 20/40 - loss 0.30169973 - samples/sec: 167.25 - lr: 0.100000\n",
      "2021-02-01 11:47:59,801 epoch 11 - iter 24/40 - loss 0.29683697 - samples/sec: 178.11 - lr: 0.100000\n",
      "2021-02-01 11:48:00,348 epoch 11 - iter 28/40 - loss 0.28862141 - samples/sec: 175.84 - lr: 0.100000\n",
      "2021-02-01 11:48:00,870 epoch 11 - iter 32/40 - loss 0.28948733 - samples/sec: 184.62 - lr: 0.100000\n",
      "2021-02-01 11:48:01,425 epoch 11 - iter 36/40 - loss 0.28862719 - samples/sec: 173.29 - lr: 0.100000\n",
      "2021-02-01 11:48:01,990 epoch 11 - iter 40/40 - loss 0.28560963 - samples/sec: 170.21 - lr: 0.100000\n",
      "2021-02-01 11:48:01,991 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:01,992 EPOCH 11 done: loss 0.2856 - lr 0.1000000\n",
      "2021-02-01 11:48:03,140 DEV : loss 0.05619174614548683 - score 0.985\n",
      "2021-02-01 11:48:03,157 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:48:03,159 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:03,688 epoch 12 - iter 4/40 - loss 0.21165037 - samples/sec: 181.47 - lr: 0.100000\n",
      "2021-02-01 11:48:04,246 epoch 12 - iter 8/40 - loss 0.23780684 - samples/sec: 172.35 - lr: 0.100000\n",
      "2021-02-01 11:48:04,791 epoch 12 - iter 12/40 - loss 0.19954049 - samples/sec: 176.47 - lr: 0.100000\n",
      "2021-02-01 11:48:05,344 epoch 12 - iter 16/40 - loss 0.21737377 - samples/sec: 173.91 - lr: 0.100000\n",
      "2021-02-01 11:48:05,928 epoch 12 - iter 20/40 - loss 0.20540478 - samples/sec: 164.67 - lr: 0.100000\n",
      "2021-02-01 11:48:06,478 epoch 12 - iter 24/40 - loss 0.22279274 - samples/sec: 174.87 - lr: 0.100000\n",
      "2021-02-01 11:48:07,018 epoch 12 - iter 28/40 - loss 0.22024095 - samples/sec: 178.44 - lr: 0.100000\n",
      "2021-02-01 11:48:07,548 epoch 12 - iter 32/40 - loss 0.20973201 - samples/sec: 181.12 - lr: 0.100000\n",
      "2021-02-01 11:48:08,111 epoch 12 - iter 36/40 - loss 0.20606994 - samples/sec: 171.13 - lr: 0.100000\n",
      "2021-02-01 11:48:08,646 epoch 12 - iter 40/40 - loss 0.20508874 - samples/sec: 179.43 - lr: 0.100000\n",
      "2021-02-01 11:48:08,646 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:08,647 EPOCH 12 done: loss 0.2051 - lr 0.1000000\n",
      "2021-02-01 11:48:09,771 DEV : loss 0.058478906750679016 - score 0.99\n",
      "2021-02-01 11:48:09,788 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:48:09,789 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:10,346 epoch 13 - iter 4/40 - loss 0.12817637 - samples/sec: 172.66 - lr: 0.100000\n",
      "2021-02-01 11:48:10,884 epoch 13 - iter 8/40 - loss 0.13205552 - samples/sec: 178.76 - lr: 0.100000\n",
      "2021-02-01 11:48:11,484 epoch 13 - iter 12/40 - loss 0.18186334 - samples/sec: 160.28 - lr: 0.100000\n",
      "2021-02-01 11:48:12,012 epoch 13 - iter 16/40 - loss 0.23237519 - samples/sec: 182.16 - lr: 0.100000\n",
      "2021-02-01 11:48:12,537 epoch 13 - iter 20/40 - loss 0.22875383 - samples/sec: 183.56 - lr: 0.100000\n",
      "2021-02-01 11:48:13,113 epoch 13 - iter 24/40 - loss 0.23913983 - samples/sec: 166.67 - lr: 0.100000\n",
      "2021-02-01 11:48:13,642 epoch 13 - iter 28/40 - loss 0.23210241 - samples/sec: 181.47 - lr: 0.100000\n",
      "2021-02-01 11:48:14,188 epoch 13 - iter 32/40 - loss 0.22104059 - samples/sec: 176.15 - lr: 0.100000\n",
      "2021-02-01 11:48:14,727 epoch 13 - iter 36/40 - loss 0.22141956 - samples/sec: 178.11 - lr: 0.100000\n",
      "2021-02-01 11:48:15,241 epoch 13 - iter 40/40 - loss 0.22256657 - samples/sec: 187.13 - lr: 0.100000\n",
      "2021-02-01 11:48:15,241 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:15,242 EPOCH 13 done: loss 0.2226 - lr 0.1000000\n",
      "2021-02-01 11:48:16,376 DEV : loss 0.0685347393155098 - score 0.9867\n",
      "Epoch    13: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2021-02-01 11:48:16,393 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:48:16,394 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:16,910 epoch 14 - iter 4/40 - loss 0.20512081 - samples/sec: 186.41 - lr: 0.050000\n",
      "2021-02-01 11:48:17,450 epoch 14 - iter 8/40 - loss 0.22450182 - samples/sec: 178.11 - lr: 0.050000\n",
      "2021-02-01 11:48:18,036 epoch 14 - iter 12/40 - loss 0.19412905 - samples/sec: 163.82 - lr: 0.050000\n",
      "2021-02-01 11:48:18,567 epoch 14 - iter 16/40 - loss 0.21508631 - samples/sec: 181.13 - lr: 0.050000\n",
      "2021-02-01 11:48:19,093 epoch 14 - iter 20/40 - loss 0.21308240 - samples/sec: 182.51 - lr: 0.050000\n",
      "2021-02-01 11:48:19,642 epoch 14 - iter 24/40 - loss 0.20951232 - samples/sec: 174.86 - lr: 0.050000\n",
      "2021-02-01 11:48:20,166 epoch 14 - iter 28/40 - loss 0.22775836 - samples/sec: 183.54 - lr: 0.050000\n",
      "2021-02-01 11:48:20,750 epoch 14 - iter 32/40 - loss 0.21955607 - samples/sec: 164.65 - lr: 0.050000\n",
      "2021-02-01 11:48:21,288 epoch 14 - iter 36/40 - loss 0.21017991 - samples/sec: 178.44 - lr: 0.050000\n",
      "2021-02-01 11:48:21,823 epoch 14 - iter 40/40 - loss 0.20756062 - samples/sec: 179.76 - lr: 0.050000\n",
      "2021-02-01 11:48:21,823 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:21,824 EPOCH 14 done: loss 0.2076 - lr 0.0500000\n",
      "2021-02-01 11:48:22,946 DEV : loss 0.04162704199552536 - score 0.99\n",
      "2021-02-01 11:48:22,963 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:48:22,964 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:23,492 epoch 15 - iter 4/40 - loss 0.16165543 - samples/sec: 182.17 - lr: 0.050000\n",
      "2021-02-01 11:48:24,038 epoch 15 - iter 8/40 - loss 0.16842541 - samples/sec: 176.14 - lr: 0.050000\n",
      "2021-02-01 11:48:24,643 epoch 15 - iter 12/40 - loss 0.18744016 - samples/sec: 158.94 - lr: 0.050000\n",
      "2021-02-01 11:48:25,173 epoch 15 - iter 16/40 - loss 0.17642477 - samples/sec: 181.46 - lr: 0.050000\n",
      "2021-02-01 11:48:25,744 epoch 15 - iter 20/40 - loss 0.18784398 - samples/sec: 168.41 - lr: 0.050000\n",
      "2021-02-01 11:48:26,288 epoch 15 - iter 24/40 - loss 0.18974889 - samples/sec: 176.34 - lr: 0.050000\n",
      "2021-02-01 11:48:26,828 epoch 15 - iter 28/40 - loss 0.19336095 - samples/sec: 178.42 - lr: 0.050000\n",
      "2021-02-01 11:48:27,387 epoch 15 - iter 32/40 - loss 0.20911808 - samples/sec: 171.75 - lr: 0.050000\n",
      "2021-02-01 11:48:27,954 epoch 15 - iter 36/40 - loss 0.20695997 - samples/sec: 169.59 - lr: 0.050000\n",
      "2021-02-01 11:48:28,514 epoch 15 - iter 40/40 - loss 0.21372183 - samples/sec: 171.74 - lr: 0.050000\n",
      "2021-02-01 11:48:28,515 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:28,516 EPOCH 15 done: loss 0.2137 - lr 0.0500000\n",
      "2021-02-01 11:48:29,669 DEV : loss 0.04949627071619034 - score 0.9867\n",
      "2021-02-01 11:48:29,686 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:48:29,687 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:30,388 epoch 16 - iter 4/40 - loss 0.16951069 - samples/sec: 137.14 - lr: 0.050000\n",
      "2021-02-01 11:48:30,960 epoch 16 - iter 8/40 - loss 0.22805644 - samples/sec: 168.13 - lr: 0.050000\n",
      "2021-02-01 11:48:31,533 epoch 16 - iter 12/40 - loss 0.19637780 - samples/sec: 167.82 - lr: 0.050000\n",
      "2021-02-01 11:48:32,072 epoch 16 - iter 16/40 - loss 0.20592073 - samples/sec: 178.43 - lr: 0.050000\n",
      "2021-02-01 11:48:32,632 epoch 16 - iter 20/40 - loss 0.20886582 - samples/sec: 171.44 - lr: 0.050000\n",
      "2021-02-01 11:48:33,214 epoch 16 - iter 24/40 - loss 0.19711997 - samples/sec: 165.51 - lr: 0.050000\n",
      "2021-02-01 11:48:33,748 epoch 16 - iter 28/40 - loss 0.18417756 - samples/sec: 180.10 - lr: 0.050000\n",
      "2021-02-01 11:48:34,322 epoch 16 - iter 32/40 - loss 0.18274453 - samples/sec: 167.83 - lr: 0.050000\n",
      "2021-02-01 11:48:34,872 epoch 16 - iter 36/40 - loss 0.18261888 - samples/sec: 174.53 - lr: 0.050000\n",
      "2021-02-01 11:48:35,419 epoch 16 - iter 40/40 - loss 0.18366926 - samples/sec: 175.85 - lr: 0.050000\n",
      "2021-02-01 11:48:35,420 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:35,420 EPOCH 16 done: loss 0.1837 - lr 0.0500000\n",
      "2021-02-01 11:48:36,553 DEV : loss 0.04371020942926407 - score 0.99\n",
      "2021-02-01 11:48:36,571 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:48:36,572 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:37,117 epoch 17 - iter 4/40 - loss 0.15302254 - samples/sec: 176.55 - lr: 0.050000\n",
      "2021-02-01 11:48:37,681 epoch 17 - iter 8/40 - loss 0.18916039 - samples/sec: 170.50 - lr: 0.050000\n",
      "2021-02-01 11:48:38,295 epoch 17 - iter 12/40 - loss 0.19714528 - samples/sec: 156.87 - lr: 0.050000\n",
      "2021-02-01 11:48:38,829 epoch 17 - iter 16/40 - loss 0.19301274 - samples/sec: 179.78 - lr: 0.050000\n",
      "2021-02-01 11:48:39,394 epoch 17 - iter 20/40 - loss 0.18726175 - samples/sec: 170.20 - lr: 0.050000\n",
      "2021-02-01 11:48:39,951 epoch 17 - iter 24/40 - loss 0.21388915 - samples/sec: 172.35 - lr: 0.050000\n",
      "2021-02-01 11:48:40,466 epoch 17 - iter 28/40 - loss 0.22080392 - samples/sec: 186.77 - lr: 0.050000\n",
      "2021-02-01 11:48:41,034 epoch 17 - iter 32/40 - loss 0.21386130 - samples/sec: 169.62 - lr: 0.050000\n",
      "2021-02-01 11:48:41,575 epoch 17 - iter 36/40 - loss 0.20139229 - samples/sec: 177.45 - lr: 0.050000\n",
      "2021-02-01 11:48:42,153 epoch 17 - iter 40/40 - loss 0.21193592 - samples/sec: 166.08 - lr: 0.050000\n",
      "2021-02-01 11:48:42,154 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:42,155 EPOCH 17 done: loss 0.2119 - lr 0.0500000\n",
      "2021-02-01 11:48:43,433 DEV : loss 0.03770633414387703 - score 0.9933\n",
      "2021-02-01 11:48:43,453 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:48:46,772 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:47,297 epoch 18 - iter 4/40 - loss 0.18371396 - samples/sec: 183.21 - lr: 0.050000\n",
      "2021-02-01 11:48:47,870 epoch 18 - iter 8/40 - loss 0.16687221 - samples/sec: 167.54 - lr: 0.050000\n",
      "2021-02-01 11:48:48,413 epoch 18 - iter 12/40 - loss 0.17745764 - samples/sec: 176.78 - lr: 0.050000\n",
      "2021-02-01 11:48:48,950 epoch 18 - iter 16/40 - loss 0.16257222 - samples/sec: 179.12 - lr: 0.050000\n",
      "2021-02-01 11:48:49,491 epoch 18 - iter 20/40 - loss 0.15247874 - samples/sec: 177.77 - lr: 0.050000\n",
      "2021-02-01 11:48:50,019 epoch 18 - iter 24/40 - loss 0.15740106 - samples/sec: 181.81 - lr: 0.050000\n",
      "2021-02-01 11:48:50,590 epoch 18 - iter 28/40 - loss 0.15964438 - samples/sec: 168.42 - lr: 0.050000\n",
      "2021-02-01 11:48:51,108 epoch 18 - iter 32/40 - loss 0.16212001 - samples/sec: 185.69 - lr: 0.050000\n",
      "2021-02-01 11:48:51,660 epoch 18 - iter 36/40 - loss 0.16233242 - samples/sec: 173.91 - lr: 0.050000\n",
      "2021-02-01 11:48:52,249 epoch 18 - iter 40/40 - loss 0.15569044 - samples/sec: 163.26 - lr: 0.050000\n",
      "2021-02-01 11:48:52,250 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:52,250 EPOCH 18 done: loss 0.1557 - lr 0.0500000\n",
      "2021-02-01 11:48:53,391 DEV : loss 0.04094585403800011 - score 0.99\n",
      "2021-02-01 11:48:53,408 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:48:53,409 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:53,949 epoch 19 - iter 4/40 - loss 0.14792991 - samples/sec: 178.10 - lr: 0.050000\n",
      "2021-02-01 11:48:54,521 epoch 19 - iter 8/40 - loss 0.16161740 - samples/sec: 168.13 - lr: 0.050000\n",
      "2021-02-01 11:48:55,063 epoch 19 - iter 12/40 - loss 0.15477009 - samples/sec: 177.76 - lr: 0.050000\n",
      "2021-02-01 11:48:55,635 epoch 19 - iter 16/40 - loss 0.13752769 - samples/sec: 167.85 - lr: 0.050000\n",
      "2021-02-01 11:48:56,158 epoch 19 - iter 20/40 - loss 0.14148519 - samples/sec: 183.54 - lr: 0.050000\n",
      "2021-02-01 11:48:56,694 epoch 19 - iter 24/40 - loss 0.14807299 - samples/sec: 179.43 - lr: 0.050000\n",
      "2021-02-01 11:48:57,262 epoch 19 - iter 28/40 - loss 0.15822615 - samples/sec: 169.02 - lr: 0.050000\n",
      "2021-02-01 11:48:57,806 epoch 19 - iter 32/40 - loss 0.15414367 - samples/sec: 176.47 - lr: 0.050000\n",
      "2021-02-01 11:48:58,376 epoch 19 - iter 36/40 - loss 0.16886720 - samples/sec: 168.72 - lr: 0.050000\n",
      "2021-02-01 11:48:58,913 epoch 19 - iter 40/40 - loss 0.16953995 - samples/sec: 179.09 - lr: 0.050000\n",
      "2021-02-01 11:48:58,914 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:48:58,914 EPOCH 19 done: loss 0.1695 - lr 0.0500000\n",
      "2021-02-01 11:49:00,067 DEV : loss 0.04235628992319107 - score 0.99\n",
      "2021-02-01 11:49:00,084 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:49:00,085 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:00,614 epoch 20 - iter 4/40 - loss 0.11058657 - samples/sec: 181.81 - lr: 0.050000\n",
      "2021-02-01 11:49:01,155 epoch 20 - iter 8/40 - loss 0.14783367 - samples/sec: 177.78 - lr: 0.050000\n",
      "2021-02-01 11:49:01,695 epoch 20 - iter 12/40 - loss 0.12221366 - samples/sec: 177.78 - lr: 0.050000\n",
      "2021-02-01 11:49:02,253 epoch 20 - iter 16/40 - loss 0.13019616 - samples/sec: 172.66 - lr: 0.050000\n",
      "2021-02-01 11:49:02,801 epoch 20 - iter 20/40 - loss 0.13549969 - samples/sec: 175.49 - lr: 0.050000\n",
      "2021-02-01 11:49:03,333 epoch 20 - iter 24/40 - loss 0.14107611 - samples/sec: 180.45 - lr: 0.050000\n",
      "2021-02-01 11:49:03,895 epoch 20 - iter 28/40 - loss 0.15850573 - samples/sec: 171.11 - lr: 0.050000\n",
      "2021-02-01 11:49:04,429 epoch 20 - iter 32/40 - loss 0.17000982 - samples/sec: 179.78 - lr: 0.050000\n",
      "2021-02-01 11:49:05,006 epoch 20 - iter 36/40 - loss 0.17221307 - samples/sec: 166.66 - lr: 0.050000\n",
      "2021-02-01 11:49:05,538 epoch 20 - iter 40/40 - loss 0.16347838 - samples/sec: 180.46 - lr: 0.050000\n",
      "2021-02-01 11:49:05,539 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:05,540 EPOCH 20 done: loss 0.1635 - lr 0.0500000\n",
      "2021-02-01 11:49:06,688 DEV : loss 0.033288776874542236 - score 0.99\n",
      "2021-02-01 11:49:06,706 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:49:06,706 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:07,247 epoch 21 - iter 4/40 - loss 0.11328491 - samples/sec: 178.10 - lr: 0.050000\n",
      "2021-02-01 11:49:07,807 epoch 21 - iter 8/40 - loss 0.07943078 - samples/sec: 171.75 - lr: 0.050000\n",
      "2021-02-01 11:49:08,341 epoch 21 - iter 12/40 - loss 0.09402577 - samples/sec: 180.45 - lr: 0.050000\n",
      "2021-02-01 11:49:08,895 epoch 21 - iter 16/40 - loss 0.11774296 - samples/sec: 173.30 - lr: 0.050000\n",
      "2021-02-01 11:49:09,467 epoch 21 - iter 20/40 - loss 0.12524150 - samples/sec: 168.11 - lr: 0.050000\n",
      "2021-02-01 11:49:10,033 epoch 21 - iter 24/40 - loss 0.12390612 - samples/sec: 169.61 - lr: 0.050000\n",
      "2021-02-01 11:49:10,629 epoch 21 - iter 28/40 - loss 0.12710368 - samples/sec: 161.35 - lr: 0.050000\n",
      "2021-02-01 11:49:11,213 epoch 21 - iter 32/40 - loss 0.13072077 - samples/sec: 164.66 - lr: 0.050000\n",
      "2021-02-01 11:49:11,776 epoch 21 - iter 36/40 - loss 0.14597096 - samples/sec: 170.51 - lr: 0.050000\n",
      "2021-02-01 11:49:12,319 epoch 21 - iter 40/40 - loss 0.14032773 - samples/sec: 177.45 - lr: 0.050000\n",
      "2021-02-01 11:49:12,320 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:12,320 EPOCH 21 done: loss 0.1403 - lr 0.0500000\n",
      "2021-02-01 11:49:13,485 DEV : loss 0.03735361248254776 - score 0.99\n",
      "Epoch    21: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2021-02-01 11:49:13,504 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:49:13,505 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:14,079 epoch 22 - iter 4/40 - loss 0.15787014 - samples/sec: 167.53 - lr: 0.025000\n",
      "2021-02-01 11:49:14,639 epoch 22 - iter 8/40 - loss 0.15916630 - samples/sec: 171.72 - lr: 0.025000\n",
      "2021-02-01 11:49:15,189 epoch 22 - iter 12/40 - loss 0.13614416 - samples/sec: 174.56 - lr: 0.025000\n",
      "2021-02-01 11:49:15,733 epoch 22 - iter 16/40 - loss 0.13307003 - samples/sec: 176.81 - lr: 0.025000\n",
      "2021-02-01 11:49:16,286 epoch 22 - iter 20/40 - loss 0.13223599 - samples/sec: 174.23 - lr: 0.025000\n",
      "2021-02-01 11:49:16,833 epoch 22 - iter 24/40 - loss 0.14423897 - samples/sec: 175.76 - lr: 0.025000\n",
      "2021-02-01 11:49:17,373 epoch 22 - iter 28/40 - loss 0.13525792 - samples/sec: 178.10 - lr: 0.025000\n",
      "2021-02-01 11:49:17,919 epoch 22 - iter 32/40 - loss 0.13137616 - samples/sec: 176.34 - lr: 0.025000\n",
      "2021-02-01 11:49:18,457 epoch 22 - iter 36/40 - loss 0.13721238 - samples/sec: 178.75 - lr: 0.025000\n",
      "2021-02-01 11:49:19,032 epoch 22 - iter 40/40 - loss 0.13731118 - samples/sec: 167.25 - lr: 0.025000\n",
      "2021-02-01 11:49:19,033 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:19,033 EPOCH 22 done: loss 0.1373 - lr 0.0250000\n",
      "2021-02-01 11:49:20,201 DEV : loss 0.02740776166319847 - score 0.9933\n",
      "2021-02-01 11:49:20,220 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:49:23,540 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:24,056 epoch 23 - iter 4/40 - loss 0.24286132 - samples/sec: 186.41 - lr: 0.025000\n",
      "2021-02-01 11:49:24,592 epoch 23 - iter 8/40 - loss 0.20088151 - samples/sec: 179.25 - lr: 0.025000\n",
      "2021-02-01 11:49:25,158 epoch 23 - iter 12/40 - loss 0.18538146 - samples/sec: 169.90 - lr: 0.025000\n",
      "2021-02-01 11:49:25,687 epoch 23 - iter 16/40 - loss 0.17663160 - samples/sec: 181.88 - lr: 0.025000\n",
      "2021-02-01 11:49:26,236 epoch 23 - iter 20/40 - loss 0.16779416 - samples/sec: 175.17 - lr: 0.025000\n",
      "2021-02-01 11:49:26,782 epoch 23 - iter 24/40 - loss 0.17448346 - samples/sec: 176.15 - lr: 0.025000\n",
      "2021-02-01 11:49:27,321 epoch 23 - iter 28/40 - loss 0.16743473 - samples/sec: 178.44 - lr: 0.025000\n",
      "2021-02-01 11:49:27,925 epoch 23 - iter 32/40 - loss 0.16042247 - samples/sec: 158.94 - lr: 0.025000\n",
      "2021-02-01 11:49:28,496 epoch 23 - iter 36/40 - loss 0.15534409 - samples/sec: 168.13 - lr: 0.025000\n",
      "2021-02-01 11:49:29,078 epoch 23 - iter 40/40 - loss 0.15555839 - samples/sec: 165.23 - lr: 0.025000\n",
      "2021-02-01 11:49:29,079 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:29,079 EPOCH 23 done: loss 0.1556 - lr 0.0250000\n",
      "2021-02-01 11:49:30,242 DEV : loss 0.026347454637289047 - score 0.99\n",
      "2021-02-01 11:49:30,265 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:49:30,267 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:30,811 epoch 24 - iter 4/40 - loss 0.14775952 - samples/sec: 176.80 - lr: 0.025000\n",
      "2021-02-01 11:49:31,384 epoch 24 - iter 8/40 - loss 0.14013712 - samples/sec: 167.54 - lr: 0.025000\n",
      "2021-02-01 11:49:31,934 epoch 24 - iter 12/40 - loss 0.13759621 - samples/sec: 175.18 - lr: 0.025000\n",
      "2021-02-01 11:49:32,465 epoch 24 - iter 16/40 - loss 0.13335789 - samples/sec: 180.79 - lr: 0.025000\n",
      "2021-02-01 11:49:33,029 epoch 24 - iter 20/40 - loss 0.13961274 - samples/sec: 170.52 - lr: 0.025000\n",
      "2021-02-01 11:49:33,559 epoch 24 - iter 24/40 - loss 0.12685667 - samples/sec: 181.13 - lr: 0.025000\n",
      "2021-02-01 11:49:34,126 epoch 24 - iter 28/40 - loss 0.14140002 - samples/sec: 169.60 - lr: 0.025000\n",
      "2021-02-01 11:49:34,678 epoch 24 - iter 32/40 - loss 0.13780130 - samples/sec: 174.23 - lr: 0.025000\n",
      "2021-02-01 11:49:35,203 epoch 24 - iter 36/40 - loss 0.14012442 - samples/sec: 182.86 - lr: 0.025000\n",
      "2021-02-01 11:49:35,773 epoch 24 - iter 40/40 - loss 0.13390172 - samples/sec: 168.72 - lr: 0.025000\n",
      "2021-02-01 11:49:35,774 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:35,775 EPOCH 24 done: loss 0.1339 - lr 0.0250000\n",
      "2021-02-01 11:49:36,945 DEV : loss 0.027666958048939705 - score 0.9917\n",
      "2021-02-01 11:49:36,963 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:49:36,964 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:37,510 epoch 25 - iter 4/40 - loss 0.12505246 - samples/sec: 176.15 - lr: 0.025000\n",
      "2021-02-01 11:49:38,060 epoch 25 - iter 8/40 - loss 0.12553585 - samples/sec: 174.86 - lr: 0.025000\n",
      "2021-02-01 11:49:38,620 epoch 25 - iter 12/40 - loss 0.12325904 - samples/sec: 171.42 - lr: 0.025000\n",
      "2021-02-01 11:49:39,170 epoch 25 - iter 16/40 - loss 0.12250467 - samples/sec: 174.56 - lr: 0.025000\n",
      "2021-02-01 11:49:39,706 epoch 25 - iter 20/40 - loss 0.11549026 - samples/sec: 179.44 - lr: 0.025000\n",
      "2021-02-01 11:49:40,275 epoch 25 - iter 24/40 - loss 0.11647603 - samples/sec: 168.72 - lr: 0.025000\n",
      "2021-02-01 11:49:40,811 epoch 25 - iter 28/40 - loss 0.11737941 - samples/sec: 179.44 - lr: 0.025000\n",
      "2021-02-01 11:49:41,349 epoch 25 - iter 32/40 - loss 0.12544049 - samples/sec: 178.78 - lr: 0.025000\n",
      "2021-02-01 11:49:41,894 epoch 25 - iter 36/40 - loss 0.12790164 - samples/sec: 176.15 - lr: 0.025000\n",
      "2021-02-01 11:49:42,418 epoch 25 - iter 40/40 - loss 0.12570020 - samples/sec: 183.56 - lr: 0.025000\n",
      "2021-02-01 11:49:42,418 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:42,419 EPOCH 25 done: loss 0.1257 - lr 0.0250000\n",
      "2021-02-01 11:49:43,569 DEV : loss 0.02988404594361782 - score 0.99\n",
      "2021-02-01 11:49:43,587 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:49:43,588 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:44,150 epoch 26 - iter 4/40 - loss 0.14996140 - samples/sec: 171.11 - lr: 0.025000\n",
      "2021-02-01 11:49:44,669 epoch 26 - iter 8/40 - loss 0.16278132 - samples/sec: 185.32 - lr: 0.025000\n",
      "2021-02-01 11:49:45,205 epoch 26 - iter 12/40 - loss 0.13974418 - samples/sec: 179.43 - lr: 0.025000\n",
      "2021-02-01 11:49:45,694 epoch 26 - iter 16/40 - loss 0.19402741 - samples/sec: 196.31 - lr: 0.025000\n",
      "2021-02-01 11:49:46,256 epoch 26 - iter 20/40 - loss 0.17542541 - samples/sec: 171.11 - lr: 0.025000\n",
      "2021-02-01 11:49:46,791 epoch 26 - iter 24/40 - loss 0.17835038 - samples/sec: 179.76 - lr: 0.025000\n",
      "2021-02-01 11:49:47,345 epoch 26 - iter 28/40 - loss 0.17714398 - samples/sec: 173.58 - lr: 0.025000\n",
      "2021-02-01 11:49:47,927 epoch 26 - iter 32/40 - loss 0.16554020 - samples/sec: 165.25 - lr: 0.025000\n",
      "2021-02-01 11:49:48,485 epoch 26 - iter 36/40 - loss 0.16947798 - samples/sec: 172.36 - lr: 0.025000\n",
      "2021-02-01 11:49:49,038 epoch 26 - iter 40/40 - loss 0.16285623 - samples/sec: 173.92 - lr: 0.025000\n",
      "2021-02-01 11:49:49,039 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:49,039 EPOCH 26 done: loss 0.1629 - lr 0.0250000\n",
      "2021-02-01 11:49:50,200 DEV : loss 0.025246622040867805 - score 0.9933\n",
      "2021-02-01 11:49:50,218 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:49:53,514 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:54,056 epoch 27 - iter 4/40 - loss 0.13427369 - samples/sec: 177.44 - lr: 0.025000\n",
      "2021-02-01 11:49:54,616 epoch 27 - iter 8/40 - loss 0.12246537 - samples/sec: 171.88 - lr: 0.025000\n",
      "2021-02-01 11:49:55,164 epoch 27 - iter 12/40 - loss 0.12382216 - samples/sec: 175.18 - lr: 0.025000\n",
      "2021-02-01 11:49:55,711 epoch 27 - iter 16/40 - loss 0.12250402 - samples/sec: 175.80 - lr: 0.025000\n",
      "2021-02-01 11:49:56,261 epoch 27 - iter 20/40 - loss 0.12067746 - samples/sec: 175.17 - lr: 0.025000\n",
      "2021-02-01 11:49:56,827 epoch 27 - iter 24/40 - loss 0.12359396 - samples/sec: 169.58 - lr: 0.025000\n",
      "2021-02-01 11:49:57,355 epoch 27 - iter 28/40 - loss 0.11474182 - samples/sec: 182.30 - lr: 0.025000\n",
      "2021-02-01 11:49:57,888 epoch 27 - iter 32/40 - loss 0.12547215 - samples/sec: 180.06 - lr: 0.025000\n",
      "2021-02-01 11:49:58,423 epoch 27 - iter 36/40 - loss 0.12406209 - samples/sec: 179.78 - lr: 0.025000\n",
      "2021-02-01 11:49:59,018 epoch 27 - iter 40/40 - loss 0.12370624 - samples/sec: 161.62 - lr: 0.025000\n",
      "2021-02-01 11:49:59,019 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:49:59,019 EPOCH 27 done: loss 0.1237 - lr 0.0250000\n",
      "2021-02-01 11:50:00,153 DEV : loss 0.025729408487677574 - score 0.99\n",
      "2021-02-01 11:50:00,170 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:50:00,171 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:00,706 epoch 28 - iter 4/40 - loss 0.11827517 - samples/sec: 179.78 - lr: 0.025000\n",
      "2021-02-01 11:50:01,255 epoch 28 - iter 8/40 - loss 0.08257807 - samples/sec: 175.18 - lr: 0.025000\n",
      "2021-02-01 11:50:01,812 epoch 28 - iter 12/40 - loss 0.08396152 - samples/sec: 172.35 - lr: 0.025000\n",
      "2021-02-01 11:50:02,374 epoch 28 - iter 16/40 - loss 0.14219129 - samples/sec: 170.82 - lr: 0.025000\n",
      "2021-02-01 11:50:02,905 epoch 28 - iter 20/40 - loss 0.13928260 - samples/sec: 181.13 - lr: 0.025000\n",
      "2021-02-01 11:50:03,460 epoch 28 - iter 24/40 - loss 0.13026156 - samples/sec: 173.28 - lr: 0.025000\n",
      "2021-02-01 11:50:04,043 epoch 28 - iter 28/40 - loss 0.12964479 - samples/sec: 164.68 - lr: 0.025000\n",
      "2021-02-01 11:50:04,619 epoch 28 - iter 32/40 - loss 0.12175687 - samples/sec: 166.95 - lr: 0.025000\n",
      "2021-02-01 11:50:05,163 epoch 28 - iter 36/40 - loss 0.12245873 - samples/sec: 176.75 - lr: 0.025000\n",
      "2021-02-01 11:50:05,706 epoch 28 - iter 40/40 - loss 0.11826773 - samples/sec: 177.13 - lr: 0.025000\n",
      "2021-02-01 11:50:05,707 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:05,708 EPOCH 28 done: loss 0.1183 - lr 0.0250000\n",
      "2021-02-01 11:50:06,840 DEV : loss 0.028199810534715652 - score 0.9933\n",
      "2021-02-01 11:50:06,859 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:50:06,860 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:07,444 epoch 29 - iter 4/40 - loss 0.08460140 - samples/sec: 164.67 - lr: 0.025000\n",
      "2021-02-01 11:50:08,001 epoch 29 - iter 8/40 - loss 0.13589033 - samples/sec: 172.35 - lr: 0.025000\n",
      "2021-02-01 11:50:08,527 epoch 29 - iter 12/40 - loss 0.15419449 - samples/sec: 182.86 - lr: 0.025000\n",
      "2021-02-01 11:50:09,057 epoch 29 - iter 16/40 - loss 0.17199386 - samples/sec: 181.47 - lr: 0.025000\n",
      "2021-02-01 11:50:09,614 epoch 29 - iter 20/40 - loss 0.17011769 - samples/sec: 172.67 - lr: 0.025000\n",
      "2021-02-01 11:50:10,161 epoch 29 - iter 24/40 - loss 0.15966918 - samples/sec: 175.82 - lr: 0.025000\n",
      "2021-02-01 11:50:10,714 epoch 29 - iter 28/40 - loss 0.15138506 - samples/sec: 173.91 - lr: 0.025000\n",
      "2021-02-01 11:50:11,270 epoch 29 - iter 32/40 - loss 0.14068715 - samples/sec: 172.97 - lr: 0.025000\n",
      "2021-02-01 11:50:11,810 epoch 29 - iter 36/40 - loss 0.15053041 - samples/sec: 178.11 - lr: 0.025000\n",
      "2021-02-01 11:50:12,376 epoch 29 - iter 40/40 - loss 0.15235425 - samples/sec: 169.92 - lr: 0.025000\n",
      "2021-02-01 11:50:12,377 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:12,377 EPOCH 29 done: loss 0.1524 - lr 0.0250000\n",
      "2021-02-01 11:50:13,552 DEV : loss 0.022333987057209015 - score 0.9933\n",
      "2021-02-01 11:50:13,571 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:50:16,899 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:17,450 epoch 30 - iter 4/40 - loss 0.22683621 - samples/sec: 174.98 - lr: 0.025000\n",
      "2021-02-01 11:50:17,978 epoch 30 - iter 8/40 - loss 0.23226186 - samples/sec: 182.16 - lr: 0.025000\n",
      "2021-02-01 11:50:18,554 epoch 30 - iter 12/40 - loss 0.19937256 - samples/sec: 166.96 - lr: 0.025000\n",
      "2021-02-01 11:50:19,127 epoch 30 - iter 16/40 - loss 0.19916682 - samples/sec: 167.54 - lr: 0.025000\n",
      "2021-02-01 11:50:19,680 epoch 30 - iter 20/40 - loss 0.19670109 - samples/sec: 173.91 - lr: 0.025000\n",
      "2021-02-01 11:50:20,224 epoch 30 - iter 24/40 - loss 0.18241901 - samples/sec: 176.81 - lr: 0.025000\n",
      "2021-02-01 11:50:20,772 epoch 30 - iter 28/40 - loss 0.16821043 - samples/sec: 175.50 - lr: 0.025000\n",
      "2021-02-01 11:50:21,331 epoch 30 - iter 32/40 - loss 0.16994103 - samples/sec: 172.04 - lr: 0.025000\n",
      "2021-02-01 11:50:21,897 epoch 30 - iter 36/40 - loss 0.17620179 - samples/sec: 169.91 - lr: 0.025000\n",
      "2021-02-01 11:50:22,440 epoch 30 - iter 40/40 - loss 0.17093973 - samples/sec: 177.12 - lr: 0.025000\n",
      "2021-02-01 11:50:22,440 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:22,441 EPOCH 30 done: loss 0.1709 - lr 0.0250000\n",
      "2021-02-01 11:50:23,597 DEV : loss 0.027369210496544838 - score 0.9933\n",
      "2021-02-01 11:50:23,615 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:50:23,616 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:24,151 epoch 31 - iter 4/40 - loss 0.07536102 - samples/sec: 180.45 - lr: 0.025000\n",
      "2021-02-01 11:50:24,684 epoch 31 - iter 8/40 - loss 0.12091255 - samples/sec: 180.46 - lr: 0.025000\n",
      "2021-02-01 11:50:25,241 epoch 31 - iter 12/40 - loss 0.13244015 - samples/sec: 172.66 - lr: 0.025000\n",
      "2021-02-01 11:50:25,831 epoch 31 - iter 16/40 - loss 0.13838759 - samples/sec: 162.71 - lr: 0.025000\n",
      "2021-02-01 11:50:26,388 epoch 31 - iter 20/40 - loss 0.13274932 - samples/sec: 172.35 - lr: 0.025000\n",
      "2021-02-01 11:50:26,977 epoch 31 - iter 24/40 - loss 0.13349340 - samples/sec: 162.88 - lr: 0.025000\n",
      "2021-02-01 11:50:27,529 epoch 31 - iter 28/40 - loss 0.12822094 - samples/sec: 174.53 - lr: 0.025000\n",
      "2021-02-01 11:50:28,130 epoch 31 - iter 32/40 - loss 0.13020758 - samples/sec: 160.02 - lr: 0.025000\n",
      "2021-02-01 11:50:28,651 epoch 31 - iter 36/40 - loss 0.12928286 - samples/sec: 184.60 - lr: 0.025000\n",
      "2021-02-01 11:50:29,188 epoch 31 - iter 40/40 - loss 0.12151829 - samples/sec: 179.43 - lr: 0.025000\n",
      "2021-02-01 11:50:29,189 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:29,190 EPOCH 31 done: loss 0.1215 - lr 0.0250000\n",
      "2021-02-01 11:50:30,489 DEV : loss 0.026891253888607025 - score 0.9933\n",
      "2021-02-01 11:50:30,507 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:50:30,508 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:31,055 epoch 32 - iter 4/40 - loss 0.07717840 - samples/sec: 175.82 - lr: 0.025000\n",
      "2021-02-01 11:50:31,587 epoch 32 - iter 8/40 - loss 0.10055689 - samples/sec: 180.79 - lr: 0.025000\n",
      "2021-02-01 11:50:32,180 epoch 32 - iter 12/40 - loss 0.09460502 - samples/sec: 161.89 - lr: 0.025000\n",
      "2021-02-01 11:50:32,761 epoch 32 - iter 16/40 - loss 0.08839339 - samples/sec: 165.52 - lr: 0.025000\n",
      "2021-02-01 11:50:33,354 epoch 32 - iter 20/40 - loss 0.08942134 - samples/sec: 162.43 - lr: 0.025000\n",
      "2021-02-01 11:50:33,892 epoch 32 - iter 24/40 - loss 0.10620943 - samples/sec: 178.45 - lr: 0.025000\n",
      "2021-02-01 11:50:34,441 epoch 32 - iter 28/40 - loss 0.10958497 - samples/sec: 175.18 - lr: 0.025000\n",
      "2021-02-01 11:50:34,994 epoch 32 - iter 32/40 - loss 0.10712019 - samples/sec: 173.60 - lr: 0.025000\n",
      "2021-02-01 11:50:35,546 epoch 32 - iter 36/40 - loss 0.11457881 - samples/sec: 174.22 - lr: 0.025000\n",
      "2021-02-01 11:50:36,063 epoch 32 - iter 40/40 - loss 0.12292935 - samples/sec: 185.70 - lr: 0.025000\n",
      "2021-02-01 11:50:36,064 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:36,064 EPOCH 32 done: loss 0.1229 - lr 0.0250000\n",
      "2021-02-01 11:50:37,224 DEV : loss 0.022949334233999252 - score 0.9933\n",
      "2021-02-01 11:50:37,246 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:50:37,248 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:37,780 epoch 33 - iter 4/40 - loss 0.07171464 - samples/sec: 181.13 - lr: 0.025000\n",
      "2021-02-01 11:50:38,321 epoch 33 - iter 8/40 - loss 0.09732858 - samples/sec: 177.45 - lr: 0.025000\n",
      "2021-02-01 11:50:38,872 epoch 33 - iter 12/40 - loss 0.10588000 - samples/sec: 174.56 - lr: 0.025000\n",
      "2021-02-01 11:50:39,376 epoch 33 - iter 16/40 - loss 0.10389740 - samples/sec: 190.86 - lr: 0.025000\n",
      "2021-02-01 11:50:39,906 epoch 33 - iter 20/40 - loss 0.12832297 - samples/sec: 181.13 - lr: 0.025000\n",
      "2021-02-01 11:50:40,461 epoch 33 - iter 24/40 - loss 0.12680699 - samples/sec: 173.29 - lr: 0.025000\n",
      "2021-02-01 11:50:41,012 epoch 33 - iter 28/40 - loss 0.13055793 - samples/sec: 174.55 - lr: 0.025000\n",
      "2021-02-01 11:50:41,556 epoch 33 - iter 32/40 - loss 0.11996662 - samples/sec: 176.80 - lr: 0.025000\n",
      "2021-02-01 11:50:42,084 epoch 33 - iter 36/40 - loss 0.11210000 - samples/sec: 182.49 - lr: 0.025000\n",
      "2021-02-01 11:50:42,644 epoch 33 - iter 40/40 - loss 0.11421954 - samples/sec: 171.85 - lr: 0.025000\n",
      "2021-02-01 11:50:42,645 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:42,645 EPOCH 33 done: loss 0.1142 - lr 0.0250000\n",
      "2021-02-01 11:50:43,783 DEV : loss 0.020772866904735565 - score 0.9967\n",
      "2021-02-01 11:50:43,800 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-02-01 11:50:47,057 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:47,592 epoch 34 - iter 4/40 - loss 0.24602358 - samples/sec: 179.71 - lr: 0.025000\n",
      "2021-02-01 11:50:48,135 epoch 34 - iter 8/40 - loss 0.15528802 - samples/sec: 176.75 - lr: 0.025000\n",
      "2021-02-01 11:50:48,675 epoch 34 - iter 12/40 - loss 0.18452626 - samples/sec: 177.76 - lr: 0.025000\n",
      "2021-02-01 11:50:49,190 epoch 34 - iter 16/40 - loss 0.18839849 - samples/sec: 186.77 - lr: 0.025000\n",
      "2021-02-01 11:50:49,711 epoch 34 - iter 20/40 - loss 0.17385294 - samples/sec: 184.26 - lr: 0.025000\n",
      "2021-02-01 11:50:50,252 epoch 34 - iter 24/40 - loss 0.17264606 - samples/sec: 177.75 - lr: 0.025000\n",
      "2021-02-01 11:50:50,803 epoch 34 - iter 28/40 - loss 0.16847493 - samples/sec: 174.54 - lr: 0.025000\n",
      "2021-02-01 11:50:51,335 epoch 34 - iter 32/40 - loss 0.16830063 - samples/sec: 180.81 - lr: 0.025000\n",
      "2021-02-01 11:50:51,863 epoch 34 - iter 36/40 - loss 0.15818244 - samples/sec: 182.16 - lr: 0.025000\n",
      "2021-02-01 11:50:52,392 epoch 34 - iter 40/40 - loss 0.14903518 - samples/sec: 181.47 - lr: 0.025000\n",
      "2021-02-01 11:50:52,393 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:52,394 EPOCH 34 done: loss 0.1490 - lr 0.0250000\n",
      "2021-02-01 11:50:53,536 DEV : loss 0.02664768323302269 - score 0.9933\n",
      "2021-02-01 11:50:53,553 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:50:53,554 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:54,151 epoch 35 - iter 4/40 - loss 0.12234982 - samples/sec: 161.06 - lr: 0.025000\n",
      "2021-02-01 11:50:54,758 epoch 35 - iter 8/40 - loss 0.18019357 - samples/sec: 158.42 - lr: 0.025000\n",
      "2021-02-01 11:50:55,347 epoch 35 - iter 12/40 - loss 0.17221572 - samples/sec: 163.26 - lr: 0.025000\n",
      "2021-02-01 11:50:55,904 epoch 35 - iter 16/40 - loss 0.15710654 - samples/sec: 172.34 - lr: 0.025000\n",
      "2021-02-01 11:50:56,470 epoch 35 - iter 20/40 - loss 0.14930801 - samples/sec: 169.91 - lr: 0.025000\n",
      "2021-02-01 11:50:57,006 epoch 35 - iter 24/40 - loss 0.14562466 - samples/sec: 179.11 - lr: 0.025000\n",
      "2021-02-01 11:50:57,534 epoch 35 - iter 28/40 - loss 0.13794069 - samples/sec: 181.82 - lr: 0.025000\n",
      "2021-02-01 11:50:58,076 epoch 35 - iter 32/40 - loss 0.13775379 - samples/sec: 177.46 - lr: 0.025000\n",
      "2021-02-01 11:50:58,640 epoch 35 - iter 36/40 - loss 0.13013856 - samples/sec: 170.20 - lr: 0.025000\n",
      "2021-02-01 11:50:59,165 epoch 35 - iter 40/40 - loss 0.12902857 - samples/sec: 183.21 - lr: 0.025000\n",
      "2021-02-01 11:50:59,166 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:50:59,167 EPOCH 35 done: loss 0.1290 - lr 0.0250000\n",
      "2021-02-01 11:51:00,341 DEV : loss 0.022028153762221336 - score 0.9967\n",
      "2021-02-01 11:51:00,358 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:51:00,360 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:00,955 epoch 36 - iter 4/40 - loss 0.08124058 - samples/sec: 161.61 - lr: 0.025000\n",
      "2021-02-01 11:51:01,514 epoch 36 - iter 8/40 - loss 0.06810630 - samples/sec: 172.04 - lr: 0.025000\n",
      "2021-02-01 11:51:02,053 epoch 36 - iter 12/40 - loss 0.10031841 - samples/sec: 178.44 - lr: 0.025000\n",
      "2021-02-01 11:51:02,583 epoch 36 - iter 16/40 - loss 0.09502550 - samples/sec: 181.48 - lr: 0.025000\n",
      "2021-02-01 11:51:03,127 epoch 36 - iter 20/40 - loss 0.10449659 - samples/sec: 176.48 - lr: 0.025000\n",
      "2021-02-01 11:51:03,667 epoch 36 - iter 24/40 - loss 0.12348381 - samples/sec: 178.10 - lr: 0.025000\n",
      "2021-02-01 11:51:04,218 epoch 36 - iter 28/40 - loss 0.11885995 - samples/sec: 174.55 - lr: 0.025000\n",
      "2021-02-01 11:51:04,737 epoch 36 - iter 32/40 - loss 0.11074497 - samples/sec: 184.97 - lr: 0.025000\n",
      "2021-02-01 11:51:05,284 epoch 36 - iter 36/40 - loss 0.11415862 - samples/sec: 176.15 - lr: 0.025000\n",
      "2021-02-01 11:51:05,841 epoch 36 - iter 40/40 - loss 0.11559329 - samples/sec: 172.36 - lr: 0.025000\n",
      "2021-02-01 11:51:05,842 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:05,843 EPOCH 36 done: loss 0.1156 - lr 0.0250000\n",
      "2021-02-01 11:51:06,969 DEV : loss 0.02187788113951683 - score 0.9933\n",
      "2021-02-01 11:51:06,986 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:51:06,987 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:07,562 epoch 37 - iter 4/40 - loss 0.16772866 - samples/sec: 167.26 - lr: 0.025000\n",
      "2021-02-01 11:51:08,099 epoch 37 - iter 8/40 - loss 0.14184074 - samples/sec: 178.77 - lr: 0.025000\n",
      "2021-02-01 11:51:08,637 epoch 37 - iter 12/40 - loss 0.16600776 - samples/sec: 178.77 - lr: 0.025000\n",
      "2021-02-01 11:51:09,182 epoch 37 - iter 16/40 - loss 0.16391239 - samples/sec: 176.47 - lr: 0.025000\n",
      "2021-02-01 11:51:09,748 epoch 37 - iter 20/40 - loss 0.15021379 - samples/sec: 169.91 - lr: 0.025000\n",
      "2021-02-01 11:51:10,298 epoch 37 - iter 24/40 - loss 0.13507693 - samples/sec: 174.56 - lr: 0.025000\n",
      "2021-02-01 11:51:10,834 epoch 37 - iter 28/40 - loss 0.13326086 - samples/sec: 179.11 - lr: 0.025000\n",
      "2021-02-01 11:51:11,355 epoch 37 - iter 32/40 - loss 0.12517885 - samples/sec: 184.60 - lr: 0.025000\n",
      "2021-02-01 11:51:11,885 epoch 37 - iter 36/40 - loss 0.12998467 - samples/sec: 181.13 - lr: 0.025000\n",
      "2021-02-01 11:51:12,435 epoch 37 - iter 40/40 - loss 0.12835879 - samples/sec: 174.87 - lr: 0.025000\n",
      "2021-02-01 11:51:12,436 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:12,437 EPOCH 37 done: loss 0.1284 - lr 0.0250000\n",
      "2021-02-01 11:51:13,629 DEV : loss 0.0243424903601408 - score 0.99\n",
      "Epoch    37: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2021-02-01 11:51:13,646 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:51:13,647 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:14,222 epoch 38 - iter 4/40 - loss 0.05336793 - samples/sec: 167.53 - lr: 0.012500\n",
      "2021-02-01 11:51:14,787 epoch 38 - iter 8/40 - loss 0.08502881 - samples/sec: 170.20 - lr: 0.012500\n",
      "2021-02-01 11:51:15,331 epoch 38 - iter 12/40 - loss 0.10383227 - samples/sec: 176.79 - lr: 0.012500\n",
      "2021-02-01 11:51:15,888 epoch 38 - iter 16/40 - loss 0.09838087 - samples/sec: 172.42 - lr: 0.012500\n",
      "2021-02-01 11:51:16,458 epoch 38 - iter 20/40 - loss 0.09585678 - samples/sec: 168.42 - lr: 0.012500\n",
      "2021-02-01 11:51:16,983 epoch 38 - iter 24/40 - loss 0.09099467 - samples/sec: 183.21 - lr: 0.012500\n",
      "2021-02-01 11:51:17,550 epoch 38 - iter 28/40 - loss 0.09369932 - samples/sec: 169.60 - lr: 0.012500\n",
      "2021-02-01 11:51:18,068 epoch 38 - iter 32/40 - loss 0.10030051 - samples/sec: 185.69 - lr: 0.012500\n",
      "2021-02-01 11:51:18,616 epoch 38 - iter 36/40 - loss 0.10451654 - samples/sec: 175.51 - lr: 0.012500\n",
      "2021-02-01 11:51:19,205 epoch 38 - iter 40/40 - loss 0.10167911 - samples/sec: 163.27 - lr: 0.012500\n",
      "2021-02-01 11:51:19,205 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:19,206 EPOCH 38 done: loss 0.1017 - lr 0.0125000\n",
      "2021-02-01 11:51:20,356 DEV : loss 0.022907396778464317 - score 0.9933\n",
      "2021-02-01 11:51:20,374 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:51:20,375 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:20,925 epoch 39 - iter 4/40 - loss 0.19935410 - samples/sec: 174.85 - lr: 0.012500\n",
      "2021-02-01 11:51:21,488 epoch 39 - iter 8/40 - loss 0.13677498 - samples/sec: 170.81 - lr: 0.012500\n",
      "2021-02-01 11:51:22,026 epoch 39 - iter 12/40 - loss 0.11469682 - samples/sec: 178.45 - lr: 0.012500\n",
      "2021-02-01 11:51:22,577 epoch 39 - iter 16/40 - loss 0.12417154 - samples/sec: 174.54 - lr: 0.012500\n",
      "2021-02-01 11:51:23,110 epoch 39 - iter 20/40 - loss 0.10817120 - samples/sec: 180.13 - lr: 0.012500\n",
      "2021-02-01 11:51:23,674 epoch 39 - iter 24/40 - loss 0.12154799 - samples/sec: 170.20 - lr: 0.012500\n",
      "2021-02-01 11:51:24,200 epoch 39 - iter 28/40 - loss 0.12431141 - samples/sec: 182.53 - lr: 0.012500\n",
      "2021-02-01 11:51:24,733 epoch 39 - iter 32/40 - loss 0.13241110 - samples/sec: 180.10 - lr: 0.012500\n",
      "2021-02-01 11:51:25,291 epoch 39 - iter 36/40 - loss 0.13482540 - samples/sec: 172.34 - lr: 0.012500\n",
      "2021-02-01 11:51:25,832 epoch 39 - iter 40/40 - loss 0.13990668 - samples/sec: 177.78 - lr: 0.012500\n",
      "2021-02-01 11:51:25,833 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:25,834 EPOCH 39 done: loss 0.1399 - lr 0.0125000\n",
      "2021-02-01 11:51:26,950 DEV : loss 0.020041445270180702 - score 0.9933\n",
      "2021-02-01 11:51:26,967 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:51:26,969 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:27,486 epoch 40 - iter 4/40 - loss 0.09915249 - samples/sec: 186.40 - lr: 0.012500\n",
      "2021-02-01 11:51:28,041 epoch 40 - iter 8/40 - loss 0.08775831 - samples/sec: 173.29 - lr: 0.012500\n",
      "2021-02-01 11:51:28,582 epoch 40 - iter 12/40 - loss 0.09584207 - samples/sec: 177.44 - lr: 0.012500\n",
      "2021-02-01 11:51:29,090 epoch 40 - iter 16/40 - loss 0.11549829 - samples/sec: 189.33 - lr: 0.012500\n",
      "2021-02-01 11:51:29,673 epoch 40 - iter 20/40 - loss 0.13344238 - samples/sec: 164.95 - lr: 0.012500\n",
      "2021-02-01 11:51:30,262 epoch 40 - iter 24/40 - loss 0.14266658 - samples/sec: 162.99 - lr: 0.012500\n",
      "2021-02-01 11:51:30,823 epoch 40 - iter 28/40 - loss 0.13226859 - samples/sec: 171.72 - lr: 0.012500\n",
      "2021-02-01 11:51:31,359 epoch 40 - iter 32/40 - loss 0.12572559 - samples/sec: 179.11 - lr: 0.012500\n",
      "2021-02-01 11:51:31,915 epoch 40 - iter 36/40 - loss 0.12627967 - samples/sec: 172.70 - lr: 0.012500\n",
      "2021-02-01 11:51:32,431 epoch 40 - iter 40/40 - loss 0.12383257 - samples/sec: 186.41 - lr: 0.012500\n",
      "2021-02-01 11:51:32,432 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:32,432 EPOCH 40 done: loss 0.1238 - lr 0.0125000\n",
      "2021-02-01 11:51:33,579 DEV : loss 0.022165412083268166 - score 0.9933\n",
      "2021-02-01 11:51:33,596 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:51:33,597 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:34,121 epoch 41 - iter 4/40 - loss 0.08936159 - samples/sec: 183.90 - lr: 0.012500\n",
      "2021-02-01 11:51:34,654 epoch 41 - iter 8/40 - loss 0.10326020 - samples/sec: 180.12 - lr: 0.012500\n",
      "2021-02-01 11:51:35,208 epoch 41 - iter 12/40 - loss 0.11127401 - samples/sec: 173.60 - lr: 0.012500\n",
      "2021-02-01 11:51:35,743 epoch 41 - iter 16/40 - loss 0.12413643 - samples/sec: 179.78 - lr: 0.012500\n",
      "2021-02-01 11:51:36,309 epoch 41 - iter 20/40 - loss 0.14550570 - samples/sec: 169.91 - lr: 0.012500\n",
      "2021-02-01 11:51:36,869 epoch 41 - iter 24/40 - loss 0.14334970 - samples/sec: 172.04 - lr: 0.012500\n",
      "2021-02-01 11:51:37,387 epoch 41 - iter 28/40 - loss 0.14473677 - samples/sec: 185.33 - lr: 0.012500\n",
      "2021-02-01 11:51:37,957 epoch 41 - iter 32/40 - loss 0.14043384 - samples/sec: 168.72 - lr: 0.012500\n",
      "2021-02-01 11:51:38,497 epoch 41 - iter 36/40 - loss 0.13207086 - samples/sec: 178.11 - lr: 0.012500\n",
      "2021-02-01 11:51:39,057 epoch 41 - iter 40/40 - loss 0.13816184 - samples/sec: 171.72 - lr: 0.012500\n",
      "2021-02-01 11:51:39,058 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:39,058 EPOCH 41 done: loss 0.1382 - lr 0.0125000\n",
      "2021-02-01 11:51:40,212 DEV : loss 0.019173508509993553 - score 0.9933\n",
      "Epoch    41: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2021-02-01 11:51:40,235 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:51:40,236 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:40,765 epoch 42 - iter 4/40 - loss 0.10939265 - samples/sec: 182.16 - lr: 0.006250\n",
      "2021-02-01 11:51:41,316 epoch 42 - iter 8/40 - loss 0.11209731 - samples/sec: 174.23 - lr: 0.006250\n",
      "2021-02-01 11:51:41,871 epoch 42 - iter 12/40 - loss 0.10703530 - samples/sec: 173.30 - lr: 0.006250\n",
      "2021-02-01 11:51:42,408 epoch 42 - iter 16/40 - loss 0.10791332 - samples/sec: 178.77 - lr: 0.006250\n",
      "2021-02-01 11:51:42,995 epoch 42 - iter 20/40 - loss 0.11563449 - samples/sec: 163.81 - lr: 0.006250\n",
      "2021-02-01 11:51:43,558 epoch 42 - iter 24/40 - loss 0.10496985 - samples/sec: 170.68 - lr: 0.006250\n",
      "2021-02-01 11:51:44,108 epoch 42 - iter 28/40 - loss 0.10078522 - samples/sec: 174.88 - lr: 0.006250\n",
      "2021-02-01 11:51:44,644 epoch 42 - iter 32/40 - loss 0.09784644 - samples/sec: 179.44 - lr: 0.006250\n",
      "2021-02-01 11:51:45,183 epoch 42 - iter 36/40 - loss 0.11084156 - samples/sec: 178.77 - lr: 0.006250\n",
      "2021-02-01 11:51:45,712 epoch 42 - iter 40/40 - loss 0.10783176 - samples/sec: 181.47 - lr: 0.006250\n",
      "2021-02-01 11:51:45,712 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:45,713 EPOCH 42 done: loss 0.1078 - lr 0.0062500\n",
      "2021-02-01 11:51:46,851 DEV : loss 0.01969796232879162 - score 0.9933\n",
      "2021-02-01 11:51:46,870 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:51:46,871 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:47,411 epoch 43 - iter 4/40 - loss 0.04445617 - samples/sec: 178.11 - lr: 0.006250\n",
      "2021-02-01 11:51:47,961 epoch 43 - iter 8/40 - loss 0.11365347 - samples/sec: 175.18 - lr: 0.006250\n",
      "2021-02-01 11:51:48,522 epoch 43 - iter 12/40 - loss 0.14761103 - samples/sec: 171.11 - lr: 0.006250\n",
      "2021-02-01 11:51:49,052 epoch 43 - iter 16/40 - loss 0.13677767 - samples/sec: 181.46 - lr: 0.006250\n",
      "2021-02-01 11:51:49,631 epoch 43 - iter 20/40 - loss 0.13726083 - samples/sec: 166.09 - lr: 0.006250\n",
      "2021-02-01 11:51:50,173 epoch 43 - iter 24/40 - loss 0.12276076 - samples/sec: 177.44 - lr: 0.006250\n",
      "2021-02-01 11:51:50,696 epoch 43 - iter 28/40 - loss 0.13009969 - samples/sec: 183.91 - lr: 0.006250\n",
      "2021-02-01 11:51:51,251 epoch 43 - iter 32/40 - loss 0.13685902 - samples/sec: 173.28 - lr: 0.006250\n",
      "2021-02-01 11:51:51,835 epoch 43 - iter 36/40 - loss 0.12998537 - samples/sec: 164.38 - lr: 0.006250\n",
      "2021-02-01 11:51:52,395 epoch 43 - iter 40/40 - loss 0.12760878 - samples/sec: 171.43 - lr: 0.006250\n",
      "2021-02-01 11:51:52,396 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:52,397 EPOCH 43 done: loss 0.1276 - lr 0.0062500\n",
      "2021-02-01 11:51:53,532 DEV : loss 0.021557990461587906 - score 0.9933\n",
      "2021-02-01 11:51:53,549 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:51:53,550 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:54,086 epoch 44 - iter 4/40 - loss 0.10610620 - samples/sec: 179.43 - lr: 0.006250\n",
      "2021-02-01 11:51:54,650 epoch 44 - iter 8/40 - loss 0.09085449 - samples/sec: 170.50 - lr: 0.006250\n",
      "2021-02-01 11:51:55,141 epoch 44 - iter 12/40 - loss 0.08223645 - samples/sec: 195.52 - lr: 0.006250\n",
      "2021-02-01 11:51:55,700 epoch 44 - iter 16/40 - loss 0.09757471 - samples/sec: 172.03 - lr: 0.006250\n",
      "2021-02-01 11:51:56,300 epoch 44 - iter 20/40 - loss 0.08923785 - samples/sec: 160.00 - lr: 0.006250\n",
      "2021-02-01 11:51:56,842 epoch 44 - iter 24/40 - loss 0.09712845 - samples/sec: 177.43 - lr: 0.006250\n",
      "2021-02-01 11:51:57,397 epoch 44 - iter 28/40 - loss 0.10458859 - samples/sec: 173.30 - lr: 0.006250\n",
      "2021-02-01 11:51:57,907 epoch 44 - iter 32/40 - loss 0.10565280 - samples/sec: 188.24 - lr: 0.006250\n",
      "2021-02-01 11:51:58,478 epoch 44 - iter 36/40 - loss 0.11230749 - samples/sec: 168.41 - lr: 0.006250\n",
      "2021-02-01 11:51:59,039 epoch 44 - iter 40/40 - loss 0.11280394 - samples/sec: 171.73 - lr: 0.006250\n",
      "2021-02-01 11:51:59,040 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:51:59,040 EPOCH 44 done: loss 0.1128 - lr 0.0062500\n",
      "2021-02-01 11:52:00,193 DEV : loss 0.02148115262389183 - score 0.9933\n",
      "2021-02-01 11:52:00,214 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:52:00,215 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:00,757 epoch 45 - iter 4/40 - loss 0.11707878 - samples/sec: 177.78 - lr: 0.006250\n",
      "2021-02-01 11:52:01,342 epoch 45 - iter 8/40 - loss 0.17299478 - samples/sec: 164.37 - lr: 0.006250\n",
      "2021-02-01 11:52:01,893 epoch 45 - iter 12/40 - loss 0.15508340 - samples/sec: 174.55 - lr: 0.006250\n",
      "2021-02-01 11:52:02,449 epoch 45 - iter 16/40 - loss 0.13263232 - samples/sec: 172.65 - lr: 0.006250\n",
      "2021-02-01 11:52:02,973 epoch 45 - iter 20/40 - loss 0.12231369 - samples/sec: 183.89 - lr: 0.006250\n",
      "2021-02-01 11:52:03,497 epoch 45 - iter 24/40 - loss 0.12148895 - samples/sec: 183.22 - lr: 0.006250\n",
      "2021-02-01 11:52:04,047 epoch 45 - iter 28/40 - loss 0.12520506 - samples/sec: 174.86 - lr: 0.006250\n",
      "2021-02-01 11:52:04,595 epoch 45 - iter 32/40 - loss 0.12619113 - samples/sec: 175.49 - lr: 0.006250\n",
      "2021-02-01 11:52:05,148 epoch 45 - iter 36/40 - loss 0.12964209 - samples/sec: 173.62 - lr: 0.006250\n",
      "2021-02-01 11:52:05,687 epoch 45 - iter 40/40 - loss 0.12576600 - samples/sec: 178.43 - lr: 0.006250\n",
      "2021-02-01 11:52:05,688 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:05,689 EPOCH 45 done: loss 0.1258 - lr 0.0062500\n",
      "2021-02-01 11:52:06,857 DEV : loss 0.020215217024087906 - score 0.9933\n",
      "Epoch    45: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2021-02-01 11:52:06,874 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:52:06,875 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:07,419 epoch 46 - iter 4/40 - loss 0.12349622 - samples/sec: 177.11 - lr: 0.003125\n",
      "2021-02-01 11:52:07,939 epoch 46 - iter 8/40 - loss 0.09361478 - samples/sec: 185.32 - lr: 0.003125\n",
      "2021-02-01 11:52:08,460 epoch 46 - iter 12/40 - loss 0.09922007 - samples/sec: 184.26 - lr: 0.003125\n",
      "2021-02-01 11:52:08,982 epoch 46 - iter 16/40 - loss 0.11044854 - samples/sec: 184.24 - lr: 0.003125\n",
      "2021-02-01 11:52:09,553 epoch 46 - iter 20/40 - loss 0.13114314 - samples/sec: 168.13 - lr: 0.003125\n",
      "2021-02-01 11:52:10,134 epoch 46 - iter 24/40 - loss 0.11892057 - samples/sec: 164.99 - lr: 0.003125\n",
      "2021-02-01 11:52:10,671 epoch 46 - iter 28/40 - loss 0.10879150 - samples/sec: 178.77 - lr: 0.003125\n",
      "2021-02-01 11:52:11,220 epoch 46 - iter 32/40 - loss 0.10067586 - samples/sec: 174.86 - lr: 0.003125\n",
      "2021-02-01 11:52:11,750 epoch 46 - iter 36/40 - loss 0.10661051 - samples/sec: 181.13 - lr: 0.003125\n",
      "2021-02-01 11:52:12,314 epoch 46 - iter 40/40 - loss 0.10112204 - samples/sec: 170.82 - lr: 0.003125\n",
      "2021-02-01 11:52:12,315 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:12,316 EPOCH 46 done: loss 0.1011 - lr 0.0031250\n",
      "2021-02-01 11:52:13,485 DEV : loss 0.020875748246908188 - score 0.9933\n",
      "2021-02-01 11:52:13,502 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:52:13,503 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:14,012 epoch 47 - iter 4/40 - loss 0.07725207 - samples/sec: 188.97 - lr: 0.003125\n",
      "2021-02-01 11:52:14,607 epoch 47 - iter 8/40 - loss 0.09128650 - samples/sec: 161.62 - lr: 0.003125\n",
      "2021-02-01 11:52:15,340 epoch 47 - iter 12/40 - loss 0.07872380 - samples/sec: 131.15 - lr: 0.003125\n",
      "2021-02-01 11:52:15,898 epoch 47 - iter 16/40 - loss 0.09612310 - samples/sec: 172.04 - lr: 0.003125\n",
      "2021-02-01 11:52:16,448 epoch 47 - iter 20/40 - loss 0.10666787 - samples/sec: 174.85 - lr: 0.003125\n",
      "2021-02-01 11:52:17,015 epoch 47 - iter 24/40 - loss 0.11683901 - samples/sec: 169.62 - lr: 0.003125\n",
      "2021-02-01 11:52:17,555 epoch 47 - iter 28/40 - loss 0.11384490 - samples/sec: 178.11 - lr: 0.003125\n",
      "2021-02-01 11:52:18,100 epoch 47 - iter 32/40 - loss 0.12044077 - samples/sec: 176.47 - lr: 0.003125\n",
      "2021-02-01 11:52:18,635 epoch 47 - iter 36/40 - loss 0.12164299 - samples/sec: 180.11 - lr: 0.003125\n",
      "2021-02-01 11:52:19,181 epoch 47 - iter 40/40 - loss 0.11850296 - samples/sec: 176.15 - lr: 0.003125\n",
      "2021-02-01 11:52:19,181 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:19,182 EPOCH 47 done: loss 0.1185 - lr 0.0031250\n",
      "2021-02-01 11:52:20,308 DEV : loss 0.0209732074290514 - score 0.9933\n",
      "2021-02-01 11:52:20,325 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:52:20,326 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:20,883 epoch 48 - iter 4/40 - loss 0.09845988 - samples/sec: 172.66 - lr: 0.003125\n",
      "2021-02-01 11:52:21,438 epoch 48 - iter 8/40 - loss 0.13904659 - samples/sec: 173.29 - lr: 0.003125\n",
      "2021-02-01 11:52:21,976 epoch 48 - iter 12/40 - loss 0.13955787 - samples/sec: 178.78 - lr: 0.003125\n",
      "2021-02-01 11:52:22,548 epoch 48 - iter 16/40 - loss 0.12367028 - samples/sec: 168.13 - lr: 0.003125\n",
      "2021-02-01 11:52:23,172 epoch 48 - iter 20/40 - loss 0.13194216 - samples/sec: 153.85 - lr: 0.003125\n",
      "2021-02-01 11:52:23,704 epoch 48 - iter 24/40 - loss 0.14091027 - samples/sec: 180.45 - lr: 0.003125\n",
      "2021-02-01 11:52:24,247 epoch 48 - iter 28/40 - loss 0.13202328 - samples/sec: 177.12 - lr: 0.003125\n",
      "2021-02-01 11:52:24,806 epoch 48 - iter 32/40 - loss 0.13399294 - samples/sec: 172.04 - lr: 0.003125\n",
      "2021-02-01 11:52:25,357 epoch 48 - iter 36/40 - loss 0.12850501 - samples/sec: 174.55 - lr: 0.003125\n",
      "2021-02-01 11:52:25,879 epoch 48 - iter 40/40 - loss 0.12862008 - samples/sec: 183.91 - lr: 0.003125\n",
      "2021-02-01 11:52:25,880 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:25,881 EPOCH 48 done: loss 0.1286 - lr 0.0031250\n",
      "2021-02-01 11:52:27,019 DEV : loss 0.022493455559015274 - score 0.9933\n",
      "2021-02-01 11:52:27,036 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:52:27,037 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:27,583 epoch 49 - iter 4/40 - loss 0.04983648 - samples/sec: 176.15 - lr: 0.003125\n",
      "2021-02-01 11:52:28,127 epoch 49 - iter 8/40 - loss 0.08991281 - samples/sec: 176.80 - lr: 0.003125\n",
      "2021-02-01 11:52:28,655 epoch 49 - iter 12/40 - loss 0.08698856 - samples/sec: 182.16 - lr: 0.003125\n",
      "2021-02-01 11:52:29,195 epoch 49 - iter 16/40 - loss 0.10525859 - samples/sec: 178.10 - lr: 0.003125\n",
      "2021-02-01 11:52:29,768 epoch 49 - iter 20/40 - loss 0.12720560 - samples/sec: 167.82 - lr: 0.003125\n",
      "2021-02-01 11:52:30,316 epoch 49 - iter 24/40 - loss 0.12264845 - samples/sec: 175.50 - lr: 0.003125\n",
      "2021-02-01 11:52:30,869 epoch 49 - iter 28/40 - loss 0.11183071 - samples/sec: 173.59 - lr: 0.003125\n",
      "2021-02-01 11:52:31,398 epoch 49 - iter 32/40 - loss 0.11115588 - samples/sec: 181.80 - lr: 0.003125\n",
      "2021-02-01 11:52:31,921 epoch 49 - iter 36/40 - loss 0.10533910 - samples/sec: 183.91 - lr: 0.003125\n",
      "2021-02-01 11:52:32,439 epoch 49 - iter 40/40 - loss 0.10121494 - samples/sec: 185.32 - lr: 0.003125\n",
      "2021-02-01 11:52:32,440 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:32,440 EPOCH 49 done: loss 0.1012 - lr 0.0031250\n",
      "2021-02-01 11:52:33,592 DEV : loss 0.021880289539694786 - score 0.9933\n",
      "Epoch    49: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2021-02-01 11:52:33,609 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:52:33,610 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:34,146 epoch 50 - iter 4/40 - loss 0.07372825 - samples/sec: 179.44 - lr: 0.001563\n",
      "2021-02-01 11:52:34,682 epoch 50 - iter 8/40 - loss 0.12304000 - samples/sec: 179.43 - lr: 0.001563\n",
      "2021-02-01 11:52:35,270 epoch 50 - iter 12/40 - loss 0.12797422 - samples/sec: 163.68 - lr: 0.001563\n",
      "2021-02-01 11:52:35,811 epoch 50 - iter 16/40 - loss 0.11127709 - samples/sec: 178.11 - lr: 0.001563\n",
      "2021-02-01 11:52:36,349 epoch 50 - iter 20/40 - loss 0.13592395 - samples/sec: 178.44 - lr: 0.001563\n",
      "2021-02-01 11:52:36,882 epoch 50 - iter 24/40 - loss 0.12317095 - samples/sec: 180.45 - lr: 0.001563\n",
      "2021-02-01 11:52:37,414 epoch 50 - iter 28/40 - loss 0.12631064 - samples/sec: 180.79 - lr: 0.001563\n",
      "2021-02-01 11:52:37,988 epoch 50 - iter 32/40 - loss 0.12495570 - samples/sec: 167.54 - lr: 0.001563\n",
      "2021-02-01 11:52:38,548 epoch 50 - iter 36/40 - loss 0.11733960 - samples/sec: 171.74 - lr: 0.001563\n",
      "2021-02-01 11:52:39,077 epoch 50 - iter 40/40 - loss 0.13220170 - samples/sec: 181.47 - lr: 0.001563\n",
      "2021-02-01 11:52:39,078 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:39,079 EPOCH 50 done: loss 0.1322 - lr 0.0015625\n",
      "2021-02-01 11:52:40,243 DEV : loss 0.021491369232535362 - score 0.9933\n",
      "2021-02-01 11:52:40,260 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:52:40,261 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:40,833 epoch 51 - iter 4/40 - loss 0.07804005 - samples/sec: 168.13 - lr: 0.001563\n",
      "2021-02-01 11:52:41,385 epoch 51 - iter 8/40 - loss 0.10142633 - samples/sec: 174.21 - lr: 0.001563\n",
      "2021-02-01 11:52:41,917 epoch 51 - iter 12/40 - loss 0.10513348 - samples/sec: 180.79 - lr: 0.001563\n",
      "2021-02-01 11:52:42,467 epoch 51 - iter 16/40 - loss 0.09192002 - samples/sec: 174.55 - lr: 0.001563\n",
      "2021-02-01 11:52:43,021 epoch 51 - iter 20/40 - loss 0.11710930 - samples/sec: 173.61 - lr: 0.001563\n",
      "2021-02-01 11:52:43,543 epoch 51 - iter 24/40 - loss 0.13163065 - samples/sec: 183.91 - lr: 0.001563\n",
      "2021-02-01 11:52:44,076 epoch 51 - iter 28/40 - loss 0.12591744 - samples/sec: 180.45 - lr: 0.001563\n",
      "2021-02-01 11:52:44,630 epoch 51 - iter 32/40 - loss 0.13386240 - samples/sec: 173.60 - lr: 0.001563\n",
      "2021-02-01 11:52:45,190 epoch 51 - iter 36/40 - loss 0.13382136 - samples/sec: 171.74 - lr: 0.001563\n",
      "2021-02-01 11:52:45,764 epoch 51 - iter 40/40 - loss 0.12589937 - samples/sec: 167.55 - lr: 0.001563\n",
      "2021-02-01 11:52:45,765 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:45,765 EPOCH 51 done: loss 0.1259 - lr 0.0015625\n",
      "2021-02-01 11:52:46,914 DEV : loss 0.021272866055369377 - score 0.9933\n",
      "2021-02-01 11:52:46,932 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:52:46,933 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:47,474 epoch 52 - iter 4/40 - loss 0.07938385 - samples/sec: 177.78 - lr: 0.001563\n",
      "2021-02-01 11:52:48,041 epoch 52 - iter 8/40 - loss 0.10100675 - samples/sec: 169.61 - lr: 0.001563\n",
      "2021-02-01 11:52:48,647 epoch 52 - iter 12/40 - loss 0.11449221 - samples/sec: 158.68 - lr: 0.001563\n",
      "2021-02-01 11:52:49,221 epoch 52 - iter 16/40 - loss 0.13285925 - samples/sec: 167.83 - lr: 0.001563\n",
      "2021-02-01 11:52:49,782 epoch 52 - iter 20/40 - loss 0.11428210 - samples/sec: 171.74 - lr: 0.001563\n",
      "2021-02-01 11:52:50,312 epoch 52 - iter 24/40 - loss 0.11166083 - samples/sec: 181.47 - lr: 0.001563\n",
      "2021-02-01 11:52:50,863 epoch 52 - iter 28/40 - loss 0.11417728 - samples/sec: 174.54 - lr: 0.001563\n",
      "2021-02-01 11:52:51,381 epoch 52 - iter 32/40 - loss 0.11909659 - samples/sec: 185.70 - lr: 0.001563\n",
      "2021-02-01 11:52:51,938 epoch 52 - iter 36/40 - loss 0.12094796 - samples/sec: 172.35 - lr: 0.001563\n",
      "2021-02-01 11:52:52,477 epoch 52 - iter 40/40 - loss 0.11336379 - samples/sec: 178.44 - lr: 0.001563\n",
      "2021-02-01 11:52:52,478 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:52,478 EPOCH 52 done: loss 0.1134 - lr 0.0015625\n",
      "2021-02-01 11:52:53,644 DEV : loss 0.02122827246785164 - score 0.9933\n",
      "2021-02-01 11:52:53,661 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:52:53,662 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:54,223 epoch 53 - iter 4/40 - loss 0.07496039 - samples/sec: 171.74 - lr: 0.001563\n",
      "2021-02-01 11:52:54,776 epoch 53 - iter 8/40 - loss 0.09729743 - samples/sec: 173.91 - lr: 0.001563\n",
      "2021-02-01 11:52:55,337 epoch 53 - iter 12/40 - loss 0.10404105 - samples/sec: 171.74 - lr: 0.001563\n",
      "2021-02-01 11:52:55,874 epoch 53 - iter 16/40 - loss 0.11808575 - samples/sec: 179.44 - lr: 0.001563\n",
      "2021-02-01 11:52:56,440 epoch 53 - iter 20/40 - loss 0.10499514 - samples/sec: 169.91 - lr: 0.001563\n",
      "2021-02-01 11:52:56,992 epoch 53 - iter 24/40 - loss 0.10441214 - samples/sec: 173.90 - lr: 0.001563\n",
      "2021-02-01 11:52:57,548 epoch 53 - iter 28/40 - loss 0.10810817 - samples/sec: 172.99 - lr: 0.001563\n",
      "2021-02-01 11:52:58,108 epoch 53 - iter 32/40 - loss 0.11165994 - samples/sec: 171.74 - lr: 0.001563\n",
      "2021-02-01 11:52:58,646 epoch 53 - iter 36/40 - loss 0.11493309 - samples/sec: 178.44 - lr: 0.001563\n",
      "2021-02-01 11:52:59,235 epoch 53 - iter 40/40 - loss 0.11436906 - samples/sec: 162.99 - lr: 0.001563\n",
      "2021-02-01 11:52:59,236 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:52:59,237 EPOCH 53 done: loss 0.1144 - lr 0.0015625\n",
      "2021-02-01 11:53:00,409 DEV : loss 0.021011125296354294 - score 0.9933\n",
      "Epoch    53: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2021-02-01 11:53:00,427 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:53:00,428 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:00,999 epoch 54 - iter 4/40 - loss 0.08900944 - samples/sec: 168.42 - lr: 0.000781\n",
      "2021-02-01 11:53:01,565 epoch 54 - iter 8/40 - loss 0.10279588 - samples/sec: 169.61 - lr: 0.000781\n",
      "2021-02-01 11:53:02,106 epoch 54 - iter 12/40 - loss 0.11542498 - samples/sec: 177.45 - lr: 0.000781\n",
      "2021-02-01 11:53:02,638 epoch 54 - iter 16/40 - loss 0.10660817 - samples/sec: 180.79 - lr: 0.000781\n",
      "2021-02-01 11:53:03,215 epoch 54 - iter 20/40 - loss 0.10437282 - samples/sec: 166.37 - lr: 0.000781\n",
      "2021-02-01 11:53:03,726 epoch 54 - iter 24/40 - loss 0.10523689 - samples/sec: 187.88 - lr: 0.000781\n",
      "2021-02-01 11:53:04,266 epoch 54 - iter 28/40 - loss 0.10414582 - samples/sec: 178.11 - lr: 0.000781\n",
      "2021-02-01 11:53:04,808 epoch 54 - iter 32/40 - loss 0.10893602 - samples/sec: 177.44 - lr: 0.000781\n",
      "2021-02-01 11:53:05,348 epoch 54 - iter 36/40 - loss 0.10753425 - samples/sec: 178.09 - lr: 0.000781\n",
      "2021-02-01 11:53:05,897 epoch 54 - iter 40/40 - loss 0.10171315 - samples/sec: 175.17 - lr: 0.000781\n",
      "2021-02-01 11:53:05,898 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:05,898 EPOCH 54 done: loss 0.1017 - lr 0.0007813\n",
      "2021-02-01 11:53:07,032 DEV : loss 0.021085012704133987 - score 0.9933\n",
      "2021-02-01 11:53:07,050 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:53:07,051 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:07,572 epoch 55 - iter 4/40 - loss 0.08971198 - samples/sec: 184.95 - lr: 0.000781\n",
      "2021-02-01 11:53:08,130 epoch 55 - iter 8/40 - loss 0.14164043 - samples/sec: 172.05 - lr: 0.000781\n",
      "2021-02-01 11:53:08,650 epoch 55 - iter 12/40 - loss 0.17721097 - samples/sec: 184.97 - lr: 0.000781\n",
      "2021-02-01 11:53:09,214 epoch 55 - iter 16/40 - loss 0.18447425 - samples/sec: 170.21 - lr: 0.000781\n",
      "2021-02-01 11:53:09,738 epoch 55 - iter 20/40 - loss 0.15919171 - samples/sec: 183.20 - lr: 0.000781\n",
      "2021-02-01 11:53:10,265 epoch 55 - iter 24/40 - loss 0.14610578 - samples/sec: 182.50 - lr: 0.000781\n",
      "2021-02-01 11:53:10,811 epoch 55 - iter 28/40 - loss 0.14320691 - samples/sec: 175.84 - lr: 0.000781\n",
      "2021-02-01 11:53:11,393 epoch 55 - iter 32/40 - loss 0.13219425 - samples/sec: 165.22 - lr: 0.000781\n",
      "2021-02-01 11:53:11,924 epoch 55 - iter 36/40 - loss 0.13203926 - samples/sec: 181.12 - lr: 0.000781\n",
      "2021-02-01 11:53:12,452 epoch 55 - iter 40/40 - loss 0.13334750 - samples/sec: 181.82 - lr: 0.000781\n",
      "2021-02-01 11:53:12,453 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:12,453 EPOCH 55 done: loss 0.1333 - lr 0.0007813\n",
      "2021-02-01 11:53:13,596 DEV : loss 0.020668212324380875 - score 0.9933\n",
      "2021-02-01 11:53:13,613 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:53:13,614 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:14,175 epoch 56 - iter 4/40 - loss 0.11211944 - samples/sec: 171.42 - lr: 0.000781\n",
      "2021-02-01 11:53:14,730 epoch 56 - iter 8/40 - loss 0.11723970 - samples/sec: 173.58 - lr: 0.000781\n",
      "2021-02-01 11:53:15,303 epoch 56 - iter 12/40 - loss 0.09448681 - samples/sec: 167.84 - lr: 0.000781\n",
      "2021-02-01 11:53:15,847 epoch 56 - iter 16/40 - loss 0.09647347 - samples/sec: 176.80 - lr: 0.000781\n",
      "2021-02-01 11:53:16,414 epoch 56 - iter 20/40 - loss 0.10434691 - samples/sec: 169.61 - lr: 0.000781\n",
      "2021-02-01 11:53:16,944 epoch 56 - iter 24/40 - loss 0.10014282 - samples/sec: 180.93 - lr: 0.000781\n",
      "2021-02-01 11:53:17,493 epoch 56 - iter 28/40 - loss 0.10154952 - samples/sec: 174.99 - lr: 0.000781\n",
      "2021-02-01 11:53:18,033 epoch 56 - iter 32/40 - loss 0.10555093 - samples/sec: 178.12 - lr: 0.000781\n",
      "2021-02-01 11:53:18,614 epoch 56 - iter 36/40 - loss 0.10871757 - samples/sec: 165.52 - lr: 0.000781\n",
      "2021-02-01 11:53:19,134 epoch 56 - iter 40/40 - loss 0.10951615 - samples/sec: 184.62 - lr: 0.000781\n",
      "2021-02-01 11:53:19,134 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:19,135 EPOCH 56 done: loss 0.1095 - lr 0.0007813\n",
      "2021-02-01 11:53:20,260 DEV : loss 0.020606450736522675 - score 0.9933\n",
      "2021-02-01 11:53:20,281 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:53:20,283 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:20,821 epoch 57 - iter 4/40 - loss 0.13594214 - samples/sec: 178.77 - lr: 0.000781\n",
      "2021-02-01 11:53:21,362 epoch 57 - iter 8/40 - loss 0.12217160 - samples/sec: 177.77 - lr: 0.000781\n",
      "2021-02-01 11:53:21,946 epoch 57 - iter 12/40 - loss 0.10645899 - samples/sec: 164.67 - lr: 0.000781\n",
      "2021-02-01 11:53:22,521 epoch 57 - iter 16/40 - loss 0.13736451 - samples/sec: 167.62 - lr: 0.000781\n",
      "2021-02-01 11:53:23,014 epoch 57 - iter 20/40 - loss 0.12123768 - samples/sec: 195.12 - lr: 0.000781\n",
      "2021-02-01 11:53:23,564 epoch 57 - iter 24/40 - loss 0.10790869 - samples/sec: 174.86 - lr: 0.000781\n",
      "2021-02-01 11:53:24,080 epoch 57 - iter 28/40 - loss 0.10640922 - samples/sec: 186.40 - lr: 0.000781\n",
      "2021-02-01 11:53:24,620 epoch 57 - iter 32/40 - loss 0.10903836 - samples/sec: 178.10 - lr: 0.000781\n",
      "2021-02-01 11:53:25,129 epoch 57 - iter 36/40 - loss 0.11140755 - samples/sec: 188.96 - lr: 0.000781\n",
      "2021-02-01 11:53:25,700 epoch 57 - iter 40/40 - loss 0.10672068 - samples/sec: 168.51 - lr: 0.000781\n",
      "2021-02-01 11:53:25,701 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:25,701 EPOCH 57 done: loss 0.1067 - lr 0.0007813\n",
      "2021-02-01 11:53:26,810 DEV : loss 0.020593460649251938 - score 0.9933\n",
      "Epoch    57: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2021-02-01 11:53:26,827 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:53:26,828 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:27,368 epoch 58 - iter 4/40 - loss 0.14132182 - samples/sec: 178.10 - lr: 0.000391\n",
      "2021-02-01 11:53:27,924 epoch 58 - iter 8/40 - loss 0.10262283 - samples/sec: 172.97 - lr: 0.000391\n",
      "2021-02-01 11:53:28,463 epoch 58 - iter 12/40 - loss 0.08511901 - samples/sec: 178.10 - lr: 0.000391\n",
      "2021-02-01 11:53:29,021 epoch 58 - iter 16/40 - loss 0.10476345 - samples/sec: 172.34 - lr: 0.000391\n",
      "2021-02-01 11:53:29,578 epoch 58 - iter 20/40 - loss 0.10677449 - samples/sec: 172.67 - lr: 0.000391\n",
      "2021-02-01 11:53:30,101 epoch 58 - iter 24/40 - loss 0.09641083 - samples/sec: 184.44 - lr: 0.000391\n",
      "2021-02-01 11:53:30,639 epoch 58 - iter 28/40 - loss 0.09232866 - samples/sec: 178.60 - lr: 0.000391\n",
      "2021-02-01 11:53:31,197 epoch 58 - iter 32/40 - loss 0.09410805 - samples/sec: 172.35 - lr: 0.000391\n",
      "2021-02-01 11:53:31,748 epoch 58 - iter 36/40 - loss 0.10219860 - samples/sec: 174.55 - lr: 0.000391\n",
      "2021-02-01 11:53:32,278 epoch 58 - iter 40/40 - loss 0.09969668 - samples/sec: 181.13 - lr: 0.000391\n",
      "2021-02-01 11:53:32,279 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:32,280 EPOCH 58 done: loss 0.0997 - lr 0.0003906\n",
      "2021-02-01 11:53:33,410 DEV : loss 0.020628681406378746 - score 0.9933\n",
      "2021-02-01 11:53:33,427 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:53:33,429 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:33,976 epoch 59 - iter 4/40 - loss 0.07886064 - samples/sec: 175.82 - lr: 0.000391\n",
      "2021-02-01 11:53:34,510 epoch 59 - iter 8/40 - loss 0.17869376 - samples/sec: 180.11 - lr: 0.000391\n",
      "2021-02-01 11:53:35,075 epoch 59 - iter 12/40 - loss 0.17159766 - samples/sec: 169.90 - lr: 0.000391\n",
      "2021-02-01 11:53:35,613 epoch 59 - iter 16/40 - loss 0.18070747 - samples/sec: 178.45 - lr: 0.000391\n",
      "2021-02-01 11:53:36,128 epoch 59 - iter 20/40 - loss 0.18131903 - samples/sec: 186.41 - lr: 0.000391\n",
      "2021-02-01 11:53:36,684 epoch 59 - iter 24/40 - loss 0.16147176 - samples/sec: 172.44 - lr: 0.000391\n",
      "2021-02-01 11:53:37,247 epoch 59 - iter 28/40 - loss 0.15330438 - samples/sec: 170.52 - lr: 0.000391\n",
      "2021-02-01 11:53:37,759 epoch 59 - iter 32/40 - loss 0.14657345 - samples/sec: 187.85 - lr: 0.000391\n",
      "2021-02-01 11:53:38,288 epoch 59 - iter 36/40 - loss 0.14163134 - samples/sec: 182.16 - lr: 0.000391\n",
      "2021-02-01 11:53:38,834 epoch 59 - iter 40/40 - loss 0.14031639 - samples/sec: 175.82 - lr: 0.000391\n",
      "2021-02-01 11:53:38,835 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:38,836 EPOCH 59 done: loss 0.1403 - lr 0.0003906\n",
      "2021-02-01 11:53:39,973 DEV : loss 0.020626956596970558 - score 0.9933\n",
      "2021-02-01 11:53:39,990 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:53:39,991 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:40,550 epoch 60 - iter 4/40 - loss 0.03506637 - samples/sec: 172.03 - lr: 0.000391\n",
      "2021-02-01 11:53:41,104 epoch 60 - iter 8/40 - loss 0.05760257 - samples/sec: 173.58 - lr: 0.000391\n",
      "2021-02-01 11:53:41,632 epoch 60 - iter 12/40 - loss 0.09532065 - samples/sec: 182.16 - lr: 0.000391\n",
      "2021-02-01 11:53:42,232 epoch 60 - iter 16/40 - loss 0.08282974 - samples/sec: 160.26 - lr: 0.000391\n",
      "2021-02-01 11:53:42,777 epoch 60 - iter 20/40 - loss 0.08396820 - samples/sec: 176.77 - lr: 0.000391\n",
      "2021-02-01 11:53:43,337 epoch 60 - iter 24/40 - loss 0.08948205 - samples/sec: 171.74 - lr: 0.000391\n",
      "2021-02-01 11:53:43,879 epoch 60 - iter 28/40 - loss 0.10567424 - samples/sec: 177.12 - lr: 0.000391\n",
      "2021-02-01 11:53:44,440 epoch 60 - iter 32/40 - loss 0.11515882 - samples/sec: 171.58 - lr: 0.000391\n",
      "2021-02-01 11:53:44,987 epoch 60 - iter 36/40 - loss 0.11414492 - samples/sec: 175.81 - lr: 0.000391\n",
      "2021-02-01 11:53:45,564 epoch 60 - iter 40/40 - loss 0.10911994 - samples/sec: 166.78 - lr: 0.000391\n",
      "2021-02-01 11:53:45,565 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:45,565 EPOCH 60 done: loss 0.1091 - lr 0.0003906\n",
      "2021-02-01 11:53:46,683 DEV : loss 0.02053683251142502 - score 0.9933\n",
      "2021-02-01 11:53:46,703 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:53:46,705 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:47,245 epoch 61 - iter 4/40 - loss 0.08287573 - samples/sec: 177.94 - lr: 0.000391\n",
      "2021-02-01 11:53:47,785 epoch 61 - iter 8/40 - loss 0.07802951 - samples/sec: 178.11 - lr: 0.000391\n",
      "2021-02-01 11:53:48,321 epoch 61 - iter 12/40 - loss 0.07805835 - samples/sec: 179.44 - lr: 0.000391\n",
      "2021-02-01 11:53:48,873 epoch 61 - iter 16/40 - loss 0.09279829 - samples/sec: 174.23 - lr: 0.000391\n",
      "2021-02-01 11:53:49,422 epoch 61 - iter 20/40 - loss 0.09642230 - samples/sec: 174.86 - lr: 0.000391\n",
      "2021-02-01 11:53:49,948 epoch 61 - iter 24/40 - loss 0.09838291 - samples/sec: 182.86 - lr: 0.000391\n",
      "2021-02-01 11:53:50,469 epoch 61 - iter 28/40 - loss 0.09728191 - samples/sec: 184.62 - lr: 0.000391\n",
      "2021-02-01 11:53:51,025 epoch 61 - iter 32/40 - loss 0.09457729 - samples/sec: 172.66 - lr: 0.000391\n",
      "2021-02-01 11:53:51,600 epoch 61 - iter 36/40 - loss 0.09654230 - samples/sec: 167.25 - lr: 0.000391\n",
      "2021-02-01 11:53:52,172 epoch 61 - iter 40/40 - loss 0.09967817 - samples/sec: 168.11 - lr: 0.000391\n",
      "2021-02-01 11:53:52,173 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:52,174 EPOCH 61 done: loss 0.0997 - lr 0.0003906\n",
      "2021-02-01 11:53:53,324 DEV : loss 0.02075272798538208 - score 0.9933\n",
      "Epoch    61: reducing learning rate of group 0 to 1.9531e-04.\n",
      "2021-02-01 11:53:53,342 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:53:53,343 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:53,902 epoch 62 - iter 4/40 - loss 0.06148577 - samples/sec: 172.04 - lr: 0.000195\n",
      "2021-02-01 11:53:54,461 epoch 62 - iter 8/40 - loss 0.07851271 - samples/sec: 171.74 - lr: 0.000195\n",
      "2021-02-01 11:53:55,052 epoch 62 - iter 12/40 - loss 0.07684907 - samples/sec: 163.00 - lr: 0.000195\n",
      "2021-02-01 11:53:55,616 epoch 62 - iter 16/40 - loss 0.09630726 - samples/sec: 170.52 - lr: 0.000195\n",
      "2021-02-01 11:53:56,125 epoch 62 - iter 20/40 - loss 0.09872818 - samples/sec: 188.59 - lr: 0.000195\n",
      "2021-02-01 11:53:56,669 epoch 62 - iter 24/40 - loss 0.11181932 - samples/sec: 177.10 - lr: 0.000195\n",
      "2021-02-01 11:53:57,221 epoch 62 - iter 28/40 - loss 0.10471868 - samples/sec: 174.22 - lr: 0.000195\n",
      "2021-02-01 11:53:57,753 epoch 62 - iter 32/40 - loss 0.10063420 - samples/sec: 180.45 - lr: 0.000195\n",
      "2021-02-01 11:53:58,317 epoch 62 - iter 36/40 - loss 0.10238912 - samples/sec: 170.51 - lr: 0.000195\n",
      "2021-02-01 11:53:58,845 epoch 62 - iter 40/40 - loss 0.11267533 - samples/sec: 182.15 - lr: 0.000195\n",
      "2021-02-01 11:53:58,846 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:53:58,846 EPOCH 62 done: loss 0.1127 - lr 0.0001953\n",
      "2021-02-01 11:54:00,162 DEV : loss 0.020693758502602577 - score 0.9933\n",
      "2021-02-01 11:54:00,179 BAD EPOCHS (no improvement): 1\n",
      "2021-02-01 11:54:00,181 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:00,753 epoch 63 - iter 4/40 - loss 0.14161762 - samples/sec: 168.42 - lr: 0.000195\n",
      "2021-02-01 11:54:01,309 epoch 63 - iter 8/40 - loss 0.12964034 - samples/sec: 172.96 - lr: 0.000195\n",
      "2021-02-01 11:54:01,914 epoch 63 - iter 12/40 - loss 0.10711384 - samples/sec: 158.93 - lr: 0.000195\n",
      "2021-02-01 11:54:02,471 epoch 63 - iter 16/40 - loss 0.10404424 - samples/sec: 172.65 - lr: 0.000195\n",
      "2021-02-01 11:54:03,023 epoch 63 - iter 20/40 - loss 0.09744609 - samples/sec: 174.23 - lr: 0.000195\n",
      "2021-02-01 11:54:03,577 epoch 63 - iter 24/40 - loss 0.09500361 - samples/sec: 173.59 - lr: 0.000195\n",
      "2021-02-01 11:54:04,147 epoch 63 - iter 28/40 - loss 0.09421945 - samples/sec: 168.68 - lr: 0.000195\n",
      "2021-02-01 11:54:04,668 epoch 63 - iter 32/40 - loss 0.09361643 - samples/sec: 184.60 - lr: 0.000195\n",
      "2021-02-01 11:54:05,184 epoch 63 - iter 36/40 - loss 0.10110787 - samples/sec: 186.06 - lr: 0.000195\n",
      "2021-02-01 11:54:05,731 epoch 63 - iter 40/40 - loss 0.11283365 - samples/sec: 175.50 - lr: 0.000195\n",
      "2021-02-01 11:54:05,732 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:05,733 EPOCH 63 done: loss 0.1128 - lr 0.0001953\n",
      "2021-02-01 11:54:06,910 DEV : loss 0.02075963094830513 - score 0.9933\n",
      "2021-02-01 11:54:06,928 BAD EPOCHS (no improvement): 2\n",
      "2021-02-01 11:54:06,930 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:07,488 epoch 64 - iter 4/40 - loss 0.16394751 - samples/sec: 172.46 - lr: 0.000195\n",
      "2021-02-01 11:54:08,008 epoch 64 - iter 8/40 - loss 0.14566356 - samples/sec: 184.63 - lr: 0.000195\n",
      "2021-02-01 11:54:08,589 epoch 64 - iter 12/40 - loss 0.12815506 - samples/sec: 165.52 - lr: 0.000195\n",
      "2021-02-01 11:54:09,136 epoch 64 - iter 16/40 - loss 0.12799096 - samples/sec: 175.81 - lr: 0.000195\n",
      "2021-02-01 11:54:09,660 epoch 64 - iter 20/40 - loss 0.14071882 - samples/sec: 183.57 - lr: 0.000195\n",
      "2021-02-01 11:54:10,215 epoch 64 - iter 24/40 - loss 0.15449081 - samples/sec: 173.09 - lr: 0.000195\n",
      "2021-02-01 11:54:10,767 epoch 64 - iter 28/40 - loss 0.14907321 - samples/sec: 173.92 - lr: 0.000195\n",
      "2021-02-01 11:54:11,334 epoch 64 - iter 32/40 - loss 0.15077633 - samples/sec: 169.60 - lr: 0.000195\n",
      "2021-02-01 11:54:11,902 epoch 64 - iter 36/40 - loss 0.14488767 - samples/sec: 169.31 - lr: 0.000195\n",
      "2021-02-01 11:54:12,460 epoch 64 - iter 40/40 - loss 0.13678013 - samples/sec: 172.06 - lr: 0.000195\n",
      "2021-02-01 11:54:12,461 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:12,461 EPOCH 64 done: loss 0.1368 - lr 0.0001953\n",
      "2021-02-01 11:54:13,629 DEV : loss 0.020676707848906517 - score 0.9933\n",
      "2021-02-01 11:54:13,647 BAD EPOCHS (no improvement): 3\n",
      "2021-02-01 11:54:13,648 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:14,211 epoch 65 - iter 4/40 - loss 0.16972741 - samples/sec: 170.82 - lr: 0.000195\n",
      "2021-02-01 11:54:14,770 epoch 65 - iter 8/40 - loss 0.12618037 - samples/sec: 172.05 - lr: 0.000195\n",
      "2021-02-01 11:54:15,345 epoch 65 - iter 12/40 - loss 0.10068952 - samples/sec: 166.95 - lr: 0.000195\n",
      "2021-02-01 11:54:15,913 epoch 65 - iter 16/40 - loss 0.08462910 - samples/sec: 169.33 - lr: 0.000195\n",
      "2021-02-01 11:54:16,485 epoch 65 - iter 20/40 - loss 0.11480596 - samples/sec: 168.13 - lr: 0.000195\n",
      "2021-02-01 11:54:17,042 epoch 65 - iter 24/40 - loss 0.11578029 - samples/sec: 172.65 - lr: 0.000195\n",
      "2021-02-01 11:54:17,613 epoch 65 - iter 28/40 - loss 0.10613445 - samples/sec: 168.12 - lr: 0.000195\n",
      "2021-02-01 11:54:18,160 epoch 65 - iter 32/40 - loss 0.10343139 - samples/sec: 175.82 - lr: 0.000195\n",
      "2021-02-01 11:54:18,698 epoch 65 - iter 36/40 - loss 0.10268633 - samples/sec: 178.79 - lr: 0.000195\n",
      "2021-02-01 11:54:19,257 epoch 65 - iter 40/40 - loss 0.10282878 - samples/sec: 172.04 - lr: 0.000195\n",
      "2021-02-01 11:54:19,258 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:19,258 EPOCH 65 done: loss 0.1028 - lr 0.0001953\n",
      "2021-02-01 11:54:20,420 DEV : loss 0.020583970472216606 - score 0.9933\n",
      "Epoch    65: reducing learning rate of group 0 to 9.7656e-05.\n",
      "2021-02-01 11:54:20,437 BAD EPOCHS (no improvement): 4\n",
      "2021-02-01 11:54:20,438 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:20,439 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:20,440 learning rate too small - quitting training!\n",
      "2021-02-01 11:54:20,440 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:23,677 ----------------------------------------------------------------------------------------------------\n",
      "2021-02-01 11:54:23,677 Testing using best model ...\n",
      "2021-02-01 11:54:23,678 loading file ..\\model\\taggers\\pii-ner-v1\\best-model.pt\n",
      "2021-02-01 11:54:28,106 0.9933\t0.9933\t0.9933\n",
      "2021-02-01 11:54:28,106 \n",
      "Results:\n",
      "- F1-score (micro) 0.9933\n",
      "- F1-score (macro) 0.9971\n",
      "\n",
      "By class:\n",
      "Address    tp: 99 - fp: 1 - fn: 1 - precision: 0.9900 - recall: 0.9900 - f1-score: 0.9900\n",
      "CreditCardNumber tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "Email      tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "Name       tp: 99 - fp: 1 - fn: 1 - precision: 0.9900 - recall: 0.9900 - f1-score: 0.9900\n",
      "Phone_number tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "Plates     tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "SSN        tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
      "2021-02-01 11:54:28,107 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'test_score': 0.9933333333333333,\n",
       " 'dev_score_history': [0.49128919860627174,\n",
       "  0.9205298013245033,\n",
       "  0.9601328903654486,\n",
       "  0.9683860232945091,\n",
       "  0.9667774086378739,\n",
       "  0.9750415973377703,\n",
       "  0.9734219269102989,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9767441860465117,\n",
       "  0.9850249584026622,\n",
       "  0.99,\n",
       "  0.9866666666666668,\n",
       "  0.99,\n",
       "  0.9866666666666668,\n",
       "  0.99,\n",
       "  0.9933333333333333,\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.9933333333333333,\n",
       "  0.99,\n",
       "  0.9916805324459235,\n",
       "  0.99,\n",
       "  0.9933333333333333,\n",
       "  0.99,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9966666666666667,\n",
       "  0.9933333333333333,\n",
       "  0.9966666666666667,\n",
       "  0.9933333333333333,\n",
       "  0.99,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333,\n",
       "  0.9933333333333333],\n",
       " 'train_loss_history': [10.895954412221908,\n",
       "  2.901124769449234,\n",
       "  1.5221708968281746,\n",
       "  0.9677627235651016,\n",
       "  0.6518452808260917,\n",
       "  0.5117852713912725,\n",
       "  0.4751723125576973,\n",
       "  0.363003808259964,\n",
       "  0.36819805651903154,\n",
       "  0.3191299272701144,\n",
       "  0.28560963105410336,\n",
       "  0.20508874049410225,\n",
       "  0.2225665705278516,\n",
       "  0.2075606203638017,\n",
       "  0.21372182685881852,\n",
       "  0.1836692588403821,\n",
       "  0.2119359160773456,\n",
       "  0.15569044081494213,\n",
       "  0.16953994547948242,\n",
       "  0.1634783839341253,\n",
       "  0.14032773058861495,\n",
       "  0.1373111843597144,\n",
       "  0.15555838774889708,\n",
       "  0.13390172366052866,\n",
       "  0.12570020304992796,\n",
       "  0.16285622944124042,\n",
       "  0.1237062368541956,\n",
       "  0.11826773018110544,\n",
       "  0.15235425382852555,\n",
       "  0.17093973341397942,\n",
       "  0.12151828682981432,\n",
       "  0.12292935443110764,\n",
       "  0.11421954142861068,\n",
       "  0.14903518036007882,\n",
       "  0.129028567369096,\n",
       "  0.1155932858819142,\n",
       "  0.12835879307240247,\n",
       "  0.10167911304160952,\n",
       "  0.13990668188780547,\n",
       "  0.12383257076144219,\n",
       "  0.13816183796152473,\n",
       "  0.10783176310360432,\n",
       "  0.12760878382250668,\n",
       "  0.1128039394505322,\n",
       "  0.1257659954484552,\n",
       "  0.10112203643657267,\n",
       "  0.11850296151824295,\n",
       "  0.12862007636576892,\n",
       "  0.1012149399612099,\n",
       "  0.1322016987018287,\n",
       "  0.12589936647564173,\n",
       "  0.11336378594860434,\n",
       "  0.11436905753798783,\n",
       "  0.1017131517175585,\n",
       "  0.13334749843925237,\n",
       "  0.1095161510631442,\n",
       "  0.1067206770181656,\n",
       "  0.0996966790407896,\n",
       "  0.1403163904324174,\n",
       "  0.10911993908230215,\n",
       "  0.09967817380093039,\n",
       "  0.11267532822676003,\n",
       "  0.11283364584669471,\n",
       "  0.13678012751042842,\n",
       "  0.10282877581194043],\n",
       " 'dev_loss_history': [3.3010094165802,\n",
       "  1.079824686050415,\n",
       "  0.4938148856163025,\n",
       "  0.27678221464157104,\n",
       "  0.18717226386070251,\n",
       "  0.1504875272512436,\n",
       "  0.10954887419939041,\n",
       "  0.10071191936731339,\n",
       "  0.07849925756454468,\n",
       "  0.07664277404546738,\n",
       "  0.05619174614548683,\n",
       "  0.058478906750679016,\n",
       "  0.0685347393155098,\n",
       "  0.04162704199552536,\n",
       "  0.04949627071619034,\n",
       "  0.04371020942926407,\n",
       "  0.03770633414387703,\n",
       "  0.04094585403800011,\n",
       "  0.04235628992319107,\n",
       "  0.033288776874542236,\n",
       "  0.03735361248254776,\n",
       "  0.02740776166319847,\n",
       "  0.026347454637289047,\n",
       "  0.027666958048939705,\n",
       "  0.02988404594361782,\n",
       "  0.025246622040867805,\n",
       "  0.025729408487677574,\n",
       "  0.028199810534715652,\n",
       "  0.022333987057209015,\n",
       "  0.027369210496544838,\n",
       "  0.026891253888607025,\n",
       "  0.022949334233999252,\n",
       "  0.020772866904735565,\n",
       "  0.02664768323302269,\n",
       "  0.022028153762221336,\n",
       "  0.02187788113951683,\n",
       "  0.0243424903601408,\n",
       "  0.022907396778464317,\n",
       "  0.020041445270180702,\n",
       "  0.022165412083268166,\n",
       "  0.019173508509993553,\n",
       "  0.01969796232879162,\n",
       "  0.021557990461587906,\n",
       "  0.02148115262389183,\n",
       "  0.020215217024087906,\n",
       "  0.020875748246908188,\n",
       "  0.0209732074290514,\n",
       "  0.022493455559015274,\n",
       "  0.021880289539694786,\n",
       "  0.021491369232535362,\n",
       "  0.021272866055369377,\n",
       "  0.02122827246785164,\n",
       "  0.021011125296354294,\n",
       "  0.021085012704133987,\n",
       "  0.020668212324380875,\n",
       "  0.020606450736522675,\n",
       "  0.020593460649251938,\n",
       "  0.020628681406378746,\n",
       "  0.020626956596970558,\n",
       "  0.02053683251142502,\n",
       "  0.02075272798538208,\n",
       "  0.020693758502602577,\n",
       "  0.02075963094830513,\n",
       "  0.020676707848906517,\n",
       "  0.020583970472216606]}"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# initialize trainer\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# start training\n",
    "trainer.train('../model/taggers/pii-ner-v1',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=24,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "source": [
    "## Scores\n",
    "\n",
    "In the interest of visibility I have copied over the final scores from the logs.\n",
    "```\n",
    "2021-02-01 11:54:23,677 Testing using best model ...\n",
    "2021-02-01 11:54:23,678 loading file ..\\model\\taggers\\pii-ner-v1\\best-model.pt\n",
    "2021-02-01 11:54:28,106 0.9933\t0.9933\t0.9933\n",
    "2021-02-01 11:54:28,106 \n",
    "Results:\n",
    "- F1-score (micro) 0.9933\n",
    "- F1-score (macro) 0.9971\n",
    "\n",
    "By class:\n",
    "Address    tp: 99 - fp: 1 - fn: 1 - precision: 0.9900 - recall: 0.9900 - f1-score: 0.9900\n",
    "CreditCardNumber tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "Email      tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "Name       tp: 99 - fp: 1 - fn: 1 - precision: 0.9900 - recall: 0.9900 - f1-score: 0.9900\n",
    "Phone_number tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "Plates     tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "SSN        tp: 20 - fp: 0 - fn: 0 - precision: 1.0000 - recall: 1.0000 - f1-score: 1.0000\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-02-01 11:54:28,191 loading file ../model/taggers/pii-ner-v1/final-model.pt\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "model = SequenceTagger.load('../model/taggers/pii-ner-v1/final-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentence:\n",
      "Hold home fight nor customer defense. Shields Shake player something.\n",
      "Tagged Sentence:\n",
      "Hold home fight nor customer defense . Shields <B-Name> Shake player something .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [8]: \"Shields\"   [− Labels: Name (0.7236)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Box direction clear sense democratic power. Adult determine rule Deanna across sometimes according.\n",
      "Tagged Sentence:\n",
      "Box direction clear sense democratic power . Adult determine rule Deanna <B-Name> across sometimes according .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [11]: \"Deanna\"   [− Labels: Name (0.999)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "High same pass Smith change. Effort board fly onto middle detail. Ahead chance small ability reduce under. Middle policy use single become.\n",
      "Tagged Sentence:\n",
      "High same pass Smith <B-Name> change . Effort board fly onto middle detail . Ahead chance small ability reduce under . Middle policy use single become .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [4]: \"Smith\"   [− Labels: Name (0.9782)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Product similar final sense senior least. Model explain reveal American they behind source. Join Ariana White president other arm until feel force.\n",
      "Tagged Sentence:\n",
      "Product similar final sense senior least . Model explain reveal American they behind source . Join Ariana <B-Name> White <I-Name> president other arm until feel force .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [17,18]: \"Ariana White\"   [− Labels: Name (0.9971)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Matthew Haas Market Republican hand sign.\n",
      "Tagged Sentence:\n",
      "Matthew <B-Name> Haas <I-Name> Market Republican hand sign .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [1,2]: \"Matthew Haas\"   [− Labels: Name (0.9799)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Whom simple Franklin nice three car. Music answer southern performance glass around.\n",
      "Tagged Sentence:\n",
      "Whom simple Franklin <B-Name> nice three car . Music answer southern performance glass around .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [3]: \"Franklin\"   [− Labels: Name (0.977)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Everybody small suggest into president. Over manager Charles government they.\n",
      "Tagged Sentence:\n",
      "Everybody small suggest into president . Over manager Charles <B-Name> government they .\n",
      "True Label: Name\n",
      "Entity\n",
      "Span [9]: \"Charles\"   [− Labels: Name (0.9952)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Dark turn purpose attack set way. Significant impact book daughter manager behavior pressure. Price true we pressure culture design 22868 Strong Square Suite 603 serve answer.\n",
      "Tagged Sentence:\n",
      "Dark turn purpose attack set way . Significant impact book daughter manager behavior pressure . Price true we pressure culture design 22868 <B-Address> Strong <I-Address> Square <I-Address> Suite <I-Address> 603 <I-Address> serve answer .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [22,23,24,25,26]: \"22868 Strong Square Suite 603\"   [− Labels: Address (0.9877)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Class speech structure ask prevent. Do tree actually 384 Moran River Suite 724 West Maureenport, NV 14327 forward.\n",
      "Tagged Sentence:\n",
      "Class speech structure ask prevent . Do tree actually 384 <B-Address> Moran <I-Address> River <I-Address> Suite <I-Address> 724 <I-Address> West <I-Address> Maureenport <I-Address> , <I-Address> NV <I-Address> 14327 <I-Address> forward .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [10,11,12,13,14,15,16,17,18,19]: \"384 Moran River Suite 724 West Maureenport , NV 14327\"   [− Labels: Address (0.9995)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Cold write close full likely actually plant method. Suite 139 Project father chair keep. Financial itself miss house reduce necessary.\n",
      "Tagged Sentence:\n",
      "Cold write close full likely actually plant method . Suite <B-Address> 139 <I-Address> Project father chair keep . Financial itself miss house reduce necessary .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [10,11]: \"Suite 139\"   [− Labels: Address (0.9952)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Cup happen say join improve would. Oil PM special parent executive foot series term. Operation adult result decision prevent talk well. 640 Eddie Mission Apt. 272 New Kimberly, ME 38505\n",
      "Tagged Sentence:\n",
      "Cup happen say join improve would . Oil PM special parent executive foot series term . Operation adult result decision prevent talk well . 640 <B-Address> Eddie <I-Address> Mission <I-Address> Apt <I-Address> . <I-Address> 272 <I-Address> New <I-Address> Kimberly <I-Address> , <I-Address> ME <I-Address> 38505 <I-Address>\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [25,26,27,28,29,30,31,32,33,34,35]: \"640 Eddie Mission Apt . 272 New Kimberly , ME 38505\"   [− Labels: Address (0.9983)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Book environmental site each produce more. Clearly 7112 Joanne Cape Apt. 685 ability support technology everything alone pressure.\n",
      "Tagged Sentence:\n",
      "Book environmental site each produce more . Clearly 7112 <B-Address> Joanne <I-Address> Cape <I-Address> Apt <I-Address> . <I-Address> 685 <I-Address> ability support technology everything alone pressure .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [9,10,11,12,13,14]: \"7112 Joanne Cape Apt . 685\"   [− Labels: Address (0.9997)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Suite 082 Behavior phone sign meeting service. Fish service attack present during security source.\n",
      "Tagged Sentence:\n",
      "Suite <B-Address> 082 <I-Address> Behavior phone sign meeting service . Fish service attack present during security source .\n",
      "True Label: Address\n",
      "Entity\n",
      "Span [1,2]: \"Suite 082\"   [− Labels: Address (0.9922)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Medical eye inside respond. Ability international change ccccc 2224009433974117 ddddd could what American actually rate. Whole although chance.\n",
      "Tagged Sentence:\n",
      "Medical eye inside respond . Ability international change ccccc 2224009433974117 <B-CreditCardNumber> ddddd could what American actually rate . Whole although chance .\n",
      "True Label: CreditCardNumber\n",
      "Entity\n",
      "Span [10]: \"2224009433974117\"   [− Labels: CreditCardNumber (0.9996)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Rock movement call turn minute American act soldier. Next customer similar agency ccccc 4371942766026400604 ddddd training industry. Painting once itself camera go yes.\n",
      "Tagged Sentence:\n",
      "Rock movement call turn minute American act soldier . Next customer similar agency ccccc 4371942766026400604 <B-CreditCardNumber> ddddd training industry . Painting once itself camera go yes .\n",
      "True Label: CreditCardNumber\n",
      "Entity\n",
      "Span [15]: \"4371942766026400604\"   [− Labels: CreditCardNumber (0.9993)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Team deal growth check human. Small these American star subject loss ccccc 4504414195582719 ddddd measure.\n",
      "Tagged Sentence:\n",
      "Team deal growth check human . Small these American star subject loss ccccc 4504414195582719 <B-CreditCardNumber> ddddd measure .\n",
      "True Label: CreditCardNumber\n",
      "Entity\n",
      "Span [14]: \"4504414195582719\"   [− Labels: CreditCardNumber (0.9996)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Run society adult large. sssss 070-94-9083 nnnnn Down phone many. Through admit involve life property decision data doctor.\n",
      "Tagged Sentence:\n",
      "Run society adult large . sssss 070-94-9083 <B-SSN> nnnnn Down phone many . Through admit involve life property decision data doctor .\n",
      "True Label: SSN\n",
      "Entity\n",
      "Span [7]: \"070-94-9083\"   [− Labels: SSN (0.9984)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Sister their service tax water sit a. Hundred region bad source well else save. sssss 617 15 2105 nnnnn\n",
      "Tagged Sentence:\n",
      "Sister their service tax water sit a . Hundred region bad source well else save . sssss 617 <B-SSN> 15 <I-SSN> 2105 <I-SSN> nnnnn\n",
      "True Label: SSN\n",
      "Entity\n",
      "Span [18,19,20]: \"617 15 2105\"   [− Labels: SSN (0.9876)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Produce military act sssss 765 70 5679 nnnnn bill. Source carry discussion use such attorney before. Friend air last. Even project mother maintain allow partner.\n",
      "Tagged Sentence:\n",
      "Produce military act sssss 765 <B-SSN> 70 <I-SSN> 5679 <I-SSN> nnnnn bill . Source carry discussion use such attorney before . Friend air last . Even project mother maintain allow partner .\n",
      "True Label: SSN\n",
      "Entity\n",
      "Span [5,6,7]: \"765 70 5679\"   [− Labels: SSN (0.9983)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "sssss 573-70-8827 nnnnn Man open upon. Activity note area behavior. Page none two morning.\n",
      "Tagged Sentence:\n",
      "sssss 573-70-8827 <B-SSN> nnnnn Man open upon . Activity note area behavior . Page none two morning .\n",
      "True Label: SSN\n",
      "Entity\n",
      "Span [2]: \"573-70-8827\"   [− Labels: SSN (0.9966)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Discover our nothing try chance federal candidate. Indeed design eeeee barbaracarpenter@yahoo.com mmmmm high people.\n",
      "Tagged Sentence:\n",
      "Discover our nothing try chance federal candidate . Indeed design eeeee barbaracarpenter <B-Email> @ <I-Email> yahoo.com <I-Email> mmmmm high people .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [12,13,14]: \"barbaracarpenter @ yahoo.com\"   [− Labels: Email (0.9989)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Magazine day physical. Eight fill on whatever glass technology. Act as pass tell action pattern eeeee huertabruce@yahoo.com mmmmm every.\n",
      "Tagged Sentence:\n",
      "Magazine day physical . Eight fill on whatever glass technology . Act as pass tell action pattern eeeee huertabruce <B-Email> @ <I-Email> yahoo.com <I-Email> mmmmm every .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [19,20,21]: \"huertabruce @ yahoo.com\"   [− Labels: Email (0.9984)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "eeeee hensleyedward@gmail.com mmmmm Increase several him marriage word truth sort. Among economic system. Usually serve candidate moment.\n",
      "Tagged Sentence:\n",
      "eeeee hensleyedward <B-Email> @ <I-Email> gmail.com <I-Email> mmmmm Increase several him marriage word truth sort . Among economic system . Usually serve candidate moment .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [2,3,4]: \"hensleyedward @ gmail.com\"   [− Labels: Email (0.9991)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Lose meet left kitchen organization herself. Business majority our. They job watch reason meet eeeee emily86@gmail.com mmmmm drive.\n",
      "Tagged Sentence:\n",
      "Lose meet left kitchen organization herself . Business majority our . They job watch reason meet eeeee emily86 <B-Email> @ <I-Email> gmail.com <I-Email> mmmmm drive .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [18,19,20]: \"emily86 @ gmail.com\"   [− Labels: Email (0.999)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Save fall card care anyone pressure. Remember eeeee susan68@ramirez.biz mmmmm sister offer draw. Take field because return fear guess.\n",
      "Tagged Sentence:\n",
      "Save fall card care anyone pressure . Remember eeeee susan68 <B-Email> @ <I-Email> ramirez.biz <I-Email> mmmmm sister offer draw . Take field because return fear guess .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [10,11,12]: \"susan68 @ ramirez.biz\"   [− Labels: Email (0.9984)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "General attorney record ten much remember. Eye live ask eeeee bridget58@gmail.com mmmmm support.\n",
      "Tagged Sentence:\n",
      "General attorney record ten much remember . Eye live ask eeeee bridget58 <B-Email> @ <I-Email> gmail.com <I-Email> mmmmm support .\n",
      "True Label: Email\n",
      "Entity\n",
      "Span [12,13,14]: \"bridget58 @ gmail.com\"   [− Labels: Email (0.9992)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Trouble religious hear environmental teacher get ZSH 214 forget. Test executive whole pass design four contain.\n",
      "Tagged Sentence:\n",
      "Trouble religious hear environmental teacher get ZSH <B-Plates> 214 <I-Plates> forget . Test executive whole pass design four contain .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [7,8]: \"ZSH 214\"   [− Labels: Plates (0.9934)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Draw 40LR5 feeling might. Under lawyer part senior.\n",
      "Tagged Sentence:\n",
      "Draw 40LR5 <B-Plates> feeling might . Under lawyer part senior .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [2]: \"40LR5\"   [− Labels: Plates (0.9544)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Able this character evidence woman it want. I require popular BAA0043 off maintain.\n",
      "Tagged Sentence:\n",
      "Able this character evidence woman it want . I require popular BAA0043 <B-Plates> off maintain .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [12]: \"BAA0043\"   [− Labels: Plates (0.9942)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Of staff international box would also. Arrive region actually training. 255-519\n",
      "Tagged Sentence:\n",
      "Of staff international box would also . Arrive region actually training . 255-519 <B-Plates>\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [13]: \"255-519\"   [− Labels: Plates (0.8353)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Population religious effort whatever contain. Employee general wife another thus mission others. 22-C881 Story year owner easy common late. Before build not gun pay upon.\n",
      "Tagged Sentence:\n",
      "Population religious effort whatever contain . Employee general wife another thus mission others . 22-C881 <B-Plates> Story year owner easy common late . Before build not gun pay upon .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [15]: \"22-C881\"   [− Labels: Plates (0.9668)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Whose raise soon participant S52 1IO alone. Value design teacher which.\n",
      "Tagged Sentence:\n",
      "Whose raise soon participant S52 <B-Plates> 1IO <I-Plates> alone . Value design teacher which .\n",
      "True Label: Plate\n",
      "Entity\n",
      "Span [5,6]: \"S52 1IO\"   [− Labels: Plates (0.9936)]\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Ball idea ever move. Sign writer third teach drop perhaps sometimes. Explain happy me good enjoy.\n",
      "Tagged Sentence:\n",
      "Ball idea ever move . Sign writer third teach drop perhaps sometimes . Explain happy me good enjoy .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Usually cold thousand professional TV direction care. Carry but role strong sister few. Region base single investment.\n",
      "Tagged Sentence:\n",
      "Usually cold thousand professional TV direction care . Carry but role strong sister few . Region base single investment .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Old start difficult others. Move decide shake talk million candidate.\n",
      "Tagged Sentence:\n",
      "Old start difficult others . Move decide shake talk million candidate .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Manager physical respond that teach father together. Republican in recently ahead.\n",
      "Tagged Sentence:\n",
      "Manager physical respond that teach father together . Republican in recently ahead .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n",
      "Sentence:\n",
      "Couple job civil green road news senior. Occur put standard air collection actually thus. Single country would them.\n",
      "Tagged Sentence:\n",
      "Couple job civil green road news senior . Occur put standard air collection actually thus . Single country would them .\n",
      "True Label: None\n",
      "Entity\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run some basic sanity checks\n",
    "\n",
    "tests = [\n",
    "    # name\n",
    "    (\"Hold home fight nor customer defense. Shields Shake player something.\",\"Name\"),\n",
    "    (\"Box direction clear sense democratic power. Adult determine rule Deanna across sometimes according.\",\"Name\"),\n",
    "    (\"High same pass Smith change. Effort board fly onto middle detail. Ahead chance small ability reduce under. Middle policy use single become.\",\"Name\"),\n",
    "    (\"Product similar final sense senior least. Model explain reveal American they behind source. Join Ariana White president other arm until feel force.\",\"Name\"),\n",
    "    (\"Matthew Haas Market Republican hand sign.\",\"Name\"),\n",
    "    (\"Whom simple Franklin nice three car. Music answer southern performance glass around.\",\"Name\"),\n",
    "    (\"Everybody small suggest into president. Over manager Charles government they.\",\"Name\"),\n",
    "    # address\n",
    "    (\"Dark turn purpose attack set way. Significant impact book daughter manager behavior pressure. Price true we pressure culture design 22868 Strong Square Suite 603 serve answer.\",\"Address\"),\n",
    "    (\"Class speech structure ask prevent. Do tree actually 384 Moran River Suite 724 West Maureenport, NV 14327 forward.\",\"Address\"),\n",
    "    (\"Cold write close full likely actually plant method. Suite 139 Project father chair keep. Financial itself miss house reduce necessary.\",\"Address\"),\n",
    "    (\"Cup happen say join improve would. Oil PM special parent executive foot series term. Operation adult result decision prevent talk well. 640 Eddie Mission Apt. 272 New Kimberly, ME 38505\",\"Address\"),\n",
    "    (\"Book environmental site each produce more. Clearly 7112 Joanne Cape Apt. 685 ability support technology everything alone pressure.\",\"Address\"),\n",
    "    (\"Suite 082 Behavior phone sign meeting service. Fish service attack present during security source.\",\"Address\"),\n",
    "    # credit card\n",
    "    (\"Medical eye inside respond. Ability international change 2224009433974117 could what American actually rate. Whole although chance.\",\"CreditCardNumber\"),\n",
    "    (\"Rock movement call turn minute American act soldier. Next customer similar agency 4371942766026400604 training industry. Painting once itself camera go yes.\",\"CreditCardNumber\"),\n",
    "    (\"Team deal growth check human. Small these American star subject loss 4504414195582719 measure.\",\"CreditCardNumber\"),\n",
    "    # ssn\n",
    "    (\"Run society adult large. 070-94-9083 Down phone many. Through admit involve life property decision data doctor.\",\"SSN\"),\n",
    "    (\"Sister their service tax water sit a. Hundred region bad source well else save. 617 15 2105\",\"SSN\"),\n",
    "    (\"Produce military act 765 70 5679 bill. Source carry discussion use such attorney before. Friend air last. Even project mother maintain allow partner.\",\"SSN\"),\n",
    "    (\"573-70-8827 Man open upon. Activity note area behavior. Page none two morning.\",\"SSN\"),\n",
    "    # email\n",
    "    (\"Discover our nothing try chance federal candidate. Indeed design barbaracarpenter@yahoo.com high people.\",\"Email\"),\n",
    "    (\"Magazine day physical. Eight fill on whatever glass technology. Act as pass tell action pattern huertabruce@yahoo.com every.\",\"Email\"),\n",
    "    (\"hensleyedward@gmail.com Increase several him marriage word truth sort. Among economic system. Usually serve candidate moment.\",\"Email\"),\n",
    "    (\"Lose meet left kitchen organization herself. Business majority our. They job watch reason meet emily86@gmail.com drive.\",\"Email\"),\n",
    "    (\"Save fall card care anyone pressure. Remember susan68@ramirez.biz sister offer draw. Take field because return fear guess.\",\"Email\"),\n",
    "    (\"General attorney record ten much remember. Eye live ask bridget58@gmail.com support.\",\"Email\"),\n",
    "    # plate\n",
    "    (\"Trouble religious hear environmental teacher get ZSH 214 forget. Test executive whole pass design four contain.\",\"Plate\"),\n",
    "    (\"Draw 40LR5 feeling might. Under lawyer part senior.\",\"Plate\"),\n",
    "    (\"Able this character evidence woman it want. I require popular BAA0043 off maintain.\",\"Plate\"),\n",
    "    (\"Of staff international box would also. Arrive region actually training. 255-519\",\"Plate\"),\n",
    "    (\"Population religious effort whatever contain. Employee general wife another thus mission others. 22-C881 Story year owner easy common late. Before build not gun pay upon.\",\"Plate\"),\n",
    "    (\"Whose raise soon participant S52 1IO alone. Value design teacher which.\",\"Plate\"),\n",
    "    # none\n",
    "    (\"Ball idea ever move. Sign writer third teach drop perhaps sometimes. Explain happy me good enjoy.\",\"None\"),\n",
    "    (\"Usually cold thousand professional TV direction care. Carry but role strong sister few. Region base single investment.\",\"None\"),\n",
    "    (\"Old start difficult others. Move decide shake talk million candidate.\",\"None\"),\n",
    "    (\"Manager physical respond that teach father together. Republican in recently ahead.\",\"None\"),\n",
    "    (\"Couple job civil green road news senior. Occur put standard air collection actually thus. Single country would them.\",\"None\"),\n",
    "\n",
    "]\n",
    "\n",
    "engine =rules.RulesEngine()\n",
    "\n",
    "for text, true_label in tests:\n",
    "    text = engine.pin_text(text)\n",
    "    sentence = Sentence(text)\n",
    "    # predict the tags\n",
    "    model.predict(sentence)\n",
    "    print(\"Sentence:\")\n",
    "    print(text)\n",
    "    print(\"Tagged Sentence:\")\n",
    "    print(sentence.to_tagged_string())\n",
    "    print(\"True Label:\", true_label)\n",
    "    print(\"Entity\")\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "        print(entity)\n",
    "    print(\"\\n\")"
   ]
  }
 ]
}